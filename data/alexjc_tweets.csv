2016-12-05 22:08:28,Even the poster sessions were epic; took 1h30 just to walk through them all + 20 min to (re)appreciate the generati‚Ä¶ https://t.co/qROz5EhJCI,1,0
2016-12-05 22:01:15,#NIPS2016 is what happens when you take a typical academic conference &amp; scale it 2000% with all industry cash it can take‚Äîin a good way.,6,0
2016-12-05 18:26:26,With for-profit conferences you rarely get this kind of treatment. Academics FTW! #nips2016 https://t.co/486LGKDFGm,8,0
2016-12-05 15:47:36,Oh wow. #NIPS2016 is bigger than I expected. Purple T-shirt strategy is working though ;-) https://t.co/w6CIvqVocQ,13,1
2016-12-05 13:56:51,@memotv I think you came to the wrong conference :-P,0,0
2016-12-05 10:12:38,"Intense competition for mindshare, @OpenAI @DeepMindAI release open-source sim framework.
https://t.co/HvJoddtgnj
https://t.co/DvbcszxxZS",17,13
2016-12-05 08:52:16,"On my way to #NIPS2016. First time there, figured the hat would act as a good landmark ;-) https://t.co/JHq2BuGISJ",26,0
2016-12-04 08:43:55,@ngutten Once we're flexible to handle anyone outside Europe then anything should be an option ;-),1,0
2016-12-03 22:45:34,"@spysamot Ruling may not be the best word to describe our intentions, but hopefully we'll make a positive impact ;-)",2,0
2016-12-03 21:07:55,"@bchjam Absolutely, I wish I had an answer for you! Elections here in Austria tomorrow so we may join global turmoil too ;-)",0,0
2016-12-03 20:49:55,"A year ago, obvious choice for founding creative.ai would have been London. Lots to say on this, but not now ;-) https://t.co/zVWNlyNUup",10,1
2016-12-03 20:43:59,It could be that decades of impact by top U.K. universities is being dismantled by the current political situation. https://t.co/Gc6AiFukhq,3,1
2016-12-03 20:36:24,"I was assuming that our #CreativeAI vision/message resonates similarly everywhere, but that may be a conclusion that's a bit premature!",1,1
2016-12-03 20:34:28,"Most interesting (for me) is statistics from LDN &amp; NY. Either there's a surplus of skills, or people want to relocate most ;-) @IgorCarron",3,2
2016-12-03 20:19:15,@IgorCarron @rodolfor Hard to speculate... I figured they are snapped up by local companies and not looking for options. Similar for Berlin.,4,2
2016-12-03 20:12:17,I'm summarising the big patterns &amp; trends here; the team we assemble will likely be made up of special cases ;-) https://t.co/fSflGfoLan,5,1
2016-12-03 20:10:04,"@rodolfor I know what you're implying; English communication is top of our skill list. (For everyone reading, I'll note I'm half-french :-)",2,2
2016-12-03 20:03:42,"@rodolfor Haha, no. We'd never hire someone who required a french-specific version. Didn't stop Spanish or Italians.",3,2
2016-12-03 20:01:18,"I think this partly reflects national interest in #AI, but also whether local scene can absorb experienced labor (e.g. nothing from Paris).",6,5
2016-12-03 19:59:59,"Within Europe, similar:
- Most experienced from London or Stockholm.
- Surprisingly many working remote!
- Lots of‚Ä¶ https://t.co/sRDMvTQJSc",5,3
2016-12-03 19:56:20,"Interesting #AI &amp; #hiring stats for our European job posts, overseas:
- Many senior applicants from NY.
- Lots of a‚Ä¶ https://t.co/foICZnwRrv",24,11
2016-12-03 16:00:50,"@ChadWittman @samim @graphific Nice, subscribed! That sounds like a great idea/format, best of luck with the first episode ;-)",1,0
2016-12-02 16:44:21,"@JazzDotCo Ah, debugging this for you: turns out you have Javascript errors that prevent whole page from loading 8-] https://t.co/ZDddxeoc5k",0,0
2016-12-02 15:55:43,"@Miles_Brundage Haven't yet looked at the conference layout, wondering how much walking there is between the rooms.",1,0
2016-12-02 15:52:04,@graphific *disclaimer: T-shirts and business cards mostly designed to make Roelof and @samim jealous.,2,0
2016-12-02 15:51:21,"@Miles_Brundage Oh, definitely! How's your schedule looking?",2,0
2016-12-02 12:13:14,"@mark_riedl DoomRL is the rogue-like, so basically a game. VizDoom is the platform for deep learning; wonder if it's next?",0,0
2016-12-02 10:53:40,Generating Images of Outdoor Scenes from Attributes and Semantic Layouts https://t.co/ljMNfJmrKe #NeuralDoodle-styl‚Ä¶ https://t.co/bRtbjZju3x,44,19
2016-12-02 10:17:34,"Business cards arrived just in time too. Purple color a bit different than intended after CMYK &amp; printing, but pret‚Ä¶ https://t.co/G4yBsAm1W6",14,0
2016-12-02 09:58:47,"I'll be wearing bright purple T-shirts at #NIPS2016. If you see me, come talk about opportunities or collaboration!‚Ä¶ https://t.co/SJstCU4fol",45,5
2016-12-02 08:06:29,"@Zergfriend Not originally, I just re-implemented it for #NeuralDoodle. https://t.co/ByrS8lKTl0",1,0
2016-12-02 08:02:29,"@Zergfriend Patch-based approaches would do that better IMHO, e.g. #NeuralPatches.",0,0
2016-12-02 07:57:45,@Zergfriend As long as it's a 2D texture rather than 3D perspective photo it should be a reasonable approach!,0,0
2016-12-02 07:50:12,"@admercs I think you can just reuse any existing #NeuralStyle implementation, just duplicate low-res image and apply to rescaled high-res.",0,0
2016-12-02 07:49:16,"@Zergfriend This will only work well under the ""fractal assumption"" (e.g. textures): do patterns at scale N also apply at N+1?",0,0
2016-12-02 07:26:22,@admercs Secret code is 2478112690.,0,0
2016-12-02 07:25:34,@tombielecki GANs can do this at low resolution. Need fully convolutional one for HD but not seen it done yet.,1,0
2016-12-02 06:31:06,Neural style meets super-resolution! https://t.co/GNTJ6hUWdH Texture Enhancement via High-Res Style Transfer for Si‚Ä¶ https://t.co/db5fX5qeXs,58,26
2016-12-02 06:22:11,@desplesda There is no uncanny bridge unfortunately!,1,0
2016-12-01 21:40:54,@tenpn Many thanks! Any cool bots you recommend?,0,0
2016-12-01 21:24:55,@tenpn Random question from a fellow Slack user. What do you use to store documentation or meeting minutes? Thanks!,0,0
2016-12-01 20:37:14,@mtrc Amazing. How did the carrier pigeon sustain itself during that long journey?!,2,0
2016-12-01 19:14:57,Playing handpan music for our kids when they can't sleep is by far fastest way to get them snoring! It's hypnotic. https://t.co/17kOrM3Nee,9,2
2016-12-01 17:18:48,@jurieongames It's been so long it's cool again ;-),0,0
2016-12-01 10:58:39,"@hannesseifert Great review, congrats! https://t.co/mzlkKru2A7",1,0
2016-12-01 10:32:10,"@ankurhandos On Leo's face I think you notice it's not quite as crisp‚Äîalmost like gaussian blur at sigma=1.0, But pretty good!",1,0
2016-12-01 10:29:12,@ankurhandos Photo-level quality is improving day by day!,1,0
2016-12-01 09:49:28,"But it's the second paper in three days that cites #NeuralDoodle, so can't complain too much‚Äîthey've done their homework ;-)",3,0
2016-12-01 09:46:39,"FWIW, I think this was mostly possible with the #NeuralPatches research from January. Need to dig into the changes, if any...",1,0
2016-12-01 09:24:03,High-Res Image In-Painting using Multi-Scale Neural Patch Synthesis https://t.co/hq5MhX2N7m Complete opposite of GA‚Ä¶ https://t.co/nHEBWfOWq4,70,32
2016-12-01 07:34:36,"@mphuget That could be @samim and @graphific, but I'd have to convince them ;-)",0,0
2016-11-30 18:30:30,"You take both pills‚Äîyou wake up in Wonderland and realize #CreativeAI also applies to Art, glad you did https://t.co/fSflGfoLan! @Bass1mpact",6,0
2016-11-30 18:07:00,"You take the red pill‚Äîyou stay in Wonderland, and I show you how deep the #CreativeAI rabbit hole goes.‚Ä¶ https://t.co/5irV3D68o9",14,1
2016-11-30 18:05:29,"You take the blue pill‚Äîthe story ends, you wake up in your bed and still believe Creativity means Art. https://t.co/WM7HD2MESW",18,0
2016-11-30 17:41:57,"@deliprao When logged-in, the front page is dynamically generated from your subscriptions.",2,0
2016-11-30 12:01:30,@mphuget @samim @graphific Thanks! I think there was a paper a few months ago about this... Need to dig it up again.,0,0
2016-11-30 10:16:36,"@JazzDotCo Like the look &amp; design of your app, but feels very slow! Spend a lot of time waiting or looking at this.‚Ä¶ https://t.co/6vNPymbtN1",0,0
2016-11-29 21:40:02,Tremendous visualizations in this article on Thought Vectors (as used in generative models) by @gabeeegoooh‚Ä¶ https://t.co/nV6KFlABul,102,44
2016-11-29 20:54:04,Awesome Typography: Statistics-Based Text Effects Transfer https://t.co/oQEyMWMF6N Semantic stylization with specia‚Ä¶ https://t.co/rbc0vSuzgH,101,60
2016-11-29 19:29:52,@pwang @graphific @samim Thank you! Details will follow very early in the new year :-),2,0
2016-11-29 11:12:01,@vakibs @samim The kind of oversight that grants Deep Mind free access to NHS records without anyone really noticing.,3,0
2016-11-28 10:14:58,@graphific @JoeThorntonPF Also to consider is that each candidate is not a single float. ‚àÉx: x &gt; max(t) but ‚àÄx: x ‚â• mean(t) #hiring #math ;),1,0
2016-11-28 09:12:29,@vakibs Plus hippopotamuses are funny :-D,1,0
2016-11-28 08:56:14,"@sheredom Thanks! It's hard to quantify awesomeness, but it's definitely high ;-)",1,0
2016-11-28 08:33:30,"Obvious yet unspoken (until now) benefits of assembling a dream team... Also, \o/ for founder alignment!‚Ä¶ https://t.co/sx4Vz4jsVM",23,3
2016-11-28 07:15:47,"@vakibs I wonder to what extent J.'s symptoms are due to his ego the size of a hippopotamus, e.g. https://t.co/042yjcy4Yl",1,0
2016-11-28 02:39:10,@avyfain c2 looks good! Curious if there's a way to break the implementation while those tests still pass ;-),0,0
2016-11-28 00:56:59,"@ThePeshwa @graphific @samim Yes, it's an option as long as relocation works out. Visa issues makes this a bit harder than it should be.",0,0
2016-11-28 00:40:47,"@avyfain If any of your code ends up Open Source, let me know so I can take a look ;-)",1,0
2016-11-28 00:35:59,"@avyfain I only spent a bit of time with Hypothesis so far, but it does seem like a different mindset‚Äîalbeit a very useful one!",1,0
2016-11-28 00:35:23,"@avyfain Hypothesis also works for specific cases (e.g. bug reports) if you write a bit more logic, no? Sometimes those may generalise...",0,0
2016-11-28 00:33:18,"@avyfain I imagine this as similar to design-by contract but for combinations of functions, known subsets of data, etc.",0,0
2016-11-28 00:32:22,@avyfain You need to find similar properties of the code. What is invariant? What do you assume? How about combinations of funcs?,1,0
2016-11-28 00:22:33,"@avyfain @DRMacIver I agree that re-implementing the tested function is not only an anti-pattern, it actually serves no purpose!",1,0
2016-11-28 00:18:27,"@avyfain @DRMacIver For xor, I would use hypothesis to validate known properties. Enough for correct implementation‚Ä¶ https://t.co/BJu9IyGwoe",2,0
2016-11-27 22:58:09,@lizardlucas42 @edersantana Not at this stage; we're planning for it though!,0,0
2016-11-27 22:10:27,"I probably can't quit teaching/broadcasting cold-turkey, so will likely do more in the near future. Maybe super-resolution? ;-) [13/10]",2,0
2016-11-27 22:07:49,"The Course is on indefinite hold, I hope to come back to it eventually ;-) @AiGameDev members will get special bonuses by email. [12/10]",3,0
2016-11-27 22:06:58,META: I prepared this sequence of Tweets in advance but apparently I can't count. [11/10],6,0
2016-11-27 22:05:57,"The https://t.co/pJXhuLPILU fixed all that and launched to particularly great reception. But with #nuclai16 alongside, I burned out. [10/10]",2,2
2016-11-27 22:04:25,"But after ~14 packed ""seasons"" of content, the format needed to change for a variety of reasons ‚Äî not least the MOOC revolution. [9/10]",0,2
2016-11-27 22:02:44,"As for @AiGameDev, in retrospect, its in-depth tech interview format was unique at bringing out ideas that never surfaced elsewhere. [8/10]",4,2
2016-11-27 22:01:12,"Thanks to the multi-track 3-day structure of @nuclai, we published more content in past 18 months than ever before via @AiGameDev. [7/10]",0,1
2016-11-27 21:59:55,"The next @nuclai conf will proceed in the same spirit, though now we're rethinking logistics. (Now looking for an event organiser.) [6/10]",1,1
2016-11-27 21:58:36,"After 9 years of doing events, Petra &amp; I were happy to take a short break ‚Äî but it looks like the org-team had different plans :-P [5/10]",1,1
2016-11-27 21:57:20,It's also personally been very rewarding front-running the #CreativeAI movement with @nuclai before it hit the public consciousness! [4/10],0,1
2016-11-27 21:54:57,"A few years ago within creative industries, #AI was only on the radar of game developers. It's been incredible watching that explode! [3/10]",1,1
2016-11-27 21:54:05,"Over the past two years, we've shifted our company emphasis from @AiGameDev to @nuclai for a long list of strategic reasons... [2/10]",1,1
2016-11-27 21:53:40,"Now https://t.co/BMTOU3asIp is official, here's an overdue update about @AiGameDev and @nuclai. (Emails will follow tomorrow.) [1/10]",13,6
2016-11-27 21:08:03,"@f00_ Except for the issues of Visas, that would be perfectly fine for us!",2,0
2016-11-27 20:48:56,"@edersantana From the kids perspective it's not so tied to company vision... More company logistics/culture, no?",0,0
2016-11-27 20:47:23,@jag_pag **blushes** üò≥¬†‚öò‚öò‚öò ;-),0,0
2016-11-27 20:27:52,"@f00_ For juniors, it's likely we'll require relocation to our local hubs. Hands-on supervision too hard to do remotely...",2,0
2016-11-27 20:11:22,@edersantana There was an article in past year showing how such humanist grand-visions are significantly more likely to resonate with women.,0,0
2016-11-27 20:06:01,"We're bringing more diversity to #AI. If you too feel it's important, help spread the word across boundaries! [8/8] https://t.co/uusfb2z660",16,7
2016-11-27 20:04:41,Our vision is centered around individual agency and AI for augmentation ‚Äî which seems to resonate beyond the usual #ML archetypes. [7/8],12,4
2016-11-27 20:03:19,Everyone on the founding team is a humanist. As @drfeifei eloquently puts it: https://t.co/TpTX1Jx9zv [6/8] https://t.co/APsSpWOCs9,12,4
2016-11-27 20:01:09,"We welcome anyone within Europe (ideally) or (alternatively) able to relocate to one of our local hubs: AMS, BER, VIE. #SiliconBridges [5/8]",7,0
2016-11-27 20:00:23,We're a distributed-first team with regular in-person retreats: lots of flexibility for team members (e.g. our work/family balance). üë™ [4/8],8,0
2016-11-27 19:59:10,This core diversity helps a lot with messaging... You can tell from the creative.ai pictogram that it was Petra's c‚Ä¶ https://t.co/CLnXxSuGe9,6,1
2016-11-27 19:58:15,Petra is on co-founding team ‚Äî rare for #AI startup? She is an integral part of making @nuclai's atmosphere so friendly &amp; welcoming. [2/8],7,0
2016-11-27 19:55:53,The topic of diversity in #AI hiring came up as quickly as I expected; there are a couple thoughts I'd like to share on that subject. [1/8],8,0
2016-11-27 17:40:04,"@Lidinwise @ojahnn Just so we're on the same page, I assumed the original post was sarcastic and humorous.",1,0
2016-11-27 13:15:49,"@KimThatWas Taking culture very seriously, building on @nuclai which had great success in diversity. We found Indy funny (still now). [2/2]",0,0
2016-11-27 13:13:41,@KimThatWas Our jobs and copy text is reviewed by Petra (female co-founder) to make sure it resonates beyond usual circles. [1/2],0,0
2016-11-27 12:10:08,"@nerdherdempire @graphific @samim If you care about #CreativeAI as a field it's a unique opportunity, if not there are others elsewhere ;-)",2,0
2016-11-27 11:34:25,"@savanvisalpara7 Staffing the core team at the moment, for juniors/interns hopefully mid-late next year.",0,0
2016-11-27 11:33:52,"@feloy2 Hi, work is ramping up already. Team focus on Q1 / ASAP for each individual. It's currently remote, founders in BER, VIE, AMS.",0,0
2016-11-27 10:34:23,"@Michcioperz Currently, yes. Need some core team members first; plan is to have more junior positions and internships afterwards.",1,0
2016-11-27 10:28:23,"@Michcioperz Architecture is still subject to iteration. NoSQL only planned in one part, the ""important"" stuff will be relational...",2,0
2016-11-27 10:22:53,I've been waiting to post this particular tweet for over a week‚Äîwhich tells you a lot about my sense of humour. ;-) https://t.co/AyprlkM9nE,5,0
2016-11-27 10:19:03,creative.ai is looking for a full-stack #Python coder to join us on our adventure into the Generative Age!‚Ä¶ https://t.co/o46wfGP4Qk,20,9
2016-11-27 10:03:16,@ElMarcel @graphific @samim Thanks! I'm glad we can finally share something about this ‚Äî it's too big to keep contained ;-),0,0
2016-11-27 08:48:27,"I'll post more details about @nuclai later; for now, if you're a professional event organiser and keen to get into this field, let me know!",0,0
2016-11-27 08:42:58,"If your skills overlap with these descriptions, I'd suggest sending your details and we'll tell you more in person. https://t.co/fSflGfoLan",8,3
2016-11-27 08:40:24,"My pitch to you for applying:
- The rest of the team we're assembling looks unbelievable.
- The vision is equally fascinating and inspiring!",6,1
2016-11-27 08:33:50,"We're still in stealth mode officially so you won't find too much information... but good recruiting takes time, so here we are!",6,0
2016-11-27 08:29:10,"Thrilled to finally announce a new project with @graphific and @samim: https://t.co/BMTOU3asIp Oh, and we're hiring‚Ä¶ https://t.co/gsblMXV8ey",165,67
2016-11-27 07:40:01,@parapraxist @samim @graphific It's the dichotomy of modern startups to be operating in stealth mode but hiring at fast pace ;-) More soon!,1,1
2016-11-27 07:34:45,"@VanushVaswani Yes, but ideally within Europe. If not, then we set the bar much higher as communication/meetups gets harder.",0,0
2016-11-26 22:12:05,@tombielecki Ah. How could we make that more clear?,0,0
2016-11-26 22:09:21,"@tombielecki Ah, https://t.co/WxFGk89Uui and creative.ai are two separate sites/initatives if that's what you mean?",1,0
2016-11-26 21:57:05,"@tombielecki Creative in what way? Business-side we have already covered for now, in stealth really so low communication ;-)",1,1
2016-11-26 21:44:20,"If you're interested in applying #AI &amp; #ML to creative industries, this is a dream opportunity with a great team! #‚Ä¶ https://t.co/PWRtWug1zb",16,8
2016-11-26 21:37:30,"I've been hinting about new projects a lot recently, but I think this is the biggest clue so far ;-) #‚öò https://t.co/GbJakAiUrU",24,2
2016-11-26 21:01:01,@AlexShafranov You mean the flower? It's followed us throughout the journey so far...,1,0
2016-11-26 21:00:02,@mykola Great! Probably best explained over Skype ;-),0,0
2016-11-26 18:35:11,"I think I'm currently around 85%. Workshop submissions for NIPS and ICML2017 kicked in this week, will never catch‚Ä¶ https://t.co/FvR40TWWTi",14,2
2016-11-26 16:32:56,"Learned some Scratch with Leon today; recording our own ""Oops"" and fart sounds to modify existing games sold it! https://t.co/PXYYHwsh7U",4,0
2016-11-26 12:36:21,It's for you! Eliot would like to wish you all a wonderful weekend. :-) https://t.co/H9pjw69LqK,22,1
2016-11-26 12:31:27,What percentage of your open tabs point to papers on https://t.co/92zSSTTyRL?,12,3
2016-11-26 08:57:55,"@paniq I like when they use the word ""we"", think it's a good sign... Trying to minimize the time until they say it ;-)",0,0
2016-11-25 18:16:45,"@jurieongames That's not lost, it gets paid out to 5/6th if terminated the month before.",0,0
2016-11-25 18:00:58,"@ferrouswheel My favourite type of technical interview is where we solve a real problem on the same side. If possible, hire them for a day.",1,0
2016-11-25 17:56:47,"@jurieongames Oh, shit. Just before Christmas too...",0,0
2016-11-25 17:37:48,"Timer-From-Me metric: duration of time until a team collapses after a member tellingly says ""I $verb [..]"" about an achievement. @BartWronsk",1,0
2016-11-25 17:22:57,"@BartWronsk @Atrix256 Yeah, I was going to post that corollary ;-) Both are respectively good and bad signs in equal measures...",1,0
2016-11-25 16:47:17,"@Atrix256 Yeah, it's leading. Letting the word emerge is a good metric ;-)",1,0
2016-11-25 16:01:50,"@Atrix256 You're interviewing someone and they accidentally say ""In the future we could [...]"" (emphasis on the ""we"" since not on team yet).",1,0
2016-11-25 15:55:30,@Atrix256 I think interviews should be collaborative; trying to minimize the time when interviewee feels like it is collaboration!,1,0
2016-11-25 15:28:48,"@robertsdionne Posted in the context of a very senior developer, I thought it was very positive!",0,0
2016-11-25 15:17:00,@bchjam API duplication? Because of the async/await keywords?,0,0
2016-11-25 15:05:12,"@edersantana Not yet, digging now! Looking for new opportunities in the web-development space‚Äîpost Ph.D.? ;-)",1,0
2016-11-25 14:59:15,"There aren't many web-frameworks that use asyncio yet though, except aiohttp‚Äîusually deployed with gunicorn. https://t.co/4Gw7MUavWV",4,0
2016-11-25 14:57:05,"Interesting! With uvloop, #Python 3.5 is now on par with Go at HTTP request benchmarks and better than Node.‚Ä¶ https://t.co/BU8uZlEvom",24,5
2016-11-25 14:36:51,@Paul_Lalonde2 @dougbinks Of course everything else has to click to. I just find it interesting to spot! Sometimes it doesn't happen at all.,0,0
2016-11-25 14:12:26,"Time-To-We metric: duration of time until interviewee accidentally says ""we"" about a job-related problem or solution. How do you minimize?",12,1
2016-11-25 10:34:44,@codeandrew Sanity check. Isn't 9m -&gt; 500m only 55x? ;-),0,0
2016-11-24 09:26:45,"@ArgesRic Hehe, just visited the front page by accident three minutes ago too‚Äînot logged in either. Crazy!",0,0
2016-11-24 09:14:00,Controlling Perceptual Factors in Neural Style Transfer https://t.co/nW8NJmfYzP (Follow-up on original work by Gaty‚Ä¶ https://t.co/XqXY2azlNV,78,24
2016-11-23 11:37:48,@FloRicx It's the only way to make these things tolerable!,1,0
2016-11-23 10:56:05,@FloRicx It's almost funny in a post-ironic way now ;-) They have a competition who can find the craziest image for their AI stories...,0,0
2016-11-23 08:33:28,"@ngutten @kylotan Yeah, at this stage it becomes a design decision not a technical one; no technology demo could sell the idea.",0,0
2016-11-23 01:02:11,"SpirOps‚ÄîParis-based R&amp;D company‚Äîdid this already 8 years ago, but selling (AI) middleware to game developers is always an uphill battle!",0,0
2016-11-23 00:58:10,There's valuable research in taking regular utility systems from games and training them with gradient descent from few examples. @kylotan,1,0
2016-11-23 00:55:04,"@kylotan I was expecting that reply, it's fair play ;-)",0,0
2016-11-23 00:40:47,"For those of you that aren't in #gamedev, ""utility systems"" are hand-written neural networks with lots of unusual activation functions. ;-)",4,2
2016-11-23 00:38:45,"@JonOlick If you showed this at actual CPU training speed it'd be one frame per hour, right? ;-)",0,0
2016-11-23 00:17:56,"Great, the whole session is online ""Turing Tantrums: AI Developers Rant""; my segment starts at 09:30:‚Ä¶ https://t.co/LUhqnPX6Aq",18,5
2016-11-23 00:11:11,"FWIW, my other micro-talks this year were better IMHO‚Äîincl. one about Generative Pipelines that evolved into a very interesting project. #‚öò",1,0
2016-11-23 00:07:29,"If you have access to the recording, you'll see how tense I get when bringing up that topic ;-) But very glad to hear people were listening!",0,0
2016-11-23 00:06:03,"It was my most rewritten talk, tough message to deliver. I didn't expect message to resonate, venue felt stagnant: https://t.co/h3yXJ5ly0B",1,0
2016-11-23 00:01:32,Surprised. Just found out I was among the top speakers of #GDC16 for my rant about the deep learning freight train. https://t.co/7h8eTeFYm0,24,1
2016-11-22 20:29:36,"@ErwanBancal @DaveChurchill Oh, when you play with random decks the AI really kicks in: it knows exactly when switch from build to attack.",0,0
2016-11-22 20:24:56,"@ErwanBancal @DaveChurchill Oh, wow you got much further than I did ;-) It is indeed a great game‚ÄîI prefer playing the bots even!",0,0
2016-11-22 19:06:24,"Invertible Conditional GANs for Image Editing https://t.co/sskf1El9n2 (Second paper today, part of adversarial trai‚Ä¶ https://t.co/OPxTQAHOsP",39,12
2016-11-22 17:01:33,@ben_throop Try this plugin for Chrome: https://t.co/7mV1PaJwX4 (Firefox version delayed by Mozilla's review team.),0,0
2016-11-22 11:13:54,"@madhumita29 @halhod More accurate would be ""for-profit company could potentially save lives"" then the cost of privacy is weighed correctly.",0,0
2016-11-22 11:13:03,"@madhumita29 @halhod If your intent was to persuade for DeepMind with your description, then you succeeded!",0,0
2016-11-22 11:07:11,"@halhod @madhumita29 Hehe. Alternate caption: ""DeepMind is digitising healthcare for future profit, why are academic concerned?""",0,0
2016-11-22 10:29:19,"Tuesdays are normally busy on arXiv in cs.CV, but today's entries take three pages. It'll take days to dig through just the good ones! :-|",1,0
2016-11-22 10:20:06,"Image-to-Image Translation with Conditional Adversarial Networks https://t.co/NWLX0EbohN Well, well. Who said progr‚Ä¶ https://t.co/UFx57qu8rK",68,34
2016-11-22 09:59:27,Super-resolution research has clearly reached the end of SSIM &amp; PSNR metrics; now requires human test subjects to e‚Ä¶ https://t.co/pnWIty7obY,31,9
2016-11-22 09:55:04,@cyberkm @ID_AA_Carmack It's likely that having AI generate source code or algorithms on its own (e.g. by search) will give better results.,0,0
2016-11-22 09:54:07,"@cyberkm @ID_AA_Carmack I'm not sure about this direction, public data is low quality and buggy. May be difficult and unwise to learn from.",0,0
2016-11-22 09:52:31,"@matesteinforth Yes. It's funny, I still had the link to this paper in my clipboard ;-) https://t.co/vYw1OhtveU",1,0
2016-11-21 12:41:22,"@Seivanheidari If event-driven implementation changes the way things work, then there's a risk: sometimes people end up with decision tree!",1,0
2016-11-21 12:40:46,"@Seivanheidari If it makes things faster than polling without changing the ""specification"", then it's great! I call those second-gen BTs.",1,0
2016-11-21 07:42:15,"@daniel_bilar So in terms of your original question, regular practices help debug but that doesn't mean we understand everything 100% ;-)",1,0
2016-11-21 07:41:35,@daniel_bilar Interesting! There was a paper about DropLabel that hints at 1) and for 2) using a traditional test set would catch this.,2,0
2016-11-21 07:28:13,"@daniel_bilar The more advanced ""intuitions"" are captured by recent papers, which is why I spent minutes every morning scanning arXiv.",1,0
2016-11-21 07:27:38,"@daniel_bilar I would consider these basic practices for machine learning even data-scienec, maybe go through one of the online courses?",1,0
2016-11-21 07:20:23,"@daniel_bilar Grid search, scientific method. Starting from best practices helps make this a much faster. Some intuition too, like coding.",2,0
2016-11-21 07:19:19,"@daniel_bilar For one dimension (correctness) you use the same tools as a regular programmer, for the others ML/DS specific techniques.",2,0
2016-11-20 20:28:17,@daniel_bilar What do you mean by debugging?,0,0
2016-11-19 22:22:39,Inverting The Generator Of A Generative Adversarial Network https://t.co/myJjMBpdvu #ML #AI https://t.co/6ZlLXfZOGX,47,16
2016-11-18 21:29:50,"@edersantana @graphific @seaandsailor Yes, it's easy enough. Did you have any trouble running CUDA on GPU while encoding/streaming?",0,0
2016-11-18 21:22:01,@edersantana @graphific @seaandsailor That part is easy enough with Skype running in parallel. Did 100s live @AiGameDev broadcast that way.,2,0
2016-11-18 21:20:35,@edersantana @graphific @seaandsailor I wondered the same thing. I suspect it's best if one person hosts somehow.. Is your replay available?,0,0
2016-11-18 21:17:29,@graphific @seaandsailor @edersantana Are there any good tools for pair programming on the same file but remotely?,0,0
2016-11-18 21:13:35,"@edersantana @graphific Hehe, ALT+TAB tweet storm.",0,0
2016-11-18 21:09:04,@edersantana @graphific I was wondering about making a new repository for that new neural interpolation paper. Good problem to handle live!,3,0
2016-11-18 21:07:42,"The #NeuralEnhance repository has better Docker files: cleaner, up-to-date dependencies and runs much better in VM: https://t.co/hR2AsKiCEn",4,2
2016-11-18 21:05:57,If I'd known @indicoData was going to use #NeuralDoodle as an example for docker deployment I'd have cleaned up related GitHub Issues ;-),4,0
2016-11-18 21:05:26,"Blog post about Docker deployments by @indicoData featuring #NeuralDoodle, via @graphific. https://t.co/LuzRcVXYfD",9,5
2016-11-18 20:48:00,@nueluno Not sure you can. The recent list is about a week long: https://t.co/LUM4hbVOhF,0,0
2016-11-18 17:41:40,@memotv Does it say how well humans performed on the task? I have to admit the examples of criminals did look more scary than the others ;-),0,0
2016-11-18 17:36:13,@memotv Bad data? Looks like a smile detector. People photographed in prison don't look happy...,1,0
2016-11-18 16:38:54,7/ Paper shows a clever trick to remove artefacts from reconstructions caused by VGG+L-BFGS. Quality &amp; resolution b‚Ä¶ https://t.co/U3WClMq88o,13,2
2016-11-18 16:36:55,"@calebthompson Unfortunately, I know nothing about Rails or Ruby ;-)",0,0
2016-11-18 16:35:12,"6/ Given the adjusted features, the error from the current image can be back-propagated to adjust the image‚Äîpretty much like #DeepDream.",2,0
2016-11-18 16:30:06,"5/ The ""trick"" is that all example images must be aligned to input image. Then it can add beards, glasses, or teeth exactly where necessary!",3,1
2016-11-18 16:28:27,"4/ To calculate the direction, a few examples are required. offset=(old people)-(young people). Then adjust input i‚Ä¶ https://t.co/OpXWEBnkcA",2,1
2016-11-18 16:25:26,3/ It works by taking high-level features from a pre-trained network (VGG-19 of course) and shifting them by Œ± in a‚Ä¶ https://t.co/ynTtk3XQo8,5,1
2016-11-18 16:23:27,"2/ Using L-BFGS as optimizer it takes 80s to render 200x200 pixels. Seems conservative, likely it could be improved. https://t.co/FyWEJJ4hgv",3,2
2016-11-18 16:21:20,1/ I'll review the paper now: https://t.co/eFpDnjYNnm Ultimately it's an optimization similar to deep dream or the original neural style.,5,2
2016-11-18 13:08:49,@graphific Happy birthday! I didn't have enough candles so you'll have to blow these out instead. ;-) https://t.co/i3BNAY8SO2,1,0
2016-11-18 11:57:04,@graphific Would love to see higher resolution ones of all those!  Their artefact removal trick is interesting...,1,0
2016-11-18 11:10:49,"@mathena It may be some variation of AI, not necessary pure DL, but it's going to happen!",0,0
2016-11-18 09:16:28,"@VanushVaswani Yes, I try ;-)",0,0
2016-11-18 08:49:35,"Deep Feature Interpolation for Image Content Changes https://t.co/oqXTaT2Y2g ""Look ma, no GAN!"" Modify features wit‚Ä¶ https://t.co/dEoOHHzt3z",106,54
2016-11-18 08:41:50,arXiv computer vision and pattern recognition is on fire this week. I saved/closed all my tabs last Sunday and got almost 100 open now...,10,1
2016-11-17 19:36:01,"Original video is here: https://t.co/DfMwvrQhdJ
Reddit ML discussion: https://t.co/ODyP2FeVIM",7,3
2016-11-17 19:29:48,Lip Reading Sentences in the Wild https://t.co/Bm7nvdKYBS Crazy results: ~50% error rate vs. ~80% human experts. Ex‚Ä¶ https://t.co/ghwlAOw3PF,214,147
2016-11-17 19:17:34,"@botminds Agree. Ultimately the technique doesn't matter, integration will likely be the same: specify interface, examples or test scripts.",1,0
2016-11-17 19:04:06,@botminds Key question: is DL going to be any worse than mediocre programmer in average team?,2,0
2016-11-17 17:12:48,@mark_riedl I guess you don't want the answer yet... This is developed further as the series continues!,4,0
2016-11-17 11:06:49,Computing energy maps of a photo-portrait at different frequencies. https://t.co/SxZ46AZTGr,11,1
2016-11-17 10:19:10,"Portrait image analysis. Bugs in visualization still look cooler than the intended purpose, but it's getting there‚Ä¶ https://t.co/sr43fiPaGd",6,1
2016-11-17 09:16:09,@alexiskennedy Very cool! Did you see this one in the comments? https://t.co/ERJnLuWvPU,0,0
2016-11-17 08:15:55,Real-Time Video Super-Resolution with Spatio-Temporal Networks &amp; Motion Compensation https://t.co/vYw1OhtveU New by‚Ä¶ https://t.co/4nPb7Gy6HC,39,10
2016-11-17 07:35:22,"Noteworthy: the paper demonstrates the benefits of ""cardinality"": number of separate blocks that are repeated and a‚Ä¶ https://t.co/UyCdb8xuGk",5,0
2016-11-17 07:32:16,ResNeXt: Aggregated Residual Transformations for Deep Neural Networks https://t.co/AYxfNZiNvP By Facebook AI &amp; UCSD‚Ä¶ https://t.co/HukN0dBoW8,101,35
2016-11-17 06:21:18,"@danbri If whole network is application-specific and trained end-2-end, then data problem is addressed partly: comes from its deployment.",0,0
2016-11-17 06:20:26,"@danbri Maybe some small components will be part of the zoo, like they are now, but modular enough to assemble.",0,0
2016-11-17 06:19:53,"@danbri Using DL on specialized applications is to reduce the burden of building custom complex architectures, less need for zoo?",0,0
2016-11-17 05:52:47,"@KaiLashArul I think NIPS is big enough that we won't bump into each other by accident, we should schedule something!",2,0
2016-11-16 20:08:44,I should point out my DMs are open to everyone. If you need any help/advice I'll do my best too! https://t.co/wPiA11AQ4a,12,2
2016-11-16 19:47:09,"@ferrouswheel Next year is not as clear yet, I will let you know!",0,0
2016-11-16 19:32:01,"@izi8000 Imagine having part of your program built with optimization-friendly operations, then it can be learned! https://t.co/tbrSoT1JxD",2,0
2016-11-16 19:18:17,"7/ If you're curious what it means for creative industries, we should chat at #NIPS2016 ;-) Very exciting projects in the pipeline! #‚öò",14,0
2016-11-16 19:05:17,"6/ This is obvious to those directly involved in artificial intelligence or machine learning, but outside the picture isn't as clear (yet).",24,6
2016-11-16 19:04:23,"5/ You'll be able to specify an architecture for your program, then let the optimization figure out the details. Differentiable computing!",26,11
2016-11-16 19:03:58,"4/ In the same way classical AI (e.g. prolog) and applied AI (behavior trees) were integrated into languages, it's DL will increasingly too.",14,8
2016-11-16 19:02:42,3/ Deep Learning is now practically its own field within software engineering (alongside traditional programming) growing extremely fast.,25,18
2016-11-16 19:01:41,"2/ The largest deep learning systems today scale not only with number of GPUs, but also in terms of feature complexity and types of inputs.",17,8
2016-11-16 19:00:11,"1/ As deep learning evolves as a discipline, it's becoming more about architecting highly complex systems that leverage data &amp; optimization.",87,42
2016-11-16 14:00:08,"@NNNenov I bet they save everything for training, could make an amazing version 2.0.",0,0
2016-11-16 13:54:25,"8/ Longest Path. Each player draws the same word until correct, no erasing. Score points for each (unique) intermediate word recognized.",1,1
2016-11-16 13:48:47,@bartwerf @paniq That's what it suggested; it would be a waste of data otherwise!,0,0
2016-11-16 13:46:31,7/ Rotation Variance. Each player's drawing is recognized at 4 different angles; player with most unique labels giv‚Ä¶ https://t.co/JNfb2n1ujg,4,1
2016-11-16 13:42:24,6/ Taboo List! https://t.co/3D03DXzygR,2,1
2016-11-16 13:41:05,@paniq When my sisters play they can get them done in &lt;2s and move on to the next without anyone else noticing...,0,0
2016-11-16 13:36:23,"@paniq TBH that happens in Pictionary too, people just end up on same wavelength.",0,0
2016-11-16 13:35:42,"@paniq Agree. My sheep was good enough! But it's building up a database, by this time next week it should be signif‚Ä¶ https://t.co/xemCxgNbVp",1,0
2016-11-16 13:32:29,"5/ Adversary. One players draws a word, all other players make changes so it's mis-recognized. Smallest change wins! https://t.co/aEB5MYLHgD",2,1
2016-11-16 13:26:04,4/ Smuggler. First player must communicate a word to second but without the AI ever recognising it; use synonymous concepts/secret language.,5,2
2016-11-16 13:16:54,"3/ Telephone. Sit in a circle, drawing in turn. After 10s AI whispers guess to next player, who draws it. Everyone wins if first&amp;last match!",7,1
2016-11-16 13:07:58,"2/ Ping Pong. First player draws given word as fast as possible, second must draw the same in less time‚Äîthen switch until someone misses.",8,1
2016-11-16 13:03:33,1/ Taboo. A second person must listen to recognized word stream (with answer excluded) and try to figure out what first person is drawing.,11,1
2016-11-16 13:00:58,"Quick, Draw! is like playing Pictionary with a convnet. It's fun already! Let's brainstorm AI-based game designs? https://t.co/pQJbc48Yeb",51,35
2016-11-16 12:52:51,"@trustswz How do you like my sheep? That was also before I found erase button, I just kept drawing hoping it'd reco‚Ä¶ https://t.co/StQ4AbHYpA",2,0
2016-11-16 12:46:16,OctNet: Learning Deep 3D Representations at High Resolutions https://t.co/VFHoxZM0eF Voxel octrees meet specialized‚Ä¶ https://t.co/gOiTQRRmc3,87,37
2016-11-16 12:26:32,@trustswz ;-) Your üêÑ is amazing!,1,0
2016-11-16 10:26:19,When Saliency Meets Sentiment: Understanding How Image Content Invokes Emotion and Sentiment‚Ä¶ https://t.co/aI0QbhziJj,20,10
2016-11-15 21:31:16,"11/ There's a follow-up paper that improves training (end-2-end, without KNN) but lots of room for more modern generative convnets! EOT.",0,2
2016-11-15 21:28:01,10/ The rest of the paper is obvious: once you have good alpha channel you can do any combination of background/for‚Ä¶ https://t.co/5ck3aJA70U,3,1
2016-11-15 21:25:07,"9/ Since annotations are not perfect, inputs and outputs &amp; effectively trimaps which are then post-processed with ""‚Ä¶ https://t.co/aF43yjjWHZ",5,4
2016-11-15 21:22:59,"8/ They reuse pre-trained FCN-8 parameters, but still takes whole day to converge. Learning rate 1E-4 as compromise‚Ä¶ https://t.co/zEvA2qMtEf",0,1
2016-11-15 21:20:14,"7/ Training required manually annotating 1800 portraits from Flickr, augmented with 4x scales, 4x rotations, 4x gamma settings: total 19k.",0,1
2016-11-15 21:17:13,6/ It's domain specific knowledge but helps get much better results. Below (c) uses no extra annotations (d) has th‚Ä¶ https://t.co/9Rz33CD1Dx,2,2
2016-11-15 21:15:31,"5/ Before the training/inference starts, an off-the-shelf face locator helps align three bitmaps to the face: normalized X, Y and mean mask.",0,1
2016-11-15 21:13:57,"4/ The paper reuses this FCN-8 architecture from semantic segmentation, with a few extra input channels to improve‚Ä¶ https://t.co/3zdgfukbd2",2,1
2016-11-15 21:10:24,"@YadFaeq Yes, that's my biggest interest. There's an improved model I'll post tomorrow!",1,0
2016-11-15 21:09:53,3/ Manually creating a trimap is tedious and fragile. Why not borrow ideas from deep semantic segmentation? https://t.co/0Ny4jRGtSU [PDF],1,1
2016-11-15 21:06:36,"2/ Typically, matting is done in a semi-supervised fashion‚Äîfor example KNN-matting uses trimaps (black: bg, white:‚Ä¶ https://t.co/UZ18fg6TCc",4,3
2016-11-15 21:03:58,1/ Matting is the process of creating an alpha channel separating foreground (usually a person) from background (us‚Ä¶ https://t.co/IWMRCO9zLA,4,3
2016-11-15 20:59:42,Automatic Portrait Segmentation for Image Stylization https://t.co/6UCzwE9scf [PDF] Includes automated CNN-based ma‚Ä¶ https://t.co/HcdToTM8UD,73,28
2016-11-15 18:23:47,"@ferrouswheel Is it feasible to get reliable portrait matting automatically, given minor errors in pixels but not huge sections?",0,0
2016-11-15 16:16:16,Luckily the whole thing is still only around 400 lines of code or I could never justify the time ;-),2,0
2016-11-15 16:15:03,"Most helpful would be a modular SR network that can combine any operations (deblur, denoise, repair) and scales (2x, 4x, 8x ++) at runtime.",1,0
2016-11-15 16:13:17,"Still room for improvement, but I learned as much about super-resolution since users started trying it, vs. reading papers &amp; writing code.",4,0
2016-11-15 15:16:35,"@JonOlick The image is not best quality in first place, but this algorithm indeed worse than human.",0,0
2016-11-15 13:12:44,"@nueluno There are a couple from similar time earlier this year, this is one of them: https://t.co/DcI0vRsQJJ",0,0
2016-11-15 13:06:17,Experiments with image matting; most techniques are semi-supervised‚Äîexcept the very latest convolution networks. An‚Ä¶ https://t.co/GaXdOprYr3,8,0
2016-11-15 09:36:09,The whole thread about RAISR is interesting to read‚Äîincluding discussions about GAN vs. regular learning for super-resolution.,2,1
2016-11-15 09:34:39,I think this is by far the nicest thing you could possibly say about any open source project. Thanks HN!‚Ä¶ https://t.co/6uZ6DI9C5G,65,8
2016-11-14 21:56:37,"I will dig into this further tomorrow! Looks like big ideas relate to performance, quality of more recent models li‚Ä¶ https://t.co/vEZuq8axhL",12,0
2016-11-14 21:35:08,"@dribnet Ah, I see. Do you somehow constrain the VAE to focus its capacity on the face, or does that happen naturally?",1,0
2016-11-14 21:26:42,@dribnet Enhancing already does a great job on mouth+nose+eyes. Hair needs more help from VAE output?,2,0
2016-11-14 21:16:14,@Miles_Brundage Plot twist! HoC was relevant right from the start... https://t.co/rXycIC6o68,2,0
2016-11-14 17:14:36,@ErwanBancal @DaveChurchill Always eager to listen!,0,0
2016-11-14 17:05:13,"@DaveChurchill BTW, @ErwanBancal is working on a very cool application that seemed ideally suited to this, so I linked him your paper ;-)",0,0
2016-11-14 16:23:17,@sarefo @samim Randomness. Or just take the firehose and reverse your filters ;-),0,0
2016-11-14 15:38:50,"@ErwanBancal @DaveChurchill Looks like product of both sets, basically nested for-loops, like itertools.product() https://t.co/iyqbhr8BWX",0,0
2016-11-14 15:28:16,@gcpascutto Thanks! @Woodgate is the author. PING ;-) https://t.co/AAWG7RABk9,0,0
2016-11-14 15:12:17,"@smilevector Haha, that's a great one! Did it take the parameters from Kate and then update on William's face? @dribnet",2,0
2016-11-14 14:51:40,"@gcpascutto Version 2.0 of LarryFilter was apparently submitted over 2 weeks ago, but still in review and on 1.2.1. https://t.co/ckKSZMsnt4",0,0
2016-11-14 14:28:02,@USAIsAnAsshole Which news/link? Try here for now: https://t.co/zvJA76J8ka,0,0
2016-11-14 12:03:44,"@shahidkamal Local networks and contributions are also the antidote for ""post-truth"" media coverage.",1,0
2016-11-14 11:14:37,"@jhermsmeier Oh, I didn't know thanks! I use TD to manage peripheral accounts (posting) but for reading I prefer the regular stream view.",0,0
2016-11-14 11:09:57,Receiving a barrage of unwanted news/reactions is not a recipe for good mental health. I prefer my activism to be proactive and goal-based.,20,2
2016-11-14 11:08:14,Switched to Chrome (at least for Tweets) since Mozilla isn't updating plugin repo. Need Twitter filter to stay sane: https://t.co/z1MTXsUgvW,8,0
2016-11-14 10:42:18,"The more I look at this astronaut picture for debugging, the weirder it looks. Doesn't it look like a disembodied h‚Ä¶ https://t.co/c24oFmFFmE",32,7
2016-11-13 08:37:22,@Smerity @rabois I like the idea of scaring journalists to do a better job though ;-),0,0
2016-11-12 19:08:40,@richardmatthias Probably best if it's a very lightweight model if you want to use it at runtime. Might be as simple as a linear problem...,0,0
2016-11-11 19:10:03,@samim Was just thinking the exact same thing. It's like a wrestling match‚Äîboth sides just as complicit but fans will happily pick one.,4,0
2016-11-10 19:10:08,@mark_riedl Which industry in particular? Most creative industries are behind non-creative when it comes to applying AI / DL.,3,1
2016-11-10 14:11:05,"@askerlee Yeah, it would work. Only challenge is that overall style would not necessarily be consistent....",0,0
2016-11-10 13:24:06,@askerlee Not yet. Anything patch-based works much better for multiple images!,0,0
2016-11-10 07:28:49,@mozilla How long does it take to approve updates to popular plugins that broke because of API changes? https://t.co/ckKSZMsnt4,0,0
2016-11-09 01:16:42,@nueluno You'd need to measure it. It may depend on your exact architecture!,0,0
2016-11-08 22:33:01,"@ArneBab Yes, I can get *some* idea after 50 epochs. Plus I can measure raw performance on random network...",1,0
2016-11-08 22:24:18,@ArneBab Indeed! I'm still experimenting‚Äîbut 16h turnaround :-) Trying to add/remove and see how close I can make my current code to w2nn.,1,0
2016-11-08 22:20:45,25/ Batch norm is an ugly hack. There I said it! Maybe residual+generative was a lame combination all along. Who knows! Question everything.,5,0
2016-11-08 22:17:49,"24/ What's the take-away? I'm going through a Romantic Period in my deep architectures, implementing more pre-2015 designs ;-)",3,0
2016-11-08 22:17:19,"23/ w2nn doesn't use an adversarial network, nor a perceptual model. It just optimizes MSE on 6k hand-picked images with great augmentation.",1,1
2016-11-08 22:13:49,"22/ The last layer is a 4x4 ""transposed convolution"" ‚Äî almost equivalent to 2x2 sub-pixel convolution. Thread: https://t.co/9YXrZIOJg5",2,0
2016-11-08 22:08:59,"21/ Notice the increasing number of filters in the layers, it's prior art for this paper that studies it in depth: https://t.co/cvn4nD4HfQ",2,0
2016-11-08 22:07:14,"20/ As for wide vs. deep, better training as it help avoid zero padding... With fewer layers you can feasibly just use larger input images.",2,0
2016-11-08 22:04:10,19/ For the anime/cartoon dataset I measured this: non-residual trains quicker &amp; reaches lower error‚Äîfor my chosen architecture at least.,1,1
2016-11-08 22:02:10,"18/ For residual, I've suspected for months it's in fact using same capacity less effectively than regular NN. https://t.co/nz8RgB25VM",0,0
2016-11-08 21:59:07,"17/ When generating pixel colors at a fixed range (not classifier), is BN more harmful than better initialization or Weight Normalization?",1,0
2016-11-08 21:56:23,"16/ Batch Normalization: the original GAN paper didn't use BN in generator for stability, I removed it too as it was slower and low benefit.",1,0
2016-11-08 21:54:40,15/ It's that the techniques from 13/ don't (yet) provide measurable benefits for the common use cases. It's interesting to speculate why...,0,0
2016-11-08 21:52:42,"14/ But w2nn isn't a static implementation of SRCNN, nagadomi stays on top of research, measures benefit of latest techniques in w2nn.",1,0
2016-11-08 20:49:29,@jordnb Prisma is also real-time now. They've both been racing for PR for the past weeks... https://t.co/iI0TXoAlUr,0,1
2016-11-08 19:14:59,@keybrot https://t.co/gHBzvsJLLI,1,0
2016-11-08 19:11:48,@keybrot Over 3-5 epochs you should see it come out of grey into rough colors with brown tint. Posting an Issue on GitHub with log...,0,0
2016-11-08 19:05:29,"@keybrot Which part, the first phase of training?",0,0
2016-11-08 18:16:12,"13/ Techniques from upconv7 that go against the latest research:
- no batch normalization
- no residuals connections
- not deep, a bit wider",2,0
2016-11-08 18:12:35,"12/ Techniques from upconv7 that line up with latest research:
- convolution
- leaky ReLU
- process at low-res
- upscale in last layer",5,0
2016-11-08 18:07:28,10/ The best performing network in w2nn is called upconv7. Here's the definition of the Torch model in Lua:‚Ä¶ https://t.co/vOJhO4IZQ1,5,0
2016-11-08 17:59:54,9/ Recent papers I used for #NeuralEnhance work great on harder problems like de-blurring and de-noising. But still lots to learn from w2nn:,1,0
2016-11-08 17:54:55,8/ I tried processing anime/cartoon images (not best quality data admittedly) and w2nn also did better‚Äîthanks to its 18 months of polishing.,3,0
2016-11-08 17:51:37,"7/ I still think w2nn does a better job here, and my original point stands: hard to get the latest papers to match quality on real cases.",0,0
2016-11-08 17:49:33,"6/ It's not quite an apples-to-apples comparison; upconv_7 is a bigger network, runs slower and processed twice to match #NeuralEnhance 0.1.",0,0
2016-11-08 17:47:15,"5/ For example, nagadomi on GitHub posted a comparison in this Issue: https://t.co/D3F0ceZ9EJ This is w2nn's result‚Ä¶ https://t.co/5SnbiuDLXf",1,0
2016-11-08 17:43:29,"@nueluno Yes, I'll get to it shortly in the thread ;-)",0,0
2016-11-08 17:41:42,4/ To the point where I implemented two papers 12 &amp; 18 months later than SCRNN and struggled to get better quality than w2nn on real images.,3,0
2016-11-08 17:39:33,"3/ These tricks are mostly orthogonal to the research published on the topic, but sometimes they are in direct opposition (surprisingly).",4,0
2016-11-08 17:37:20,"2/ However, in the two years the project has been active on GitHub, it's become a huge collection of practical tricks for super-resolution.",3,0
2016-11-08 17:33:26,1/ The project is originally based on research from early 2015 known as SRCNN: super-resolution convolutional NN. https://t.co/9XcBvYxA2Z,2,3
2016-11-08 17:32:07,"I dug into the ""waifu2x"" (henceforth w2nn) project yesterday, both code &amp; Issues and learned a lot! Thoughts below. https://t.co/auXaVVI8PO",51,16
2016-11-08 10:06:56,"Indeed, there are no checkerboard patterns or ghosted edges. Only some blurry areas of the image‚Äîwhich is understan‚Ä¶ https://t.co/Zz07NnnIgi",3,1
2016-11-08 09:40:23,"@quasimondo Ah, I see. I got two suspensions already with @DeepForger so don't want to risk it‚Äîthough troll phase is over now.",0,0
2016-11-08 09:33:21,@quasimondo Congratulations either way! Here's to the next few years ;-),1,0
2016-11-08 09:32:45,@quasimondo Did you have any trouble with people trolling the bot with inappropriate or illegal images?,0,0
2016-11-08 08:25:31,"@askerlee The deeper the random network, the worse the patterns: https://t.co/ppC8WmWgKn",0,0
2016-11-08 07:38:49,More evidence there are always multiple labs working on big ideas; conference deadlines synchronize the publication‚Ä¶ https://t.co/Y2BIx0jXOz,18,7
2016-11-08 07:35:27,End-to-end Optimized Image Compression https://t.co/mZ3BjFxqDB Applying convolution to beat JPEG2000 (again) with p‚Ä¶ https://t.co/wd4O8ZBEVx,71,39
2016-11-07 21:30:13,"@graphific Oh, that was a few epochs ago. My loss is currently 1.7998E+1.",6,0
2016-11-07 13:45:05,17/ The code for this paper is available! You can find it on GitHub: https://t.co/lYulufX5Qv #torch #lua ... and follow: @culurciello,11,5
2016-11-07 09:38:48,"@alan2here Yes, I looked into it. They have networks trained on photos too.",0,0
2016-11-07 08:43:57,"@vjk2005 Thanks! I found a website that does that already, just downloaded 45k images‚Äîmore to come.",0,0
2016-11-07 07:58:17,"@Larryfilter It's still not up, is that normal turn-around time? If so, it's crazy.",0,0
2016-11-07 07:12:39,"Adversarial Machine Learning at Scale https://t.co/tOfA59bFyT Paper by Google &amp; OpenAI, training more robust models‚Ä¶ https://t.co/3HwwgNfnbP",37,19
2016-11-06 11:48:20,"Damn, and I wasn't there to see it! Feels very much like reaching 500 LinkedIn connections did 5 years ago ;-)‚Ä¶ https://t.co/5db4aZFRAE",2,0
2016-11-05 23:31:26,"@William_Malo Yes, that's what I ended up doing just now ;-)",0,0
2016-11-05 23:30:58,"I think I'm going to use screenshots from high-quality anime videos for now, much more consistent in quality. Now t‚Ä¶ https://t.co/25jqO8qp3d",9,1
2016-11-05 23:29:41,Thanks for the advice everyone; crawling Reddit a pretty good option but still mixed quality... https://t.co/dEpvPWxbhR,0,0
2016-11-05 23:04:56,@rms80 Indeed! I bet the original source is the same as you suggested ;-),0,0
2016-11-05 23:01:28,@rms80 I took a shortcut... Found a website that just has lots of screenshots of anime at regular intervals!,2,0
2016-11-05 23:00:42,@dribnet @ferrouswheel That's in `master` already; best compute JPEG compression at runtime with random levels‚Äîmore data to learn from!,1,0
2016-11-05 21:50:18,@madebyollin Awesome! I have fast internet but need to check Reddit's policy for crawling delays...,1,0
2016-11-05 21:02:18,@reviewero Thanks! Looking for something a bit more consistent in format that wouldn't require too much manual filtering.,0,0
2016-11-05 20:57:03,@edersantana Also I suspect #NeuralEnhance will do better because of the perceptual loss and the GAN combined...,1,0
2016-11-05 20:56:17,"@larsiusprime I looked but it's not available: a private collection of 6,000 HD images.",0,0
2016-11-05 20:53:26,Looking for a HD collection of cartoon/anime images to train a specialized version of #NeuralEnhance overnight. Any ideas for sources?,9,3
2016-11-05 20:19:10,@cepera_ang It's learning a more spatially compact representation so it can process it with more layers efficiently.,0,0
2016-11-05 20:15:24,@cepera_ang It doesn't lose information because there are more channels in the low-res (64 vs. 3) but it's significantly faster to process.,0,0
2016-11-05 20:08:54,"@cepera_ang You mean using an existing algorithm instead of letting the CNN downsample? When it downsamples, it also increases layers to 64.",0,0
2016-11-05 20:08:02,"@cepera_ang You want the final output to be the same resolution as the input, right? The CNN downsamples for efficiency...",0,0
2016-11-05 20:01:15,"@YadFaeq Oh, interesting. Is anyone using that paper in production applications?",1,0
2016-11-05 19:04:24,"@ferrouswheel It's never mentioned in academic papers, so not sure it's standard. But a good idea! https://t.co/VVcEtkLIG6",1,0
2016-11-05 18:57:28,"@ferrouswheel The noise I had was a hybrid Gaussian and S&amp;P: basically gaussian with exponent, rescaled and clamped. Will try alternatives.",0,0
2016-11-05 18:55:13,@ferrouswheel Any hue-based representation won't work because dimension is not continuous 360==0 but you can't linearly interpolate.,1,0
2016-11-05 18:54:32,@ferrouswheel I found the same: CNN should be able to learn those transformations. Only reason to use YUV or Lab is procedural manipulation.,1,0
2016-11-05 18:52:42,"@ErwanBancal Ah, usually I do but I didn't get this notification. Will reply...",0,0
2016-11-05 17:38:15,This example is a 1:1 enhance (no zooming) since it was the most requested use-case. But internally it down-samples 4x and back again!,1,1
2016-11-05 17:36:32,"Improved noise/blur used in training, and 24h later #NeuralEnhance works better! It removes pixelation quite well,‚Ä¶ https://t.co/eTrdvq053A",31,7
2016-11-05 17:32:11,"@xDirtyPunkx It was. While mixing, I naively thought I had made too much ;-)",1,0
2016-11-05 16:54:48,"Eliot's pre-birthday request was ""chocolate and raspberries"" so I made mousse with frozen raspberries underneath an‚Ä¶ https://t.co/NSDOHMxEfO",17,1
2016-11-05 16:43:11,"@edersantana Often with transfer learning, it generally seems faster but get stuck in plateau where training from scratch does better. [2/2]",0,0
2016-11-05 16:42:06,@edersantana Net2Net adds randomness and still needs more training. Ultimately trying to help networks get out of local minima. [1/2],2,0
2016-11-05 16:16:29,"@IanMcMeans Yes, that's the kind of thing I'm looking for. Have the same intuition as you, but I'm sure there's a paper somewhere I missed!",0,0
2016-11-05 16:03:27,"Wondering if you can simply measure stddev of the activations, and if it's low then replace that neuron's weights with copy of high stddev.",1,0
2016-11-05 16:02:28,"Are there any Net2Net-like algorithms that detect redundant neurons, and re-initialize them as copies of most critical neurons?",8,1
2016-11-05 14:46:30,"@nrose Nothing for creative industries in general, which is over $2.25T market.",1,0
2016-11-04 19:56:14,"@Wikisteff It's already live as release 0.2, but has many problems on noisy images (see follow-up Tweet). https://t.co/zvJA770JIK",2,0
2016-11-04 19:19:36,"@mtrc Combine this with ""What's already available"" and you have a winner! So much stuff already out there for anyone wanting to apply AI.",2,0
2016-11-04 19:18:22,"@mtrc Torn about this one... There are many indie games with APIs or entire game code available, not much uptake except for AAA.",2,1
2016-11-04 19:05:09,"If the tools and APIs are as open as they describe in the blog, then I'm sad it took @DeepMind to get there but glad anyway.",8,0
2016-11-04 18:28:21,"@ferrouswheel Ah, was just trying to find a single equation that would give me both a gaussian and salt &amp; pepper look, but guess I need two?",0,0
2016-11-04 16:35:49,"@Thanatosyletus @Donzanoid It was a new feature on the website, if you didn't upgrade your phone app you probably didn't notice.",0,0
2016-11-04 16:14:56,"@Donzanoid Alternatively, they liked that design but it overloaded their notification system and couldn't scale ;-)",0,0
2016-11-04 16:08:22,"@Donzanoid I wonder if the problem was that the recipient list was highly obfuscated, so you never knew who you were really writing to.",0,0
2016-11-04 15:48:40,"@pmawhorter Oh, the data has lots of everything. I mean likely input formats and how they are broken (blur, noise, JPEG artifacts).",0,0
2016-11-04 15:42:27,"@pmawhorter Anything out of training set is likely to cause problems, just need to extend training to cover likeliest cases.",0,1
2016-11-04 12:09:18,"@F_Vaggi Absolutely, since last night I'm varying more the pixel radius but no results to show so far. You mean blue noise?",0,0
2016-11-04 11:52:25,@__AtifKhan Object Recognition tasks tend to only require bounding boxes. Segmentation requires pixel correct labels.,0,0
2016-11-04 08:45:09,I think I need to add more randomness into the blur pre-process during training; network seems to have learned exact distribution too well.,3,0
2016-11-04 08:40:33,"Example photo with noise caused by poor lighting and mediocre lense. It's not (yet) fixed by #NeuralEnhance, yellow‚Ä¶ https://t.co/biOdRswEIZ",3,3
2016-11-04 08:35:02,Version 0.1 does better in some cases (download it from releases) if you want to upscale by 4x ‚Äîor OK to downscale it first.,0,0
2016-11-04 08:32:46,"Latest #NeuralEnhance models are pretty good at removing blur (below), but sometimes insert ghosted yellow edges. B‚Ä¶ https://t.co/E5muOGD8Tz",54,17
2016-11-04 08:30:53,"Twitter rolled back change to hide who Tweet is addressed to, and obfuscate recipient list. Now review looks crap! https://t.co/YZt3L1NQLh",4,0
2016-11-04 08:04:57,"@cepera_ang I thought about it, I will consider the format. That said, Twitter summaries are unique &amp; easy to consume, where blogs aren't.",2,0
2016-11-03 23:17:30,"@deanpomerleau @edersantana @graphific Thanks, not read that one yet! Most of the time we just discover why an old‚Ä¶ https://t.co/TPKIXX4mxQ",2,0
2016-11-03 22:45:27,@nueluno @edersantana @graphific Any papers or open source implementations you recommend? Are there hybrids?,1,0
2016-11-03 22:44:48,".@edersantana @graphific 16/ In summary, it's a paper I'll print out tomorrow and read again :-) Lots to learn from‚Ä¶ https://t.co/OLHBH56hTt",6,0
2016-11-03 22:41:28,".@edersantana @graphific 15/ Unlike papers in super-res &amp; style transfer, ENet reduces size of feature maps increme‚Ä¶ https://t.co/OufGICI8wU",1,0
2016-11-03 22:34:02,".@edersantana @graphific 14/ This is known as Spatial Dropout. https://t.co/3AKtLN6wj9 Must investigate it further,‚Ä¶ https://t.co/TMgzZ28YbJ",8,1
2016-11-03 22:32:47,".@edersantana @graphific 13/ Interestingly, they got performance boost from stochastic depth (recent ResNet extnsio‚Ä¶ https://t.co/NzYemJVH2l",2,0
2016-11-03 22:28:43,"@lobachevscki Download a library like Keras and go through some of the samples, see which one you find most fun. It‚Ä¶ https://t.co/m8XVxb1yo6",3,0
2016-11-03 22:26:37,".@edersantana @graphific 12/ Frequent 3x3 ""dilated"" convolutions (where corners of filter sit 2-4-8 or 16 pixels aw‚Ä¶ https://t.co/IIXgR7twsC",2,1
2016-11-03 22:21:43,".@edersantana @graphific 11/ One block ""conv"" includes a combination of filters factorized as 1x5 and 5x1; it's as‚Ä¶ https://t.co/tJqIOa4yvO",9,0
2016-11-03 21:47:25,.@github Only the small lower-quality networks have been retrained. Likely it'll be faster to write some Net2Net tr‚Ä¶ https://t.co/6poj5RX4qO,1,2
2016-11-03 21:45:50,.@github #NeuralEnhance 0.2 is now available! Fast tiled rendering (for big photos) and 1:1 denoise &amp; deblur withou‚Ä¶ https://t.co/N5gEnwSs7H,22,3
2016-11-03 20:13:39,".@edersantana @graphific 10/ The whole network is a combination of ""bottleneck"" blocks assembled together as residu‚Ä¶ https://t.co/jSdOPaJ0e4",6,1
2016-11-03 19:52:23,.@edersantana @graphific 9/ The learned slope on negative side helps gradient descent decide if layer should satura‚Ä¶ https://t.co/064jlmLRcJ,7,0
2016-11-03 19:50:10,.@edersantana @graphific 8/ The non-linear operations in the network are all parametric rectified linear (PReLU). B‚Ä¶ https://t.co/xZiL3CQfXg,12,0
2016-11-03 19:40:48,".@edersantana @graphific 7/ Most of the ideas feel refreshing! For example, the input layer is a combination of bot‚Ä¶ https://t.co/b963KiOWpn",6,1
2016-11-03 19:37:54,".@edersantana @graphific 6/ This doesn't have a big underlying principle, it's a collection of performance-tested a‚Ä¶ https://t.co/Zw8uUnQ9FF",5,0
2016-11-03 19:32:48,".@edersantana @graphific 5/ If you can increase speed and reduce parameters, then it's (likely) easier to scale up‚Ä¶ https://t.co/a2bREkLcly",4,1
2016-11-03 19:30:52,".@edersantana @graphific 4/ This paper builds on many other papers from 2015, but things move fast so likely obsole‚Ä¶ https://t.co/FjFchEtu97",3,2
2016-11-03 19:25:41,".@edersantana @graphific 3/ Insights from segmentation apply relatively well to other ""image transformation"" proble‚Ä¶ https://t.co/mcDeFMNwah",3,1
2016-11-03 19:24:14,"2/ @edersantana brought it up previously, and more recently @graphific. This paper is a great summary and has variety of interesting tricks.",5,2
2016-11-03 19:23:23,"1/ Looking at deep learning architectures, segmentation research seems ahead of other fields like style transfer or super-resolution.",6,4
2016-11-03 19:21:16,ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation https://t.co/fg4Nt5kB52 Interesting re‚Ä¶ https://t.co/CbHguJTsz1,311,141
2016-11-03 16:59:50,@ngutten So you want some kind of unsupervised learning of what is a natural image (low-level loss) or what makes i‚Ä¶ https://t.co/mOYCx5g7dm,0,0
2016-11-03 16:57:25,"@halhod As an organizer of small-medium conferences, happy to trade passes especially for pre-conference coverage a‚Ä¶ https://t.co/SL54xLtIRF",1,0
2016-11-03 16:52:37,@ngutten You can learn a perceptual model adversarially as long as you have examples of real photos. The SRGAN paper basically does this.,0,0
2016-11-03 14:17:10,"@ngutten Perceptual solves that well (combined with TV-loss), but apparently using a lower layer in the adversary also seems to work.",0,0
2016-11-03 13:52:15,@ngutten It's missing some kind of grounding?,1,0
2016-11-03 13:51:33,@zaoo @nlguillemot @sehurlburt @richgel999 Almost two weeks later I feel very good. The work/projects keep me energ‚Ä¶ https://t.co/uMkwILnBra,1,0
2016-11-03 07:43:19,"@ngutten OK, that part makes sense. So the third network would be similar to the encoder but trained with its own weights?",0,0
2016-11-03 07:37:04,"@ngutten So either your ""latent space"" is part of the adversary (trained) or it's static and it's like perceptual l‚Ä¶ https://t.co/Tz95FOjU3K",0,0
2016-11-03 07:29:38,@ngutten Yes. See the OpenAI paper on tricks for improving training of GANs. It's a bit like perceptual loss but in the adversary's space.,1,0
2016-11-02 20:06:46,@securitygen Less than 320x200 pixels.,1,0
2016-11-02 20:06:05,"@samim @github Trending since Saturday too, and only today (finally) beat those pesky Javascript libraries for the‚Ä¶ https://t.co/HTwkf4ThgU",28,2
2016-11-02 13:46:27,"@securitygen Rescale it so it's 4x smaller, then run it through the script.",0,0
2016-11-02 13:44:57,@securitygen That's the plan!,0,0
2016-11-02 13:42:47,@securitygen Current work-around would be to down-sample it by 4x. I'll post an update once 0.2 is out with this feature!,0,0
2016-11-02 13:40:14,"@securitygen By default it's enlarging 4x, not just enhancing. I'm training a version for enhancing only. Is that w‚Ä¶ https://t.co/B5QIo2UUuT",0,0
2016-11-02 13:38:33,@securitygen Lower the resolution not the size on disk. Will be fixing this soon hopefully...,0,0
2016-11-02 13:34:22,Cross-Modal Scene Networks https://t.co/FnGpbeCDfg Deep Learning to extract meaning from multiple representations.‚Ä¶ https://t.co/kuAVU8rKCj,25,9
2016-11-02 13:22:01,SoundNet: Learning Audio Representations from Unlabeled Video https://t.co/BAQUC9f23h Exciting experiments with mul‚Ä¶ https://t.co/6GxVA0HgzC,49,20
2016-11-02 12:34:53,@ngutten You mean in the same process? I presume you're on Theano currently?,0,0
2016-11-02 08:16:20,@smilevector @dribnet Is that decoloration (seems new) caused by the post-processing?,0,0
2016-11-01 22:05:06,@ch402 @Zergfriend @dribnet @smilevector [2/2] as well as extra layers afterwards to effectively fix the pixelation‚Ä¶ https://t.co/A79DxTMEwW,0,0
2016-11-01 22:03:37,@ch402 @Zergfriend @dribnet @smilevector The nearest-neighbor upscaling seems to require larger filters (5x5 or mor‚Ä¶ https://t.co/10KFfxelbR,0,0
2016-11-01 22:02:19,"@ch402 @Zergfriend @dribnet @smilevector It's similar to SRGAN, and the GAN does a great job of reducing checkerboa‚Ä¶ https://t.co/MBXEiuksie",0,0
2016-11-01 20:13:53,"@LaurieCheers Yes, I have that code in place just now ‚Äî will take a bit to train though ;-)",0,0
2016-11-01 16:31:03,Professor Forcing: A New Algorithm for Training Recurrent Networks https://t.co/Hqhqrwa8LE (Uses adversarial techni‚Ä¶ https://t.co/MVA52upEwj,18,4
2016-11-01 15:24:30,"@cmarschner I could retire, if so.",0,0
2016-11-01 13:22:57,@Matthieu_Bizien That's a good idea! (I presume it works? :-) Found way to support multiple files better too.,0,0
2016-11-01 10:56:24,https://t.co/yt6MoulcKp,3,0
2016-11-01 09:37:00,@snakenuts I can almost count them on my fingers.,2,0
2016-11-01 09:33:37,"When researchers mention ""high-resolution photorealistic images"" and ""128x128"" in the same abstract, my eyebrows raise by at least 1cm.",63,3
2016-11-01 07:04:51,"@KaiLashArul @YouTube Do you have experience with #devops using docker too? Looking into Kubernetes (unrelated), th‚Ä¶ https://t.co/KjoXLH8PQv",0,0
2016-11-01 07:03:58,"@KaiLashArul Ah, I'd need to make some changes to the script but that could work!",0,0
2016-11-01 07:02:46,"@aranajhonny Try something smaller, total pixels below 64k or remove that warning in the code.",1,0
2016-11-01 07:01:54,@Zergfriend @dribnet @smilevector Looks like compression artefacts in this case. I tried nearest-neighbor upscaling‚Ä¶ https://t.co/ZSNGB3KMyz,0,0
2016-10-31 23:24:04,"@KaiLashArul @github Ah, just realized I can't just mount one image because it needs to output the result too‚Äîthat‚Ä¶ https://t.co/q9xNja5kpI",0,0
2016-10-31 23:20:29,"I expected some Docker proficiency too, but it's obviously not the case and frankly Docker sucks at this :-) https://t.co/p9HQyYGhb1",1,0
2016-10-31 23:19:18,"@KaiLashArul Oh, maybe... Can you mount a single file with docker? Then Have an easy alias and an advanced one for folders.",0,0
2016-10-31 23:14:30,"Instructions aside, I think it reflects slow improvements with Python packaging, also growing maturity of the libraries (Theano/Lasagne).",4,1
2016-10-31 23:12:56,"@KaiLashArul Not a bad idea, then have the script also check `images` folder too as a convenience hack? (Otherwise‚Ä¶ https://t.co/7WsDidoGa7",0,0
2016-10-31 23:11:49,"On the bright side, python Deep Learning installation problems are zero so far‚Äîcompared to significant hassle at #NeuralDoodle's launch.",1,0
2016-10-31 23:10:31,Trying to suppress my subconscious shouting to build a lightweight webserver within docker instance and let people select files in browser.,2,0
2016-10-31 23:08:52,Are there any tools to help assign/mount folders in more obvious way? Are there conventions for scripts to load those files intuitively?,0,0
2016-10-31 23:06:51,Plus on Windows docker has some kind of permissions spasm that only lets it work within C:\Users\&lt;username&gt;\ which does not help :-|,0,0
2016-10-31 23:06:14,"It's not intuitive which folders are mounted where, and how you refer to the files on the command line so they exist within the instance...",0,0
2016-10-31 23:05:24,The #NeuralEnhance README recommends docker users mount folders with `run -v ...` but it's a significant hurdle for many users. Any tips?,3,0
2016-10-31 22:44:21,@andreas @graphific @samim I have a HD version of the building already... but the paperwork is pretty boring close‚Ä¶ https://t.co/C4TlN0tAcV,4,0
2016-10-31 21:53:55,@quasimondo @graphific @samim it's legal if you bring along a robot to make up the numbers to four :-),5,1
2016-10-31 19:00:25,@CasperKaae I thought that would be relatively standard too but found a couple papers evaluating alternatives...,0,0
2016-10-31 18:59:05,@CasperKaae Thanks btw! Switching to linear+softplus/softminus worked well for discriminator. What do you use for the adversarial loss?,0,0
2016-10-31 18:51:07,"@jackclarkSF @graphific @samim Yep, I'll be there and scheduling lots of meetings already ;-) I'll be around most of the week.",3,0
2016-10-31 18:47:50,@hardmaru @graphific @samim Thanks! I'll tell you more at NIPS if you got your ticket in time ;-),2,0
2016-10-31 18:45:36,"@Bopuc @samim @graphific In the airport, in and out today unfortunately. Will notify in advance next time!",2,0
2016-10-31 18:29:58,"Thus, with the stroke of a pen, on a cold and rainy Monday afternoon in Berlin, the movement took its legal form. #‚Ä¶ https://t.co/FVo6KIkM6S",55,3
2016-10-31 03:48:49,"@msfeldstein I don't know minimal number of training images yet, but it's on my list of things to try. Went as low‚Ä¶ https://t.co/uJ4ui4Cdpx",0,0
2016-10-30 21:32:54,"@bcredeur97 @olivercameron Images with JPG compression artifacts currently cause problems, as you can see they are‚Ä¶ https://t.co/yGpuvQ0bNC",1,0
2016-10-30 20:06:42,Deep Learning Postulate #14: There's always a paper on arXiv that can justify the quick hacks in your code. https://t.co/SSOvkT1w7p,33,5
2016-10-30 20:00:01,"I added this cowardly warning instead of staying up... PR welcome! Generate overlapping tiles, cut off padding, the‚Ä¶ https://t.co/oZbexsxDut",3,0
2016-10-30 19:48:00,.@github Biggest remaining issue is adding tiled rendering so it works smoother within Docker and on machines with‚Ä¶ https://t.co/29owWpKyNE,4,0
2016-10-30 19:46:47,#NeuralEnhance is trending on GitHub! Made little fixes today and merged some useful PRs. https://t.co/Ki9jRyQlDP https://t.co/AUPBXjj48B,57,14
2016-10-30 19:15:32,"@albietz @hardmaru Ah, cool! Will read more... Updating G and D once each is also recommended in SRGAN paper, but n‚Ä¶ https://t.co/py49ehTLJa",2,0
2016-10-30 18:21:53,"@aCraigPfeifer Sorry, I haven't yet looked into OCR. Try an arXiv search?",1,0
2016-10-30 16:41:07,@Stefano_Design It just needs code for tiled rendering! But if you zoom in too much the network may no longer recog‚Ä¶ https://t.co/PwZkqhn1Kn,0,0
2016-10-30 14:14:26,https://t.co/tzF4nsGFds,5,0
2016-10-30 13:33:21,@aCraigPfeifer If you do end-2-end OCR with deep systems they'd likely learn similar features by themselves... no pre-processing required.,1,0
2016-10-30 12:33:18,@dribnet Great news! I updated README instructions to make sure existing models not loaded. How many hours and what GPU?,2,0
2016-10-30 08:47:16,@hardmaru Do you have any thoughts on using the same or different data to train the discriminator and generator? https://t.co/832r5cd9Et,4,0
2016-10-29 23:34:08,"@mflux @alteredq @bkaradzic Yeah, we discussed it a few weeks ago... Needs further investigation ;-) https://t.co/NXn0dIcp7Z",6,0
2016-10-29 23:32:10,@dribnet Did you start training your own model and it's now loading that instead of the one you originally downloaded?,1,0
2016-10-29 22:52:42,"@API_Beast No, I looked for the waifu2x training set and didn't find it. Is it public and I just missed it?",0,0
2016-10-29 22:49:32,@dribnet How are you downscaling? What format? I tried with small and medium and can't see the artefacts you posted. https://t.co/kkyhlOW1u8,4,0
2016-10-29 22:41:28,@hardmaru @edersantana You're turning my brain inside out‚ÄîI like it! It'd be like running the current code to learn‚Ä¶ https://t.co/BYO1SNZ3PG,2,0
2016-10-29 22:38:46,Now there's a long list of practical things to try and it looks like new models will be training in the background for a while ;-),5,1
2016-10-29 22:37:09,I knew the results were not always great before releasing (took weeks to tune) but decided we'd learn quicker if I just released anyway...,6,1
2016-10-29 22:34:17,"@hardmaru @edersantana Your idea is a bit like style transfer: ""apply 1980s camera style"" ;-) Wondering if plain bl‚Ä¶ https://t.co/9nenrQYR2d",2,0
2016-10-29 22:32:42,"@hardmaru @edersantana I haven't tried with GAN, but training an auto-encoder for #NeuralStyle with image Gaussian‚Ä¶ https://t.co/vdUvaVRhK7",1,0
2016-10-29 22:30:24,Amazing! Note to self: I'm going to have to train the next #NeuralEnhance model to deal with noise/compression arte‚Ä¶ https://t.co/G9v8h19Igd,24,3
2016-10-29 22:21:08,@paniq In fact that kind of post-process should work with a significantly smaller network. Needs some experimenting to find out how small...,3,0
2016-10-29 22:20:24,"@paniq Yes. It would have to be a newly trained network, but mostly the same code could do the trick.",3,0
2016-10-29 22:15:37,"@newakamo @github That's the problem, there is none yet. It's a subjective measure currently. People use other pre-‚Ä¶ https://t.co/3eIlilmUUg",1,0
2016-10-29 22:13:50,"@newakamo @github Hallucinated details that are perfect but 1px off are punished by PSNR/SSIM, which is why results‚Ä¶ https://t.co/bSvu8V3ym7",0,0
2016-10-29 22:12:45,@newakamo @github The latest super-resolution research is going beyond PSNR/SSIM because there's not much left ther‚Ä¶ https://t.co/P1hrxpz72D,0,0
2016-10-29 22:04:28,@matesteinforth @SEHSUCHT @github Not bad! I should really train a model for upscaling cartoons/sketches/drawings ;-),1,0
2016-10-29 22:00:47,"For large images, the #NeuralEnhance code should probably split up large  images into multiple windows then stitch‚Ä¶ https://t.co/f8mSzQl6nY",9,2
2016-10-29 21:48:25,@dribnet Were the compression-like artefacts generated by the network or Twitter? Otherwise it's reasonable.,1,0
2016-10-29 21:46:30,I trained #NeuralEnhance on 300k HD images from the OpenImage dataset from Flickr. (Input scale choice makes a big‚Ä¶ https://t.co/Uz2SNd6mKn,16,5
2016-10-29 21:43:26,"@bkaradzic If it outputs an image that looks somewhat like the original, then it worked. Quality is a different problem...",1,0
2016-10-29 21:42:18,"Thinking of training a #NeuralEnhance 1x that just fixes compression artefacts, noisy pixels, and other blurring. (Just set --scales=0.)",5,2
2016-10-29 21:40:44,If you have blurry/noisy/glitchy photos ‚Äî or other types of images ‚Äî find as many examples as you can and train a new model with same code!,4,1
2016-10-29 21:39:13,"The default models with #NeuralEnhance are trained on HD photos from Flickr. Things that look similar work great, the rest won't so much...",7,7
2016-10-29 21:34:17,@bkaradzic The more similar your photo is to the training set (OpenImages from Flickr) the better it will work. May‚Ä¶ https://t.co/fymCma3Nkz,2,0
2016-10-29 21:32:58,@sterlingcrispin @olivercameron #NeuralEnhance only injects crisp edges or high-frequency detail where it recognize‚Ä¶ https://t.co/rViPHLjI4t,3,0
2016-10-29 21:31:30,"@hardmaru @edersantana That's also the top comment on /r/MachineLearning. If the training data is similar, it shoul‚Ä¶ https://t.co/plFUqapJTr",4,0
2016-10-29 21:28:49,@sterlingcrispin @olivercameron What were you expecting to see in that example?,0,0
2016-10-29 21:26:14,"@sterlingcrispin Yes, I tried it on games too. The results are reasonable! (We discussed it a few weeks ago, conclu‚Ä¶ https://t.co/J8oPM3D1NE",0,0
2016-10-29 21:24:52,@my2k @WilliamChyr @olivercameron The model available for download is not trained on paintings but I could do that‚Ä¶ https://t.co/A87kN38ved,3,0
2016-10-29 20:48:58,@holocronweaver Optimized like what and under what metrics? If you use traditional PSNR/SSIM it's likely worse beca‚Ä¶ https://t.co/QWQYRLpORA,0,0
2016-10-29 20:45:38,"Hehe, I wrote the code and spent weeks tweaking the parameters and still don't believe the results. Crazy! https://t.co/b0TTF3Voyo",181,68
2016-10-29 20:37:57,@Larryfilter @snerber @Tigersharke @fotobus @soframel Very cool! Any idea how long it takes for the plugin to be ap‚Ä¶ https://t.co/LMcIrkBPAz,0,0
2016-10-29 19:09:36,"@lucaswiman Optimist: Legal system is adversarial setup, it picks up on new tricks pretty quickly.
Cynic: Just anot‚Ä¶ https://t.co/c0OXzrlDy0",0,1
2016-10-29 15:59:59,My reply on HN about scaling super-resolution networks to get better results. https://t.co/daLqLcrfVr https://t.co/c9yR2G8ulO,5,2
2016-10-29 15:38:23,@DaveChurchill Haven't compared with waifu2x yet; need to find out what dataset they used for training to compare.‚Ä¶ https://t.co/QAZU12gsB4,0,0
2016-10-29 15:35:38,@DaveChurchill It's around this level of quality: https://t.co/MwKde7Y8sA Doesn't inject as much high-frequency det‚Ä¶ https://t.co/nt7iikYJAT,0,0
2016-10-29 13:59:43,"@17facet @hardmaru Don't know exactly, will check at PC later. See layer sizes and compressed 16-bit version on GitHub.",0,0
2016-10-29 13:38:06,"@17facet @hardmaru Depends on model size, a function of generalizability. Could be realtime if specialized.",0,0
2016-10-29 12:31:48,@dribnet I also recently changed the adversary loss to use softplus (no NaN errors) and it likely requires some tun‚Ä¶ https://t.co/Ccd2TzMJHS,0,0
2016-10-29 12:29:54,"@dribnet In case you reached the adversarial training part, I dropped the adversary weight in README: could be too high for some datasets.",0,0
2016-10-29 12:29:02,".@github Couple of bugs fixed, thanks for reports! I'll try to find time to work on the Docker image later...",1,1
2016-10-29 12:26:49,"@hardmaru @github Yeah, some things it does surprise me too! (Thanks for pointing it out, fixed the references in README ;-)",2,0
2016-10-29 12:25:48,.@github But it's 2016. Got to have those GIFs ;-) Here's comparison from a photo of a bank in London. Full compari‚Ä¶ https://t.co/wC2dm6noLW,5,3
2016-10-29 12:23:26,.@github I figured anyone that's either a hacker or experienced in the field would check original 24-bit HD images‚Ä¶ https://t.co/cMpMEmVJqE,1,0
2016-10-29 12:22:14,".@github Took some criticism for showing pixelated vs. upscaled comparison, but it was expected &amp; on purpose: only‚Ä¶ https://t.co/dYDj18K6SX",1,0
2016-10-29 12:21:13,.@github Hacker news discussion about #NeuralEnhance. Very positive overall and encouraging: https://t.co/H0ELwPbefR,11,4
2016-10-29 10:36:50,@marcosalvi There was a paper applying such a loss to neural-style for video. Not sure about the details from memory but I'd start there...,0,0
2016-10-29 10:26:16,"@marcosalvi I haven't tried yet, if not: a) could use some temporal blend/anti-aliasing, b) needs to be trained wit‚Ä¶ https://t.co/cGdWoc6OlX",0,0
2016-10-29 09:58:10,"@Smerity @heyaudy @DeepForger When I have time I'll turn it into a more Art-centric bot, taking nice images from sp‚Ä¶ https://t.co/hDT8LPk7qp",2,0
2016-10-29 09:21:15,@htoyryla I'm on my phone and can't tell if you posted the original accidentally!,0,0
2016-10-29 08:39:57,"@lucaswiman As long as judges understand it's basically lying, should give lawyers less room to wiggle.",1,0
2016-10-29 07:35:07,".@github This is a great sign, it works on someone else's machine ;-) Lots of questions, answering with‚Ä¶ https://t.co/QfCK1TSbzR",6,0
2016-10-29 07:32:35,"@hardmaru @dribnet That said, I've learned a lot since then, worth another try. Maybe also increasing GAN weight to‚Ä¶ https://t.co/2T2qqMQilk",2,0
2016-10-29 07:31:51,@dribnet I have data but it was trained with older version of code so may not be compatible. May need to retrain wh‚Ä¶ https://t.co/PINVrN9GUk,0,0
2016-10-29 07:30:01,@cmarschner The online demo of #NeuralEnhance is trained for general photos; the more different the worse the resul‚Ä¶ https://t.co/3QCXbp5Hem,0,0
2016-10-29 07:28:36,@cmarschner I haven't trained this version of #NeuralEnhance to hallucinate too much: makes for good single-image d‚Ä¶ https://t.co/eGV6P1UltX,1,0
2016-10-29 07:27:36,@heyaudy People can always retweet to spread the message. That's what @DeepForger did and still got 2 copyright str‚Ä¶ https://t.co/NjJ6LYoRSn,2,0
2016-10-29 07:26:59,"@newakamo @github On #NeuralEnhance GitHub page, the photos of old station, Hong Kong, and bank lobby are out of da‚Ä¶ https://t.co/2wCTELUjvi",0,0
2016-10-29 07:25:23,@JonOlick The performance of #NeuralEnhance depends on the size of the model. It tested from 4 residual (x2) blocks‚Ä¶ https://t.co/aoe6Qss86T,0,0
2016-10-29 07:23:19,@edersantana @heyaudy @DeepForger If you can build one of those I'd love to try it ;-),0,0
2016-10-29 07:22:55,"@mokafolio The #NeuralEnhance demos actually saved JPG files, so the size isn't too big. Maybe the compression level is a bit too high!",0,0
2016-10-29 07:20:50,"@hardmaru @dribnet I tried this, that was my original intention! There was not enough information contained in the‚Ä¶ https://t.co/VnGtnRr7vO",1,0
2016-10-29 07:19:39,"@msfeldstein Ah, #NeuralEnhance is hardcoded to train from files in dataset/*/*.jpg. Either edit that or put your f‚Ä¶ https://t.co/XqL94lp51P",1,0
2016-10-29 00:01:31,"@heyaudy Image reply bots are done until Twitter fixes things, IMHO. There's no way you can moderate the trolling/s‚Ä¶ https://t.co/TDIF3WhdjE",1,0
2016-10-28 23:59:48,"@nueluno Yes, it's the same code. The site is running on the ""medium"" model that I included in the GitHub release.",2,0
2016-10-28 23:58:22,".@github It's not the easiest thing to get up-and-running if you're not into deep learning, but I'll make time for‚Ä¶ https://t.co/zTHUa2eqR9",6,0
2016-10-28 23:55:24,".@github I included a few trained models for comparison (performance / results), but need to retrain them with the‚Ä¶ https://t.co/wSzUt4yb1n",2,0
2016-10-28 23:51:24,.@github This time I actually measured the actual lines of code: 332. It's pretty crazy what you can do these days.‚Ä¶ https://t.co/J5A32yAgur,7,1
2016-10-28 23:46:14,".@github I've been tweaking &amp; tuning this code for weeks; I suspect there's a lot of room left for improvement, but‚Ä¶ https://t.co/cJk32LhcIm",5,2
2016-10-28 23:44:52,#NeuralEnhance lets you apply 4x super-resolution to your photos CSI-style in only 340 lines of code!‚Ä¶ https://t.co/jDvd7HcaBh,479,264
2016-10-28 13:14:37,There's also high probability that AI/ML can help non-creative artists ;-) They're more likely to be the early adop‚Ä¶ https://t.co/qdpiAvTZrM,20,2
2016-10-28 07:37:13,"@Woodgate Ah, OK. Well just FYI it's currently broken. Reviews on the plugin page on Mozilla suggests since around September?",0,0
2016-10-28 07:34:21,"@Woodgate Twitter is constantly changing its layout, so I presume that broke the plugin? But maybe it's Firefox updates.",0,0
2016-10-28 02:52:44,"From now on, when I imagine procedural music generators I'm going to think of this... https://t.co/63E1pqL3rx",8,5
2016-10-28 02:46:18,@Brombadil @graphific I think of YouTube as video hosting for edited videos (+ poor comments). I'd be surprised if‚Ä¶ https://t.co/Lq5qI8kWZi,0,0
2016-10-28 01:51:22,@Woodgate Hi! Love(d) the LarryFilter. Are you still supporting it? It doesn't seem to work on recent changes. Is the code public?,0,0
2016-10-28 01:38:49,Detecting People in Artwork with CNNs https://t.co/WSSGd3JDjf Includes new #PeopleArt dataset:‚Ä¶ https://t.co/Ou7oWEqpKw,73,51
2016-10-28 01:22:16,"@halhod @graphific True, also a good selling point for their fancy new phone (given the name) and its fancy camera.",0,0
2016-10-28 01:19:29,"@edersantana @graphific Yeah, this would fit best with their core business! Just Facebook had bigger deep learning‚Ä¶ https://t.co/mzMdeLprHr",0,0
2016-10-28 01:18:35,"@halhod @graphific Ah, Android is like an app somehow but I don't think of it as social. Also never used Google Pho‚Ä¶ https://t.co/lfp4ClJ6ZH",0,0
2016-10-28 01:15:13,"@graphific Google has no social network, they're unlikely to ship anything to end users. It's also a bit of a stretch as a cloud service...",0,0
2016-10-27 19:40:29,@mark_riedl You're right about GDC of course; I doubt corporate conferences could ever turn into a research-oriented community.,0,0
2016-10-27 19:39:40,"@mark_riedl Without looking, I'd guess a significant percentage of papers are from companies. DNN research now spans industry + academia.",1,0
2016-10-27 19:35:38,@mark_riedl The big AI/ML conferences are no longer academic. You can tell by looking at the sponsors‚Äîif there are any ;-),0,0
2016-10-27 18:17:46,https://t.co/IkErvgmtuG #generative https://t.co/c8SlWZN334,14,7
2016-10-27 18:06:14,"@burningion Did they announce Intel CPUs? OpenCL is pretty solid on there, but the ecosystem would have to catch up.",0,0
2016-10-27 16:17:27,@edersantana Not yet! Will check it out later...,0,0
2016-10-27 16:05:07,Mask-Off: Synthesizing Face Images in the Presence of Head-mounted  Displays https://t.co/nh3SZorgCg #AR #VR https://t.co/8FAaR7C5be,60,59
2016-10-27 14:52:45,@mtyka @MauricioM There were some technical &amp; design challenges; it took Prisma to show the quality before they even considered it.,2,0
2016-10-27 12:57:22,@mtrc ;-) Is this saying you have no more emails or none of them are important?,2,0
2016-10-27 12:56:00,@ajmooch Thanks! Maybe could be added to Lasagne? ;-) Have you tried mirror padding upfront (1xN pixels) rather than Nx1 each convolution?,0,0
2016-10-27 11:47:01,"@okayultra If trained on portraits specifically, it does a better job. This one is just for general photos!",0,0
2016-10-27 11:39:01,@alexisheloir It's in the direct reply ;-),0,0
2016-10-27 11:17:16,"@rndbrtrnd Yes, in that case it's loaded from the cache because it's done.",0,0
2016-10-27 11:13:31,@rndbrtrnd They are the steps in the process... Should go from 1-&gt;2-&gt;3 as you complete the process.,0,0
2016-10-27 11:07:27,"@rndbrtrnd A bug ;-) It shows steps of the super-resolution process when you submit again, but since this image is ready it shouldn't show.",0,0
2016-10-27 11:04:51,"@rndbrtrnd Ah, if you want to submit your own image you click bottom left button or title. Then upload a new one...",0,0
2016-10-27 10:58:29,"@rndbrtrnd Maybe the top 2-3 things to improve (except performance, training a faster network now).",0,0
2016-10-27 10:56:41,@doppenhe Lasagne / Theano ;-),1,0
2016-10-27 10:54:29,@doppenhe It's written in Python.,0,0
2016-10-27 10:46:33,"These tweets will self-destruct shortly! Will be releasing soon with code, just need some early stress testing &amp; feedback.",0,1
2016-10-27 10:45:41,"Want to help test a super-resolution demo? Running on CPU with big network, so takes 60s. (GPUs busy training ;-) https://t.co/XUb6rORSKT",15,2
2016-10-27 07:40:23,"Oops, I messed up the link. I have yet to read about ""Fruit Detection and Yield Estimation"" with deep learning ;-) https://t.co/WCR4pW2A1N",1,0
2016-10-27 07:21:18,"1) Facebook is working on mobile style transfer.
2) Zuck is quick to respond to Google stealing the PR limelight!
https://t.co/To4OBnB1NY",22,11
2016-10-27 07:19:01,@MauricioM I didn't see that post but I knew it was coming ;-) Thanks for sending it!,1,0
2016-10-27 07:00:30,Predicting First Impressions with Deep Learning https://t.co/9N5PP9FJuj (Learns to assign 4 scores to faces based o‚Ä¶ https://t.co/SQYF3BJyXV,28,11
2016-10-26 11:20:16,It seems networks require significantly more capacity (maybe larger filters?) to fix the artifacts introduced by this pixelated upscaling.,0,0
2016-10-26 11:18:10,"I tried nearest-neighbor upscaling instead of subpixel convolution on super-resolution, and was rather disappointed. https://t.co/RKVJXg2tGD",3,2
2016-10-26 11:03:48,"11/ Overall, it's an impressive generalization of fast style! Most replies so far are about quality; still room to‚Ä¶ https://t.co/psYtUMakRw",0,2
2016-10-26 11:00:03,10/ I can see why authors used separate blog post to introduce nearest-neighbor upscaling‚Äîit's mentioned as benefit here but not studied.,0,0
2016-10-26 10:57:18,"9/ Final improvement is using nearest-neighbor upscaling rather than deconvolution, as they previously introduced: https://t.co/CmVxjd5unm",1,0
2016-10-26 10:55:20,8/ Another improvement is using reflection for padding all convolution layer inputs. Wonder how much slower this is than zero padding?,1,0
2016-10-26 10:50:45,7/ This means the network can reuse convolution weights (3x3 kernels) and new styles can be retrained quicker with only 0.3% of parameters.,2,0
2016-10-26 10:48:57,"6/ Not only are activations normalized per image, but there are style-specific parameters Œ≥ (multiplier) and Œ≤ (off‚Ä¶ https://t.co/RsD1nQ0blb",3,0
2016-10-26 10:26:21,@ngutten Can't remember the name they used. Need to read it again!,0,0
2016-10-26 10:25:16,"@ngutten One trick from the OpenAI paper is to measure equality at first or second layer of adversary, like lightweight perceptual loss.",0,0
2016-10-26 10:18:49,"@ngutten Ah, I was going to suggest it was a capacity issue‚Äîglad you found it ;-) How does it scale?",0,0
2016-10-26 08:20:30,"5/ The main improvement in paper by @dumoulinv et al. is inspired by Instance Normalization, but now style-specific: https://t.co/J7cWeXCvHY",3,0
2016-10-26 08:09:01,"@yoavgo @hardmaru There exists a subset of paintings whole ""style"" you can mostly capture with these neural representations.",2,0
2016-10-26 08:07:49,"@yoavgo @hardmaru Oh, absolutely. At best it's capturing color and texture, and their global distribution in the image.",1,0
2016-10-26 08:06:03,"8/ Results look good, it seems to help work around distribution glitches imposed by the ""gram-matrix"" representatio‚Ä¶ https://t.co/USJkl07hhJ",3,1
2016-10-26 07:51:44,"7/ Instance Normalization makes sure output at each layer is in same range, so the CNN can learn a local mapping that works globally too.",1,2
2016-10-26 07:48:38,6/ You can see how the optimization is trying to put as many style elements as possible into each image patch. #Prisma designed around this!,0,0
2016-10-26 07:47:09,"5/ As a result, the CNN assumes that the local distribution of style in the image is the same as the global distrib‚Ä¶ https://t.co/vPKgfa5AZH",1,1
2016-10-26 07:44:12,"4/ Because convolution networks process images via local windows (e.g. 3x3 filters), they can't approximate this global distribution.",1,0
2016-10-26 07:41:23,"3/ #NeuralStyle imposes a global distribution of ""style"" elements in the target picture, basically like a sliding puzzle or self-mashup.",1,0
2016-10-26 07:38:07,"2/ It's conceptually similar to batch normalization, which helps DNN learn quicker‚Äîbut in this case fixing a problem caused by #NeuralStyle.",0,0
2016-10-26 07:33:56,1/ The trick in this paper (from July) is now used in open source libraries and as the basis of this new research: https://t.co/ZH7Bfj13gC,5,2
2016-10-26 07:12:46,4/ Here they use an extra residual block and double to 128 channels (1.6M params) plus three improvements that comb‚Ä¶ https://t.co/aDXqh9bEy5,2,0
2016-10-26 07:05:28,"3/ Fundamentally, architecture is very similar to perceptual loss paper, which had 4 residual blocks +encode/decode. https://t.co/QWW4FA2QU1",4,0
2016-10-26 07:00:53,2/ It's still feed-forward; should work in real-time and on mobile. New styles can be trained incrementally with subset of new parameters.,2,0
2016-10-26 06:58:13,"1/ The big idea of this paper is to learn multiple styles with single network, unlike #Prisma that relies on custom networks for each style.",7,0
2016-10-26 06:56:47,A Learned Representation For Artistic Style (via @hardmaru) https://t.co/Qu2NIgaXf3 Feed-forward and multi-style ne‚Ä¶ https://t.co/HMeLDXaJbH,58,31
2016-10-25 18:47:59,@edersantana @vladkol When you have kids the fridge will pose a bigger object recognition task!,3,1
2016-10-25 18:17:37,@syhw Nice coincidence for a deep learning researcher!,2,0
2016-10-25 18:15:15,Does anyone have a fridge that looks like this? Ours is running closer to 100% capacity! ;-) https://t.co/DwsgQOcQ0X,25,5
2016-10-25 15:02:21,@SpectralFilter @Wikisteff @BecomingDataSci The keyword you're looking for is GAN: https://t.co/8rknTC35H1,2,0
2016-10-25 14:10:53,Learning Object Shapes via 3D Generative-Adversarial Modeling https://t.co/si2q2mA5WE Reconstructs IKEA furniture v‚Ä¶ https://t.co/ZtcRf0WmFa,102,49
2016-10-25 06:49:16,"@Wikisteff @BecomingDataSci Getting 100% classification is difficult, but even at probability 0.7 it gives generator a signal to learn from!",1,2
2016-10-25 06:47:54,@Wikisteff @BecomingDataSci It's being done right now! The whole field of generative adversarial networks relies on this idea to help train.,3,2
2016-10-24 07:36:15,@spysamot Not so far. Decaffeination process leaves me suspicious...,0,0
2016-10-24 05:31:01,"@xululululuuum Ran out of options ;-) The bottom option covers ""no caffeine by principle"" and top option is close enough!",1,0
2016-10-23 23:26:46,"@santiontanon Ah, that explains it! (Clicks *Follow* again.)",0,0
2016-10-23 23:25:13,@santiontanon Are you a novelty bot account? :-D,0,0
2016-10-23 23:23:32,@paniq Good idea! https://t.co/MAArXLZ6ZX,3,2
2016-10-23 23:21:59,"@dphrygian I find coffee withdrawal to be hardest; first headaches, then exhaustion and depression for a while. How long does it take you?",0,0
2016-10-23 23:17:28,"@dphrygian Oh, I get the headaches too! Similar when I indulge in sugar then cut it out again. How do you most notice the feeling better?",0,0
2016-10-23 23:13:25,When was the last time you didn't have caffeine for a whole day?,0,0
2016-10-23 23:10:38,"Cut out caffeine since Friday, spent two days mostly sleeping ;-) Almost back to normal, but time seems to be passing slower now!",21,0
2016-10-20 13:27:04,"@graphific @samim Confirmed, my filter doesn't work anymore.",0,0
2016-10-19 10:21:41,"Deep Identity-aware Transfer of Facial Attributes https://t.co/X00y12Ca7D
GAN-powered enhancing of images to remove‚Ä¶ https://t.co/srzyvgBIG2",51,19
2016-10-18 23:03:44,@phelixlau Each arrow is one batch: was the average loss higher or lower than running average?,3,1
2016-10-18 20:54:48,"That moment, over 10h later, when you realize that architectural change really paid off with a new record perceptua‚Ä¶ https://t.co/cKI3vg3t3w",23,5
2016-10-18 19:53:39,"@Seivanheidari Yes! Thought about the combination a lot, they seem orthogonal and very much complementary...",0,0
2016-10-18 12:30:36,@edersantana Depends how deep. Deeper would be worse. Good activation functions (maybe batch_norm) help: https://t.co/k1Vr64CTxm,1,0
2016-10-18 12:13:02,"@edersantana Not yet, but when enlarging it's mostly about initializing with identity preserving transforms‚Äîshould be easy enough.",0,0
2016-10-18 12:12:25,@edersantana https://t.co/flvexk1ESI,1,0
2016-10-18 12:10:51,@edersantana Also training incrementally with net-2-net operations to speed things up and avoid side-effects of huge depth.,1,0
2016-10-18 12:09:51,"@edersantana I'm considering instead initializing the layers to an identity transform, one recursive super-resolution paper did this....",1,0
2016-10-18 12:03:15,@edersantana Not yet. Like adding a gate that's controlled with single parameter? Using PReLU extensively already...,0,0
2016-10-18 11:58:47,@edersantana Number of channels primarily. I'm mostly using 3x3 as a constant except for rare cases of pre- or post-processing.,0,0
2016-10-18 08:08:25,"@wandedob No, I tend not to read those papers. But they do come up when I browse this arXiv category: https://t.co/LUM4hcdpGf Search there?",1,0
2016-10-18 08:04:09,5/ Such applied papers are still worth skimming to get a grasp of related areas. Interesting things can come up! https://t.co/ejheitfN3S,2,0
2016-10-18 08:01:17,lluminant Aware Gamut-Based Color Transfer https://t.co/zXIcdEiXRr [PDF] This one looks generally very useful. Like‚Ä¶ https://t.co/CJn0ZOSzfh,25,8
2016-10-18 07:54:49,"4/ The rest seems like common sense engineering: white balancing, brightness matching, reusing existing algorithms as appropriate.",0,1
2016-10-18 07:50:09,3/ Petra points out some lipstick/hair colors are also terrible combinations: clear reflection of the lack of diversity in this research ;-),5,0
2016-10-18 07:49:07,2/ Almost half the images in the entire paper have obviously wrong aspect ratios. How can they possibly be computer vision researchers?,3,0
2016-10-18 07:47:44,"1/ I want to know who missed the opportunity to call this paper ""Color Transfer meets Mr. &amp; Mrs. Potato Head"" https://t.co/ehYUF3PFbJ",0,0
2016-10-18 07:45:20,Digital Makeup from Internet Images https://t.co/0cYO5Jqzf5 This one is actually not deep learning ;-) #offbrand https://t.co/n10qpC8V62,24,12
2016-10-18 06:57:33,The GAN forces it to hallucinate related textures that it would handle more conservatively otherwise. These would h‚Ä¶ https://t.co/NLoPfyZnjY,3,0
2016-10-18 06:51:47,I've found a convnet with either increased capacity or applied to a narrower problem can learn high-frequency details without an adversary.,2,0
2016-10-18 06:47:47,"However, these textures are not applied consistently to similar areas of the image; they fade out near borders. (Often looks acceptable.)",0,0
2016-10-18 06:45:24,"After another 8h of training 4x super-resolution GAN, hallucinated patterns improved: more variation and context se‚Ä¶ https://t.co/yfYarecnsk",1,1
2016-10-17 22:33:53,"@peter_halasz No, it trains on the same patterns in all images. I should add the gaussian blur everywhere, might help a bit...",1,0
2016-10-17 22:16:29,"Going to let it train overnight‚Äîsee how it goes. Not too optimistic about its usability, creative maybe! @YellowTide https://t.co/Kv5EeqBX0q",2,1
2016-10-17 22:14:08,"@edersantana @peter_halasz Yeah, it's from Justin's perceptual loss paper too (maybe before). He uses sigma=1.0. Need to add it!",1,0
2016-10-17 22:12:40,@peter_halasz My reply made surprising sense considering I thought you replied to a more recent Tweet ;-),0,0
2016-10-17 22:11:40,". @peter_halasz The original image is downsampled 4x, then aliasing patterns are misinterpreted and upscaled to something else plausible.",0,0
2016-10-17 22:07:44,A couple more GAN hallucinations. It's now altering fashion trends and re-positioning garage doors! https://t.co/Q8zHV1Ha2C,7,0
2016-10-17 22:04:23,@peter_halasz Interesting! It's definitely under-trained though at this stage... Going to let it run overnight.,0,0
2016-10-17 21:31:37,I wasn't pleased with contribution of adversarial network for super-resolution so cranked up its weight. It's now h‚Ä¶ https://t.co/fdTpRr1g5Y,32,9
2016-10-17 21:27:36,"@fhuszar @vintermann Thanks! I printed the paper and started working through it, but this makes a lot of sense to my programmer brain ;-)",0,0
2016-10-17 21:08:06,@vintermann It seems Lasagne has an Affine Transformation layer already; their code is Lasagne/Theano too. https://t.co/zGmkBU2J7u,0,0
2016-10-17 20:56:42,"@vintermann I have a super-resolution GAN already, so depending how easy it is to code I could try it out ;-)",0,0
2016-10-17 20:52:45,"@vintermann I started reading it today, yes. Not too familiar with the background research, so a bit slower... What's the neat trick?",0,0
2016-10-17 20:41:56,"21/ In short, there are more questions than answers here. Not yet convinced of this direction (yet) but keen to hear any possible solution!",2,0
2016-10-17 20:39:52,"20/ Anecdotally, learning to fix or learning residual of a bilinear upscale seems like harder problem in super-res: https://t.co/zF3tnjWa6j",2,0
2016-10-17 20:33:05,19/ They mention bilinear rescaling didn't work. I suspect it's because they need double kernel size and bigger + more complex problem.,1,0
2016-10-17 20:30:52,"18/ As a result, you can see low-res jagged edges and subsequent convolution filters trying to fix it. Possibly wor‚Ä¶ https://t.co/YQ1DR8hkfE",0,0
2016-10-17 20:28:14,"17/ In the article, they don't suggest upscaling with transposed convolution: instead rely on nearest neighbor bitmap-like rescaling.",2,0
2016-10-17 20:25:02,"16/ Using 4x4 kernels helps because it's a bit more consistent. Except for padding, 4 blue pixels always used‚Äîbut s‚Ä¶ https://t.co/5sMF9nK4B0",4,0
2016-10-17 19:54:31,"15/ What causes checkerboard is not the inconsistency of input, but the fact they are different weights alternating usage every other pixel.",4,0
2016-10-17 19:52:55,"14/ Sometimes, only 1 real pixel (in blue) contributes to output (in green). Sometimes it's 2, even 4. Each time different weights are used!",6,0
2016-10-17 19:50:56,"13/ Specifically, upscaling deconvolution sucks specifically because it's implemented with zero padding. Look how i‚Ä¶ https://t.co/YvaiyaFwsZ",1,0
2016-10-17 19:47:46,12/ I found the explanations in this article more confusing than @edersantana's post or @dumoulinv's visualizations: https://t.co/hTLtk7dviW,1,0
2016-10-17 19:44:09,11/ The article specifically addresses deconvolution (a transposed conv operation) to upscaling images. Previously: https://t.co/9YXrZIOJg5,3,0
2016-10-17 19:40:23,"10/ For example, residual layers that express output as an additive modification of input tends to reduce artefacts. https://t.co/h9wBNrHI89",1,0
2016-10-17 19:36:20,"9/ The article focuses on second way to solve this is changing the neural network structure, discouraging these patterns from appearing.",1,0
2016-10-17 19:34:49,"8/ Likely total variation would help with most example images, but as you increase the weight it also generally reduces crispness of edges.",2,0
2016-10-17 19:33:00,7/ I think this is one of first papers to mention TV loss: https://t.co/QkC0fyf3Ss but it's not mentioned or compared in the article above.,3,0
2016-10-17 19:30:59,6/ The most common way to reduce artefacts is to include total-variation loss‚Äîencouraging nearby pixels to have similar values.,1,0
2016-10-17 19:23:34,"5/ There are two main ways to fix these checkerboard patterns: a) rework convolution architecture, and b) change problem definition.",2,0
2016-10-17 19:22:12,4/ It's a love-hate relationship for me; forcing these checkerboard away IMHO causes the network capacity to drop‚Äîit's noticeable visually.,2,0
2016-10-17 19:18:48,3/ The fact these patterns emerge naturally in images suggest it's the most effective way to solve the problem. https://t.co/bQkQ4GHFbI,5,0
2016-10-17 19:16:47,"2/ On the flip side, these are also dithering patterns that can improve the image: crisper edges, better blends. https://t.co/OZ8FQMjBlM",3,0
2016-10-17 19:15:08,"1/ It's easy to see checkerboard patterns as an enemy. In the paintings above, for example, it looks terrible and it's clearly a bug.",2,0
2016-10-17 19:09:38,Deconvolution and Checkerboard Artifacts https://t.co/qMLo0MqNEi Important topic for anything neural ‚à© image synthe‚Ä¶ https://t.co/mJDFjterIH,39,6
2016-10-17 12:46:00,@dribnet Cool! New dataset?,0,0
2016-10-15 11:11:23,@robmbrown See these two follow-up Tweets: https://t.co/YeD2ilGbMC,0,0
2016-10-15 09:53:39,"@robmbrown It's mathematically impossible to do 100% correct. It's always going to be an assumption, problem is under-determined.",0,0
2016-10-15 09:45:01,"@robmbrown If you want to present 100% true information, don't super-resolve it. That's the only way...",1,0
2016-10-15 09:44:22,@graphific It's a step towards algorithmic government. Just train the next generation to grow up with this (like Wikipedia) and game over!,1,0
2016-10-15 09:30:07,"@robmbrown I don't know of any research that does this yet, but I don't see the application. If you apply super-resolution, it's cosmetic.",0,0
2016-10-15 09:25:28,"@robmbrown It would require a different design that what I'm using, right now I only request that images look natural and lowres matches.",0,0
2016-10-15 09:24:10,@robmbrown You mean algorithms that don't add *any* detail until it's absolutely sure it's true? (e.g. shadows based on sun position).,0,0
2016-10-15 09:18:57,"@robmbrown Yes, that's what I mean. Any super-resolution process will basically add such details that may not be ground truth.",2,0
2016-10-15 09:11:30,"@robmbrown ""As long as the lowres version looks the same, come up with any highres version that fits the past training set.""",0,0
2016-10-15 09:10:46,"@robmbrown Yes, the upscaling process is 100% hallucination. As neural networks get better, this will increase.",1,0
2016-10-15 09:05:45,"@robmbrown It's standard dataset used for comparison among researchers, but I agree. Would love to see vacation photos, old family pictures.",0,0
2016-10-15 08:23:13,"@lordofthelake Yes, preparing for that incrementally.",4,0
2016-10-15 08:19:05,"@dribnet Likely need to train it on exactly same resolution that you output, then also randomly drop-out entire pixels so it reconstructs.",0,0
2016-10-15 08:17:37,"@dribnet It's one I put together for this project. FYI, upscaling output of your VAE didn't work well yet, effective resolution is low.",1,0
2016-10-14 21:17:46,"Now training on 50k OpenImages from flicker it's not specializing as well in either of those cases, but possibly a bit more general?",8,2
2016-10-14 21:16:15,I got my variation to train from a new HD faces dataset (even more specialized) and that turned out particularly we‚Ä¶ https://t.co/UUgS8zy5Ub,26,2
2016-10-14 21:11:40,"It's trained on 350k ImageNet entries, which feature a lot of cat &amp; dog varieties, so it learned to do hair/fur particularly well ;-) [2/2]",14,3
2016-10-14 21:09:36,Think I figured out why the baboon from this super-resolution paper turned out so well. [1/2]‚Ä¶ https://t.co/PEGnImd1be,19,6
2016-10-14 18:49:08,@MieszkoZ I think 9/10 is the default template text‚Äîeveryone is getting it! Or they simply labelled one example wrong...,1,0
2016-10-14 16:20:28,"@paniq If they are both generated, then one out of two is *very* impressive!",0,0
2016-10-14 16:18:21,"There was only one question with no obvious AI-generated mistakes (IMHO). Picked based on progression, one had flow and the other didn't.",0,0
2016-10-14 16:17:01,"The first phase you need to pick which is which, but the score is not shown. Felt pretty easy: just find notes clearly out of tune.",0,0
2016-10-14 16:15:55,See if you can recognize Bach from AI in this music test. I got 9/10‚Äîcurious which one I missed ;-)‚Ä¶ https://t.co/Fx36IOYFBK,11,8
2016-10-14 15:40:26,@SommerPascal 4x larger in both dimensions.,0,0
2016-10-14 14:28:06,"@void995 Yeah, that's exactly what it is. It's been a while though, can't remember details how ;-)",0,0
2016-10-13 21:09:35,"@mphuget Occasionally run stuff in the cloud. Haven't needed a big upgrade yet, maybe soon...",0,0
2016-10-13 20:55:23,@mphuget It's an old machine upgraded with SSD and with a recent TitanX.,0,0
2016-10-13 20:39:10,@mlascarides Maybe I can take episode two towards fiction ;-),1,0
2016-10-13 20:35:38,"@hideous_ GTAV ;-) It does look cartoon-like, which is why I started using games to test it...",0,0
2016-10-13 20:33:57,This short story was auto-biographical ‚Äî no fiction here ;-) https://t.co/7fClMW7yIc,1,1
2016-10-13 20:28:38,Training a few more convnets for super-resolution. Scaling down now the one with larger capacity works well enough.‚Ä¶ https://t.co/tmY7xLu5p8,9,2
2016-10-13 20:19:39,"We finish hanging up the washing, Petra casually slides the drying rack in front of my deep learning rig: ""The clothes dry better here.""",30,8
2016-10-13 12:23:02,@dougbinks @RichardKogelnig @Donzanoid Bokeh for 2D: https://t.co/ttsc3jpIkf (or d3js wrapper) For 3D not as mature: https://t.co/Y4XROG3HLq,4,0
2016-10-13 07:19:25,"@SparseJacobian One venue is booked though, we'll likely decide within a few weeks and announce in next month(s). Thanks for interest!",1,0
2016-10-13 07:18:16,@SparseJacobian Difficult subject! We were planning to take a break (new project in pipeline) but chairs/attendees/speakers won't let go ;-),1,0
2016-10-13 07:06:43,"@SparseJacobian The only other paper I know in this field is this: https://t.co/M6h1YuUC44 Learning to predict colors, then tree coding.",1,0
2016-10-13 06:59:56,@SparseJacobian @sknthla Still long way to go to beat the more modern video or image codecs. Likely 12 months R&amp;D ;-),0,0
2016-10-13 06:59:16,@SparseJacobian @sknthla Don't read this then ;-) https://t.co/vdNuwEX8Pi,1,0
2016-10-13 06:57:44,"@SparseJacobian @sknthla Yes, there were multiple papers recently (one by Google, comparing to JPG) but only just scratching the surface.",1,0
2016-10-13 06:49:49,"@SparseJacobian @sknthla Another called ""adversarial networks"" https://t.co/MwKde8fJk8 Both are separate NNs used to measure output quality.",1,0
2016-10-13 06:48:12,"@SparseJacobian @sknthla Two recent techniques, one now called ""perceptual loss"" that's best summarized here: https://t.co/bTbPzYYvGK",1,0
2016-10-13 06:39:22,Apparent Display Resolution Enhancement for Moving Images https://t.co/QteYPE7g17 via @jp_axs4ll (Renders different‚Ä¶ https://t.co/WbFH4rVeEV,19,6
2016-10-13 06:31:14,"@SparseJacobian @sknthla It doesn't have to be deep‚Äîlikely just a couple layers, but done in hardware like Hololens could have big impact.",0,0
2016-10-13 06:30:28,"@SparseJacobian @sknthla For starters, stochastic gradient descent can help optimize kernel weights that are still tuned manually for TAA.",0,0
2016-10-13 06:28:57,"@SparseJacobian @sknthla If you undersample, then you save bandwidth and can let specialized ""conv"" hardware (in VR headset) do upscaling.",0,0
2016-10-13 06:27:19,@SparseJacobian People are working on it‚Äîfor reasons that may not be obvious ;-) Original idea is more sensible than you think (see thread).,0,0
2016-10-13 06:21:38,@SparseJacobian @sknthla Did you read the thread? Topic came up in depth. Rendering good dots takes time + manual convolution ops already.,0,0
2016-10-12 22:02:12,@FreneticPony Patch-based approaches could work well here! Some people applied #NeuralDoodle to this...,0,0
2016-10-12 21:52:26,@YS My code just down-scales images then tries to reproduce the original.,0,0
2016-10-12 20:47:54,Looks like stylized post-processing and anti-aliasing of rendered will be powered by #ML soon enough? https://t.co/9QuXCioHyt,5,0
2016-10-12 20:42:31,"@randallb @ericflo That's the question, not 100% clear yet. Read the thread for other perspectives.",2,0
2016-10-12 20:38:01,"@Rob_Bishop @jackclarkSF Yeah, AA is clear. See the discussion in the thread @sknthla linked! Some questions about performance to buy-in.",0,0
2016-10-12 20:36:44,"@YS For training, high-resolution is required. Doesn't need to be the original of the censored version.",1,0
2016-10-12 20:33:49,@Rob_Bishop @sknthla @jackclarkSF I imagine getting buy-in from graphics developers would be tough ;-) Did you get it faster than rendering?,0,0
2016-10-12 20:32:29,"@YS It's not restoring the original image, it's hallucinating detail based on the neural network training and original images in dataset.",0,0
2016-10-12 20:29:01,@Atrix256 @won3d @JonOlick I bet that would work... going to add it to the queue of things to try ;-),0,0
2016-10-12 20:26:40,@jackclarkSF I thought it was video/photo upscaling? With games you *could* render directly at higher resolution... @sknthla @Rob_Bishop,1,0
2016-10-12 20:14:11,"@won3d Don't talk too loud about this, maybe neural nets will bring back interlacing ;-) How did/do people solve this originally?",0,0
2016-10-12 20:11:50,"@won3d Oh, assuming the rest is possible de-interlacing should be easy! Just input two half-height frames and learn convolution weights.",0,0
2016-10-12 20:07:07,"@RH_Hagdahl Today, yes. Though people still do full screen temporal AA. What if we could do 2x upscale + AA for just 10% more compute?",0,0
2016-10-12 20:06:03,"Dedicated neural-inspired silicon that takes current low-res frame and accumulation buffer, displays high-res frame direct on TV or headset.",7,3
2016-10-12 20:04:00,Heard rumors that Hololens' HPU (holographic processing unit) is clever hardware-level image feature extraction. How about same for render?,4,2
2016-10-12 20:02:19,Of course question is whether it's more efficient to generate extra pixels via rendering or upscaling. Dedicated hardware could change this!,2,0
2016-10-12 20:00:37,Reminds me of @dougbinks' dynamic resolution rendering from 2012. See full article here: https://t.co/zxse1F7Nrn https://t.co/hKf7ZBavle,6,2
2016-10-12 19:57:10,"Wondering if it's feasible for games to render at half the resolution, then upscale with convolution networks doing temporal anti-aliasing.",15,7
2016-10-12 17:31:40,@SebAaltonen @fatlimey There's 20Mb of bzip2 data on disk ;-) It's not designed for small size or performance at this stage!,0,0
2016-10-12 17:28:25,"@17facet @BartWronsk I imagine it'd work best with more channels, but smaller resolution. (I'd start with 2x smaller experiment.)",0,0
2016-10-12 17:27:04,"@17facet @BartWronsk Advantage of using gradient-descent is that it could find near-optimal representation for this buffer, even 2x smaller.",1,0
2016-10-12 17:25:34,"@17facet @BartWronsk Gotcha! NN could learn intermediate representation, then combine that with next RGBD frame, output new buffer+RGB w/AA.",3,0
2016-10-12 17:21:04,"@BartWronsk @17facet Recursion is implicit, right? You can just train it as &lt;input buffers&gt; to &lt;output channels&gt; then run it once per frame.",0,0
2016-10-12 17:15:52,"@17facet @BartWronsk I'd just do 2D convolution with two stacked frames as inputs. RNN are indeed a pain to train, also implement in shader?",0,0
2016-10-12 17:14:46,TIL that rendering engines in modern games use expert-crafted convolution for temporal anti-aliasing. Thread: https://t.co/dPMVXfIhlP,39,15
2016-10-12 17:08:24,@17facet @BartWronsk At this stage you'll probably train overnight anyway ;-),0,0
2016-10-12 17:06:56,"@17facet @BartWronsk You could use video and down-sample that, but training NN at different resolution will be less optimal.",0,0
2016-10-12 17:06:21,"@17facet @BartWronsk True, if you can render at that resolution just for training it'd be ideal. (Could be a separate super-charged PC.)",0,0
2016-10-12 17:03:15,"@17facet @BartWronsk Question is if they are free to use by neural network at this stage, and if there's a few more spare channels too ;-)",0,0
2016-10-12 17:01:36,@17facet @BartWronsk It's not that easy. The ideal case is to have perfect photo for each rendered frame...,0,0
2016-10-12 17:00:08,"@BartWronsk @17facet At the stage this anti-aliasing is done, is there spare memory on GPU to use a few extra temporary channels?",0,0
2016-10-12 16:57:35,"It's very real, @Wikisteff! Only ""bug"" is the cartoon-like look, but I picked a good example for that ;-) https://t.co/xHvJtWFSqf",1,1
2016-10-12 16:56:19,"@BartWronsk @17facet Thanks! So in this case, the frames and buffers used as inputs are the same resolution as the output?",0,0
2016-10-12 16:51:40,@BartWronsk @17facet Cool! What's the complexity of your convolutions: kernel size and number of layers/iterations?,0,0
2016-10-12 16:47:33,"@BartWronsk @17facet If it's feasible to keep the previous frame around, then I'm sure the information could help with quality‚Äîat a cost.",1,0
2016-10-12 16:46:04,"@BartWronsk @17facet If it's possible to make regular filters stable, then only need to tell a NN about that objective during training too.",0,0
2016-10-12 16:36:37,". @17facet For real-time anti-aliasing, it'd need to be one or two layers deep at most. It's currently 38 layers deep in total.",4,0
2016-10-12 16:28:01,"@17facet Taking an image of the same resolution, and just fixing/smoothing it up? Should be easy...",1,0
2016-10-12 16:17:25,@IgorBrigadir @quasimondo The original is captured to .GIF ;-),1,0
2016-10-12 15:58:54,"@quasimondo It should already... It does that in places, but I think Twitter makes it look worse.",1,0
2016-10-12 15:58:14,. @aasensior This code is the highest-quality I can make it: 16 residual blocks (2) x 128 filters. I'd have to lower capacity for real-time.,2,0
2016-10-12 15:51:04,"Another example of super-resolution on a video game screenshot. Far from perfect yet but may release soon, let ever‚Ä¶ https://t.co/ekZsg18yfc",20,7
2016-10-12 15:35:12,"@ThePeshwa Yes, subpixel and a few other things. Google's OpenImage dataset, about 50k photos.",0,0
2016-10-12 10:08:07,@alykhantejani licecap of my screen. https://t.co/kgP8aoX2mE The image comparison tool is a Javascript web-page.,3,1
2016-10-12 09:55:24,"@bartwerf I haven't checked yet, likely much more stable than #DeepStyle. Would need additional constraints to be 100% smooth.",0,0
2016-10-12 09:50:08,"Trained a neural network for super-resolution overnight, but results look cartoon-like on certain images. Applying‚Ä¶ https://t.co/DOG6VaLFxj",114,35
2016-10-11 17:27:50,"@CasperKaae OK, I'll give it a try once this run is over ;-) Results great so far, despite code ugliness! https://t.co/3YI9KTC60H",4,0
2016-10-11 17:18:47,@CasperKaae Thanks. It's my first adversarial setup so going through the basics ;-) Most code online uses sigmoid+(hacks or runtime errors).,0,0
2016-10-11 17:05:10,@richardmatthias Congrats? But can you justify the legitimacy of its usage in a single Tweet... ;-),0,0
2016-10-11 15:38:48,@CasperKaae I heard TensorFlow has some safeguards built-in. What are you using?,0,0
2016-10-11 07:57:59,@F_Vaggi I want to know who decided that particular equation was a good idea ;-) It certainly wasn't an engineer!,0,0
2016-10-11 07:40:05,"In theory, there's no difference between theory and practice. In practice, 1E-6. #ml #epsilon https://t.co/9SbdnqxxHN",31,8
2016-10-11 06:50:02,"Deep Pyramidal Residual Networks
- Paper: https://t.co/rruFujxt1U
- Code: https://t.co/ggpcDBo4ws
- TL;DR: Graduall‚Ä¶ https://t.co/EfK8cU9Uhz",107,44
2016-10-11 06:32:35,Convolutional Networks as Models of Generalization and Blending within Visual Creativity https://t.co/Q5hPgg2ZqB‚Ä¶ https://t.co/V3GElXWEL5,31,13
2016-10-10 14:29:36,@quasimondo @muellerfreitag **casually glances at TitanX temperature log to see if it's below 75** Erm...,2,0
2016-10-10 14:23:18,"If user-collected data is the new coal, then generated media is the new oil. /cc @muellerfreitag",6,0
2016-10-10 13:20:45,"@void995 This came up, probably more modern: https://t.co/69RfXrRSI4",0,0
2016-10-10 08:04:49,@hardmaru Sci-Hub ;-) https://t.co/w5OUkJime3,11,1
2016-10-09 12:19:12,"Let me guess, residual networks? ;-) https://t.co/KBhuyKSZG8 https://t.co/5iqb3dftbp",5,4
2016-10-08 08:04:52,"13/ Currently investigating alternatives to ReLU in super-resolution too, I think it's important line of research‚Äîbut that's it for now! EOT",2,2
2016-10-08 08:03:37,"12/ Since ReLU units clamp half their input domain to zero, I found benefits to ELU in many generative applications: https://t.co/k1Vr64CTxm",6,2
2016-10-08 08:01:43,11/ Another fascinating detail I understand better is the use of ELU (exponential linear units) instead of ReLU‚Äîsee‚Ä¶ https://t.co/qZk5SPSIIf,2,3
2016-10-08 07:59:58,"10/ This is an interesting approach to explore, but I have yet to try it or understand why it's better ;-) https://t.co/ayZgt2N6yz",0,1
2016-10-08 07:58:01,"9/ This paper instead uses an equation derived here https://t.co/Y9ZDSMDyGs, based on SSIM metric but using simplif‚Ä¶ https://t.co/xD5uihvZr1",2,1
2016-10-08 07:54:18,"8/ Image synthesis papers increasingly use ""perceptual loss""‚Äîusing pre-trained NN to measure reconstruction quality: https://t.co/AvlXjjusHH",2,1
2016-10-08 07:49:29,"7/ They train both left and right stereo images together, solving three different objectives at the same time (reco‚Ä¶ https://t.co/u54t6qi8JZ",7,3
2016-10-08 07:45:38,6/ The solution is to compute a disparity map specifying how pixels should be warped‚Äîinspired by optical flow paper‚Ä¶ https://t.co/JcrBLoh6cu,5,3
2016-10-08 07:37:05,5/ This particular paper solves depth problem by learning to reconstruct one of two stereo images from the other wi‚Ä¶ https://t.co/62NH6S7nr3,4,2
2016-10-08 07:32:26,"4/ It seems pre-historic (/s ;-) computer vision approaches rely on unsupervised techniques, expert tuned equations? https://t.co/ScsEqxRtKK",1,1
2016-10-08 07:29:40,"3/ For completeness, there's apparently another deep learning paper that learns depth unsupervised, via @ankurhandos https://t.co/YrdkNUSTyH",1,2
2016-10-08 07:26:40,"@Michcioperz It's not just you, 57% so far ;-)",0,0
2016-10-08 07:24:25,"What year was https://t.co/tDlW5a4UOf founded, guess without looking it up:",3,1
2016-10-07 19:15:54,"2/ Traditionally, depth estimation is done with supervised learning from depth sensors, or using video game hacks! https://t.co/g9YfQrgU8X",14,7
2016-10-07 19:13:14,1/ I'm looking into depth estimation based on the advice of @edersantana. Insights are different yet applicable to any image transformation.,9,3
2016-10-07 19:11:37,"Unsupervised Monocular Depth Estimation w/ Left-Right Consistency https://t.co/daPVQYa9qn Boring title, fascinating‚Ä¶ https://t.co/pGPUNE1ULN",97,31
2016-10-07 18:36:35,@ElMarcel Next time! I'm in the airport now. Are you around‚Äîfor future reference?,0,0
2016-10-07 18:23:06,Berlin is an incredibly vibrant city. I'm still amazed at low price of coffee! Won't be another 10 years until my next visit hopefully.. #‚öò,3,0
2016-10-07 18:20:06,This seemed like the ideal post-ironic place to spend the afternoon in Berlin with @graphific and @samim. https://t.co/L8SC1S2LZr,14,1
2016-10-06 15:03:00,". @azeem compares the AI industry to the (unethical) sugar industry. ""We all convince ourselves its for the greater good, read TechCrunch.""",1,0
2016-10-06 14:51:13,Watching @azeem deliver an inspiring talk about exponential growth and AI. Appropriate #disco light in background! https://t.co/TKQmpUg9Ee,7,0
2016-10-06 07:17:36,In Berlin. Construction everywhere! Busy today but some time tomorrow if any locals want to meet and chat ;-) https://t.co/cGrzSSF2m7,12,0
2016-10-06 03:52:23,Visualizing an erosion algorithm on a procedural landscape. #procgen https://t.co/ythS9kA1BA https://t.co/vpNJXm8RzB,40,12
2016-10-05 14:05:43,@mike_preuss Many thanks! /cc @jurieongames Mike fixed those links posted by @AiGameDev bot ;-),0,0
2016-10-05 06:13:45,@edersantana I think it took me over a month to feel truly comfortable :-/,2,0
2016-10-04 22:23:25,"If you ever worried there won't be jobs in the future, watch this guy helping robots train‚Äîforever. (Next decade in‚Ä¶ https://t.co/Zcol1TnH2B",54,33
2016-10-04 20:45:52,"@edersantana I did the same thing! It'll be straining at first, don't push too hard. Memorize keys on paper and quit qwerty cold turkey.",3,0
2016-10-04 20:39:33,"@edersantana Cool! Did you pop the keys and put them back in, or buy a DVORAK keyboard?",0,0
2016-10-04 12:14:24,There's a horror movie in this somewhere... #robotics https://t.co/PajXL6VTbb https://t.co/EShcRIRaaJ,22,7
2016-10-04 10:22:49,"@mike_preuss Many thanks! Have a great day, speak to you tomorrow :-P",0,0
2016-10-04 10:04:51,Justin released his fast-neural-style source code in #Torch. https://t.co/V2ShTiHTjy With TitanX can do 4 models in‚Ä¶ https://t.co/ZGlecnooeE,286,152
2016-10-04 09:33:15,"@bergi_bergos I'm looking into domain-specialized SR now, lots of potential! Could also ship few custom layers of weights, rest standard.",0,0
2016-10-04 08:53:53,"@mike_preuss It's automated, can't easily change all the old links. Can you add a redirect?",0,0
2016-10-04 08:40:53,"@mike_preuss It's heavy rain here, but cool projects going on indoors ;-) Taking it from old URLs, is there new one? https://t.co/9Coiy3ddSb",0,0
2016-10-04 08:22:35,"@mike_preuss Indeed, good morning! How's your day? I get redirect to here with incognito window and no cookies: https://t.co/Q04GOCVSKR",0,0
2016-10-04 08:09:22,"@mike_preuss Hi Mike, seems like the CIG proceedings from 2014 redirect &amp; require login again. Sorry to bother! https://t.co/9Coiy3ddSb",0,0
2016-10-04 07:59:38,"@Miles_Brundage It's always very loaded on Tuesdays, going to take a loot at my topics now ;-)",1,0
2016-10-03 21:50:32,"Creative coding with the kids earlier, procedurally animating a flower. Yes it was fun; I think I secretly like Jav‚Ä¶ https://t.co/gYfPFctWuc",14,0
2016-10-03 16:00:26,"@stevedekorte In the real-time game sense, there's not much to read. For traditional games like backgammon? Look up TD-Gammon, AlphaGo.",0,0
2016-10-03 15:57:35,"@stevedekorte @dmimno ""assuming they can track them"" is the part that's not really done today with any deep networks.",1,0
2016-10-03 15:53:20,@stevedekorte @dmimno Even when driving (or in a video) the system gets one label and has to figure out the rest on its own.,0,0
2016-10-03 15:29:10,@stevedekorte @dmimno You know how many labels you give them. Unsupervised is less clear!,0,0
2016-10-03 13:29:39,"Full report ""Civil Law Rules on Robotics"" to the European Parliament is online: https://t.co/RGXmfi9dVs Thanks‚Ä¶ https://t.co/xwe0Q1CeI9",3,1
2016-10-03 13:21:39,@tomlebrun_IA Thanks for reporting! Is the original report online?,1,0
2016-10-03 13:19:49,"European Parliament report demands establishing criteria for what constitutes ""autonomous intellectual creation"" #AI https://t.co/hiiIvFljXt",7,2
2016-10-03 12:52:14,"@Thomas_Wint True, though the further labeling is unsupervised.",1,0
2016-10-03 11:37:43,I suspect convolution for generating 1D sequences will progress quickly. It seems a more intuitive architecture to work with! @genekogan,5,1
2016-10-03 11:15:43,With toddlers you only need to correct them a few times for them to learn; for a neural network you'd need another‚Ä¶ https://t.co/rcVL41oWOX,20,4
2016-10-02 22:55:23,"@Wikisteff If there are other images of similar type, should be possible!",1,0
2016-10-02 22:36:42,@KaiLashArul I'm tweaking a few other things for large (more representative) networks. I will do another comparison then!,1,0
2016-10-02 22:29:15,"@KaiLashArul 3x3 subpixel is equivalent to 6x6 transposed, which fails to train in same iterations. 4x4 is simpler, converged sooner? [2/2]",0,0
2016-10-02 22:27:09,"@KaiLashArul As you increase network complexity, subpixel is easier to train: better quality and also faster. [1/2]",0,0
2016-10-02 22:18:06,Links to HD datasets used for evaluating super-resolution algorithms: https://t.co/5QPh5XX2kB (Been told I should p‚Ä¶ https://t.co/2uKXBUQF1s,22,1
2016-10-02 20:25:24,@CasualEffects That's my new dataset... I'll see if I can scrape Flickr for landscapes or something ;-),3,0
2016-10-02 18:49:25,"@hideous_ As I said, it's overfitting. It's just learning those images by heart!",1,0
2016-10-02 18:45:20,"@hideous_ Yeah, it is. I'm mind-blown...",0,0
2016-10-02 18:45:06,@saltyhorse Me too! Sylvester?,1,0
2016-10-02 18:38:40,My hypothesis was I could train a highly specialized super-resolution network and get great results at 4x. Think it could work 8x almost!,4,0
2016-10-02 18:32:02,I let my super-resolution NN overfit on 15 images. It's got amazingly good at doing those 8x. Still can't believe i‚Ä¶ https://t.co/2jTJGryDkg,30,3
2016-10-02 16:13:56,"@edersantana @soumithchintala The receptive fields for the 4 combined sub-pixels would be the same on left side, for right side not sure...",0,0
2016-10-02 16:00:20,@edersantana @soumithchintala Does the view() resolve into this for-loop? Looks deceptively simple in Torch. https://t.co/JbI4bewoos,1,0
2016-10-02 14:40:25,Switched to sub-pixel neural layer and now doing 8x super-resolution. This is before doing anything interesting. Or‚Ä¶ https://t.co/4ebSaSAndw,22,2
2016-10-02 14:36:14,"@edersantana :-) The Tweet following this was out-of-sequence, so this is hidden in thread view. Not perfect yet! https://t.co/1PI1WMyL78",1,0
2016-10-02 14:06:46,"I'm using Andrew's Lasagne/Theano implementation of a sub-pixel layer. Really clean code, haven't benchmarked it: https://t.co/Bs5qiBHtkc",2,1
2016-10-02 13:52:47,"@q33r4 Don't know, it's from my close-ups of famous people dataset! https://t.co/jRK28kM6kh",1,0
2016-10-02 13:47:16,"For 3x double rescaling, the subpixel 3x3 deconv (left) trains faster than transposed deconv 6x6 but slower than tr‚Ä¶ https://t.co/kwmxpi8ePz",1,0
2016-10-02 13:41:14,8x super-resolution test with deconvolution NN only. Here 3x3 sub-pixel layer and then transposed convolution filte‚Ä¶ https://t.co/jHpE4RWIxU,4,0
2016-10-02 11:57:08,"Extra reason why everyone should switch to subpixel layers: means you don't need to worry too much about padding, get better results faster!",4,2
2016-10-02 11:53:48,"Just noticed my new visualizations for 4x4 and 6x6 have incorrect padding: top&amp;left -1 pixel, right&amp;bottom+1 pixel. https://t.co/VNaiswrYfT",1,1
2016-10-02 10:38:41,TL;DR to get transposed convolutions to work as well as subpixel layer you need large filter size &amp; better plan for padding. But nobody did!,1,0
2016-10-02 10:36:30,"Obviously zero-padding for 6x6 kernel size is even worse, and quality would degrade compared to subpixel unless it's specifically addressed.",2,0
2016-10-02 10:34:55,"To get same receptive field with transposed convolution at double scale, you need 6x6 kernel size‚Äîequivalent to 3x3‚Ä¶ https://t.co/MQeeZYFu9a",3,0
2016-10-02 10:18:59,"With sub-pixel layer, *each* output pixel gets input from 3x3 input pixels‚Äîwith only 1 pixel padding required. This is why it's better IMHO!",5,0
2016-10-02 10:17:10,"The down side of bigger kernels is that they need more padding, and if you zero pad the buffer it biases the results towards the mean.",3,1
2016-10-02 10:15:14,"2x2 kernels can only learn nearest pixel upscaling, but 4x4 (my favorite) can do bilinear again without asymmetrica‚Ä¶ https://t.co/Wnjc79cPpT",5,0
2016-10-02 09:43:44,"3x3 kernels can learn bilinear interpolation, but if you want to double output size needs extra padding‚Äîcausing ble‚Ä¶ https://t.co/Mo8wthaha8",7,0
2016-10-02 09:09:48,This inconsistency explains why 3x3 transposed convolution isn't great: an inconsistent numbers of input pixels contribute to output.,3,0
2016-10-02 09:07:49,The white cells in GIF above are zeros filled in automatically between pixels. Weights in 3x3 filter are used selectively on 1-4 real pixel.,2,0
2016-10-02 09:05:38,"Going to explain why using this convolution visualization, also in Eder's post. Here's 2x upscaling with 3x3 filter‚Ä¶ https://t.co/gYdciUxm6M",9,2
2016-10-02 09:01:22,"Not only does it train in fewer epochs, but the resulting images are cleaner too. I struggled with this, and I don't think it's addressed.",0,1
2016-10-02 08:59:30,"Now @edersantana's repository goes beyond validating it's equivalent/faster, it makes the case subpixel is better. https://t.co/lwG5oLoPrg",6,1
2016-10-02 08:56:33,"The question asked is ""Is the deconvolution layer the same as a convolutional layer?"" and the answer seems to be, surprisingly, ""Yes?""",3,0
2016-10-02 08:51:39,"The authors also followed up with short note recently, comparing classic transposed convolution with new sub-pixel:‚Ä¶ https://t.co/xhsR7nsnmS",12,2
2016-10-02 08:47:40,"Section 3.3.1 has a study about the quality of the filters, along with visualizations, and indeed sub-pixel layer l‚Ä¶ https://t.co/YkmDKMXX9w",3,0
2016-10-02 08:46:14,"The original paper focused most on performance: you can process images in low-resolution, then use sub-pixel layer to turn it HD very fast!",1,1
2016-10-02 08:42:52,"It takes the new sub-pixel layer from this paper earlier this year, updated here: https://t.co/Lym1VleUTS https://t.co/EBaSEgl5Hu",10,4
2016-10-02 08:38:14,ICYMI. This repository may hold one of the biggest contributions to deep generative models this year: https://t.co/J7nBig7tKq,84,27
2016-10-01 21:53:52,"@trustswz Does SRGAN use the sub-pixel de-convolution too? Working on a version, how long does SRGAN take to train? ;-)",1,0
2016-10-01 17:39:43,@logicalerror It's a bug I can't explain yet! Should learning simple input/output mapping.,0,0
2016-10-01 17:21:16,"@quasimondo Wait... ""It's Creative AI!"" Am I doing that right?",4,0
2016-10-01 17:17:48,https://t.co/uLTTkpsMkJ,0,2
2016-10-01 17:05:48,"Cleaned up my super-resolution code, looks much better now! Downside is something broke I think, can't tell for sur‚Ä¶ https://t.co/G8O9giwOce",13,2
2016-10-01 14:50:41,"@algotrading_raf I'm not 100% sure, but it's basically a feedback loop that probably just blows up over 10 iterations.",0,0
2016-10-01 09:30:32,@dribnet @fchollet Time to scrape them all and setup a torrent?,6,0
2016-09-30 23:19:19,@shahidkamal Worth a try! Might be more applicable on MIDI files than the raw WAV ;-),1,0
2016-09-30 23:18:53,"@shahidkamal For continuous data and music, see DeepMind's WaveNet.",1,0
2016-09-30 23:13:56,@shahidkamal Most of the examples on the GitHub page are 2D... it's continuous data I'm not sure about. Project seems like grammar model?,1,0
2016-09-30 20:43:14,"Generating good skin/lip patterns seems to be easy. Harder is smoothing jagged edges on silhouette, teeth, and faci‚Ä¶ https://t.co/PIvoMqJvZr",0,0
2016-09-30 20:32:03,"@marmalade_tim Can't explain it fully ;-) I'm using another NN to help train it, and that has rough similarities with human visual cortex.",1,0
2016-09-30 20:30:53,"In this case, I'm not enforcing a smoothness constraint: it's mostly adversarial. Wanted to see how it would emerge ;-)",1,0
2016-09-30 20:26:18,"Generative NN often (for me :-) learn ""dithering"" patterns as a loophole, it makes good use of neurons. Now they ar‚Ä¶ https://t.co/rhwwylxs25",4,1
2016-09-30 20:23:28,"The adversarial setup means training another NN (called discriminator) against the upscaler, learning to distinguish output from originals.",1,0
2016-09-30 20:21:31,"Integrated adversarial loss for my 4x face upscaler, then thought ""it's surprisingly stable""‚Äîthen boom. Interesting‚Ä¶ https://t.co/qrhe5raiiG",9,2
2016-09-30 17:54:59,"Didn't spend very long on it, but the large strides at the input level made the output very noisy‚Äîfamiliar ""dithering"" patterns but worse.",1,1
2016-09-30 17:52:46,Has anyone had any luck with #NeuralStyle transfer using Google's Inception architecture? They mention it in the bl‚Ä¶ https://t.co/OztyAwJQgv,4,3
2016-09-30 17:09:30,"@Izzimach Yes, possibly. It seems to be patch-based but with some experimentation it could work!",0,0
2016-09-30 15:12:51,"""Requires no more up-front work than Markov techniques, but produces results on par with an L-grammar."" #procgen‚Ä¶ https://t.co/jBf4U9rZts",95,51
2016-09-30 13:20:34,@bchjam It's still a pivot ;-),0,0
2016-09-30 12:27:04,"&gt; You are in the headquarters of a global megacorp trying to buy an AI advantage by running a community competition.
FIND EXIT",6,0
2016-09-30 12:24:58,"Opposite alternative and equally valid approach is to focus on storytelling: the more asymmetrical the conversation, the easier technically.",1,0
2016-09-30 12:21:47,"*20 minutes and 1 second later*
- Alexa: OK, your time's up. See you next week?
- Human: Thanks for listening! It's good to talk.",4,0
2016-09-30 12:18:46,"- Eliz^H Alexa: What do you think about this election?
*13 minutes later*
- Alexa: Oh, tell me about your relationship with your [dad|mom]!",2,0
2016-09-30 12:16:25,I suspect the winner of this competition will have strong focus on psychology and interaction design. Work around t‚Ä¶ https://t.co/oU2ZxXQcMV,14,2
2016-09-30 07:54:11,"@Swayson MOOCs always had value for education, but the market the companies/VCs foresaw when investing was not there...",1,0
2016-09-30 07:49:42,You know the MOOC fad is over now Udacity is pivoting into self-driving cars... https://t.co/uTh5tQM8Hu,12,0
2016-09-29 23:37:52,@edersantana No but it's funny as hell ;-),0,0
2016-09-29 23:35:44,"@edersantana You need to put a #PAI logo in there somewhere, because ethics.",0,0
2016-09-29 22:51:28,@ekuber That part of my personality comes out in the evenings ;-),1,0
2016-09-29 22:35:41,"Deep down I suspect the residual approach (for image generation) is easier to train, but is a much worse use of the network's capacity.",0,0
2016-09-29 22:33:36,Output from traditional NN at only 40% capacity of residual. It's dithering because it lost a regularizer (residual‚Ä¶ https://t.co/WJSShVeiqL,3,0
2016-09-29 22:05:28,"@edersantana I'll keep you posted, currently combining 2-3 papers in my super-resolution experiments ;-)",1,0
2016-09-29 21:52:49,"@edersantana Is there a Keras layer for the sub-pixel stuff yet? ;-) Also, by ""deconv"" you meant transposed ops we just talked about?",1,0
2016-09-29 21:23:58,Expressing the problem in residual form constrains output heavily; each layer produces features similar to input. It's a strong regularizer.,3,0
2016-09-29 21:19:24,"This NN uses ""residual"" blocks: it learns what changes need to be applied to the image features to make it look more like a hi-res face.",1,1
2016-09-29 21:14:55,"More faces upscaled 4x with deep convolution network. Not yet found satisfactory fix to desaturation, but otherwise‚Ä¶ https://t.co/DxratdRPf5",20,1
2016-09-29 21:04:29,@edersantana Hrm. Is this a placeholder / hack or is there really no other way to implement this aside the sub-pixel shuffling trick?,0,0
2016-09-29 19:46:37,@edersantana In Lasagne there's no zero padding: https://t.co/Zi9USeTZdd Is at the Theano level?,0,0
2016-09-29 18:15:48,"@edersantana In Lasagne, I thought transposed conv. was just running the code convolution code in reverse (backward pass is forward pass).",0,0
2016-09-29 18:12:36,"@edersantana Then I'm not using that deconv ;-) I'm using transposed convolution (2x upscale), then regular convolution (3x3).",0,0
2016-09-29 18:05:38,"@edersantana Yes, have you seen that before? Any ideas about the cause? Various minor changes reduce the effect...",0,0
2016-09-29 17:45:31,"The latest setup of the convolution network has ""decided"" to generate overlapping circles around each original low-‚Ä¶ https://t.co/Y5LSY2j3oi",5,2
2016-09-29 17:30:23,"@M_PF @graphific The 2016 batch of convolution-based solutions are better currently. Caveat for mugshots, it's injecting generative detail.",1,0
2016-09-29 17:23:18,"@cgeorgewilliams Not yet, only 36h of experimenting and training so far. It will be hopefully once done ;-)",0,0
2016-09-29 16:58:57,"@cgeorgewilliams Yes, of course ;-) There are few unique layer types, many have same settings others have shared parameters even!",0,0
2016-09-29 15:57:38,"The two buggy layers still tried to fix problem (via dithering) and last layer also by trying to smooth things out, but too limited scope.",0,0
2016-09-29 15:55:34,"@sneakin Yeah, a human can see them as legos but combining them together is not a task for a neural network‚Äîyet?",0,0
2016-09-29 15:50:09,"Turns out I made mistakes in layers N-2 and N-1 (one parameter wrong), and they were throwing out all the hard work of previous 36 layers.",4,0
2016-09-29 15:46:33,"Simple color mapping could help with colors (thanks @quasimondo), but I should fix the loss function in first place: https://t.co/avb9tMxlS0",2,0
2016-09-29 12:26:29,"@quasimondo Cool! If I pre-train it with different parameters the saturation is fine, which papers recommend anyway.",1,0
2016-09-29 12:22:27,@JonOlick The one I want to fix first is visible on skin between pupil and eyebrow.,0,0
2016-09-29 11:59:09,@Soukhinov Desaturation is a know problem with E2E deep learning for super-resolution: https://t.co/UniefImZOt,1,0
2016-09-29 11:46:22,"Twitter's JPG ultra-compress the dithering patterns away, so why should I fix that ;-) Trains quite quickly, now may need to scale up!",4,1
2016-09-29 11:44:38,Training a convolution network for 4x upscaling of faces-only. Some progress but desaturation and dithering pattern‚Ä¶ https://t.co/Jvj3gBZIpx,45,14
2016-09-29 09:47:51,"This is a great book name hack! Right now, I exclusively want to get it because of Christopher Alexander's ""A Patte‚Ä¶ https://t.co/KN2eOxfjCo",13,1
2016-09-29 08:46:06,"@cupe_cupe @nuclai Ah, I used whatever was in our shared Drive. You can send a link to the final directly if you want.",0,0
2016-09-29 08:31:54,"@cupe_cupe @nuclai Fixing the layout will take a bit of time, we'll tweet it after it's done.",0,0
2016-09-29 08:30:31,Trying to move forward but some old problems resurfaced today‚Äîall at the same time somehow! https://t.co/SahFG4gQtq,3,0
2016-09-29 08:10:58,"@cupe_cupe @nuclai Done. Need to fix the ""Coming Soon"" box on the top right though ;-)",1,0
2016-09-28 21:34:22,"@davegershgorn Thought same thing. How can it not be? This new initiative is clearly a PR counter-punch, OpenAI stole show since last year.",1,0
2016-09-28 21:29:12,"@graphific If they offloaded this and didn't check the content reflected their views, I have even less faith in the initiative.",1,0
2016-09-28 21:23:51,"@graphific Even if they fix the wording, whatever caused that sentence to first emerge will still be there! I have little faith here...",1,0
2016-09-28 21:21:01,"A non-profit AI marketing initiative: ""we're here to make sure you agree nothing can go wrong.""‚Ä¶ https://t.co/U2fDpq6uID",2,0
2016-09-28 17:27:43,@xDirtyPunkx @richardmatthias It's closer to ASCII art than Haskell.,2,0
2016-09-28 13:16:17,@danofer Oh! Did you find the report/paper?,0,0
2016-09-27 21:07:30,"@syhw Yeah, I had that code before. New equation has a few more things to tune, no standard rules yet...",1,0
2016-09-27 21:00:20,"@graphific Open PDF, read cryptic latex equation, decrypt paragraph below, write one line of code, tune for 3h, regret it. That?",2,0
2016-09-27 20:22:52,"My previous approach to control learning rate was a hack! Now I can claim it's something formal and ""state-of-the-art"". Few percent better.",8,0
2016-09-27 20:21:31,"Also integrated this equation to control learning rate. Not as impressive as I expected, lots of tuning too... https://t.co/HHDV07KtKz",13,0
2016-09-27 18:43:43,"@ankurhandos I mean the recursive approach. I have tried various residual architectures with mixed results, from a few Lasagne repositories.",1,0
2016-09-27 18:42:40,"The residual approach acts as strong regularizer to smooth image, it avoids these dithering patterns‚Äîwhich now requ‚Ä¶ https://t.co/iTDmY8XJKM",1,0
2016-09-27 18:38:49,"I tried common residual representation, but they are much harder and slower to train... New one trains in minutes! https://t.co/jvnsZVPcPP",0,0
2016-09-27 18:36:29,"No, I'm not clipping the gradients but batch_norm everywhere, trial &amp; error experiments for weight initialization. https://t.co/wbLzuug2qv",0,0
2016-09-27 18:35:12,I'm manually creating a sequence of conv. layers with shared weights‚Äîwhich reduces the parameter space and helps in train much quicker.,0,0
2016-09-27 18:32:41,Just integrated this recursive convolution technique to a super-resolution prototype. I'm very impressed! https://t.co/OKbmqVHgby,19,7
2016-09-27 17:42:29,"@raudelmil The Atari Deep Reinforcement solutions use 4 frames as input, it allows basic prediction, etc.",0,0
2016-09-27 17:14:44,"@raudelmil Yes, it would need one variable to know it is in the ""strafing state"" if you assume the same direction same time ;-)",0,0
2016-09-27 16:43:48,@SommerPascal It's true. Though only one piece of data would be necessary for it to learn how to follow a single plan (strafe target).,0,0
2016-09-27 09:56:22,@drtowerstein Always in collaborations... Otherwise Step 1) textbook ;-] Step 2) find willing subjects.,0,0
2016-09-27 09:53:10,"@drtowerstein I have no idea, I want to know more about psychology in HR but you can't find any textbooks ;-) I guess it's not common then?",0,0
2016-09-27 09:44:51,@drtowerstein It's more for improving my team management / dynamics.,0,0
2016-09-27 09:43:32,"@drtowerstein I tend / try to stay on top of practitioner books, but you gave me the impression psychology side (from research) was ignored.",0,0
2016-09-27 09:39:56,"@drtowerstein Interesting read! No, I haven't yet.",0,0
2016-09-27 09:33:45,"@drtowerstein HR or anything related to hiring, team dynamics, leadership.",0,0
2016-09-27 09:29:52,"@drtowerstein Yeah, anything that backs up the claim that theory is far ahead of practice. I'm afraid of missing out ;-)",0,0
2016-09-27 09:26:07,"@l4rz It's a world-wide competition with online submissions, winners from U.S.-based companies.",0,0
2016-09-27 09:15:15,"@drtowerstein Thanks! You mentioned a textbook? I'm looking for summary of overwhelmingly accepted beliefs in the field, not single studies.",0,0
2016-09-27 09:08:21,@codeandrew Schmysics.,0,0
2016-09-27 09:00:20,@codeandrew 2021 will be a good year!,0,0
2016-09-27 08:57:12,"@mjntendency Well-designed arena combat games have incredible depth, there's room left but diminishing returns and hard to notice for most!",1,0
2016-09-27 08:47:15,I'm actually surprised press coverage was not more negative. It has to be a concern‚Äînow big companies are onboard! https://t.co/4kFroElHJG,4,1
2016-09-27 08:34:52,"TL;DR of most of my technical Tweets: ""they trained a neural network to do something better than we could before."" https://t.co/N7YqSzMGWp",20,8
2016-09-27 08:26:16,@mittense @nothings ;-) They're just trained a big-ass neural network from raw pixels to raw actions in Doom; plays better than most humans.,2,2
2016-09-27 08:22:25,The fact it learns from raw pixels would be classed as nothing short of a miracle 5 years ago. @nothings https://t.co/jADjAk2wV5,8,3
2016-09-27 08:20:29,"Maybe there were theoretical insights, but Facebook Research won ""limited deathmatch"" too‚Äîso differentiator was engineering &amp; computation?",0,0
2016-09-27 08:15:31,"With everything that happened building up to this (Atari, AlphaGo, maze following) it ended up not appearing like such a big achievement!",0,0
2016-09-27 08:14:52,"Overall, I'd say it's an above average human player‚Äîbut below experienced gamer. It doesn't dodge much or circle strafe, no obvious tactics.",3,2
2016-09-27 08:12:34,First-person capture of Intel Lab's deep neural network that won the VizDOOM competition 2016 a few days ago: https://t.co/uCfG8kuj9w,17,13
2016-09-26 21:31:21,@notmisha @Miles_Brundage ImageNet solution but trained in 15 minutes on a commodity GPU!,2,0
2016-09-26 21:15:40,@cyberkm @ForrestTheWoods I switched to plain old Dvorak about 10 years ago too ;-) Is the programmer version better?,1,0
2016-09-26 20:40:22,Just because the cost of task X is falling (thanks to AI) doesn't mean the whole market around X will shrink or collapse‚Äîon the contrary.,6,1
2016-09-26 19:55:44,"Writing this mostly for future reference, so I can reflect on my Tweet timeline when the project unexpectedly:",1,0
2016-09-26 19:50:52,Intense day on upcoming top-secret project. Over-delivering by 300% is exhausting and energizing at the same time! #‚öò,10,0
2016-09-26 19:05:38,@tombielecki Yes. https://t.co/Od2POGNPOI,1,0
2016-09-26 17:29:13,@McFunkypants for Twitter CEO!,2,0
2016-09-26 17:21:55,@nueluno @samim Thanks! Still experimenting with format. If there's anything in particular you'd like to see let me know ;-),0,0
2016-09-26 17:10:04,@nueluno @samim It's a hobby project so I don't think they've studied the amount of novelty yet... Worth downloading to try!,0,0
2016-09-26 17:03:45,"@nueluno @samim The whole video is generated from a neural network's learned abstractions, not a collage or blend of existing images.",1,0
2016-09-26 16:47:51,@nueluno @samim Do you have a link/paper?,0,0
2016-09-26 14:29:25,"@TweetEdMiller Not 3D quite yet, 2D video generation?",0,0
2016-09-26 14:21:40,"@TweetEdMiller Most ""deconv"" operations are in fact convolution backwards; the correct name is ""transposed"" convolution. Same idea really!",1,0
2016-09-26 14:20:36,"8/ Here's a video of cycling through the different subjects from dataset, and changing the emotions: https://t.co/JhUZHQjCmF",2,1
2016-09-26 14:17:11,7/ Everything suggests we could have great generative models today if we just increased GPU/NN capacity‚Äîassuming gradient descent holds up!,5,1
2016-09-26 14:14:57,"@gameism I mean one NPC, typo!",0,0
2016-09-26 14:14:26,"6/ The increased resolution comes at the cost of not being able to generalize as well, e.g. to different orientatio‚Ä¶ https://t.co/Db5LohgBpA",3,1
2016-09-26 14:13:02,"5/ But also, b) there are only 67 subjects in the dataset with many emotions/orientations. Easy to overfit! https://t.co/ubxwcRC9iG",4,1
2016-09-26 14:10:38,4/ I think success is due to: a) using new higher-resolution dataset with very clean white backgrounds. NN only learns relevant information.,2,1
2016-09-26 14:08:25,"3/ In this case, there's blurring but it *still* looks acceptable and &gt;2x higher-resolution than previous attempts (max. 256).",4,0
2016-09-26 14:07:14,"2/ If you followed my tweets about super-resolution, you know that MSE causes blurred outputs (visible above). Fix: https://t.co/2WiaN0M2SX",3,2
2016-09-26 14:04:57,1/ It works by loading portrait meta-data (used as inputs) and images (as target outputs) and does supervised training with MSE error.,2,1
2016-09-26 13:53:55,@gameism Makes things easier ;-) Would you mix both in once NPC?,0,0
2016-09-26 13:53:07,"Generating and Animating Faces with Deconvolution Networks https://t.co/mDsK9iktiO 512x640 resolution, new record?‚Ä¶ https://t.co/ARMkoHUJMK",166,77
2016-09-26 12:19:00,"@richardmatthias ""Mess of state"" is the exact opposite problem of ""Mess of logic"" that FSMs have. I think they are cousins.",0,0
2016-09-26 12:18:08,@richardmatthias Even better ;-) My first production BT had an FSM node but I should have just said I was too busy ‚Äî figured it out later.,0,0
2016-09-26 12:12:41,"@tenpn Oh, I agree. I think the other two have many downsides as well, so you pay for the overhead that caused 3 to fail.",1,0
2016-09-26 12:04:41,"@TrAIthlon Yeah, I like that approach. But does it require the team-size of an Ubisoft to have enough AI coders at hand? ;-)",1,0
2016-09-26 12:03:34,@tenpn Do you think the third option should / could have worked somehow?,0,0
2016-09-26 11:54:53,"@SaffronCR Yes, don't get me started ;-) Currently reviewing a submission about this... it's well written but I have opposite opinion.",1,0
2016-09-26 11:53:12,@SaffronCR I think that's what I'd do as well :-D,1,0
2016-09-26 11:50:36,@SaffronCR The point I will make later (once results arrive) is that those tools are sometimes incompatible; one answer is an anti-pattern.,1,0
2016-09-26 11:49:50,"@SaffronCR Yeah ;-) Question assumes you had BT already. I assume most BT developers will have run into this question, hence the poll.",0,0
2016-09-26 11:42:32,@okayultra Teach the designer who came to you.,0,0
2016-09-26 11:31:09,@JoeyMFaulkner Try to build a stealth-game Guard AI in a simple top-down environment.,1,0
2016-09-26 11:30:34,@weballergy I think what we're seeing is a structural change. Not much more room for progress on top task. But only time will tell ;-),0,0
2016-09-26 11:27:07,@McOmghall You can make a sequences of actions loop... but structurally they are direct acyclic graphs.,1,0
2016-09-26 11:26:13,For those non-#gamedev: you could put almost any code into a branch of BTs. That doesn't mean you should... https://t.co/p7ms5FA3us [PDF],7,2
2016-09-26 11:16:08,"You are a #GameAI programmer, writing a behavior tree (BT). Designer asks you for a finite state machine (FSM) in one place, what do you do?",5,2
2016-09-26 10:55:31,"16% improvement over last year, 3% improvement since February. They should make a ""limited training resources"" version of the competition.",7,0
2016-09-26 10:42:51,A plateau in performance is expected as we approach or surpass human levels. Some other tasks in comp. still have room for big improvements!,3,0
2016-09-26 10:40:02,"Multi-ResNet was published on arXiv just a few weeks ago. However, in the competition it performs similarly to top 10 other submissions...",1,0
2016-09-26 10:37:57,"As @masoudabdi13 points out, FAIR's results are ""modularized multi-way extension of ResNet"" similar to this: https://t.co/GBIPUCegBD",2,1
2016-09-26 10:28:20,It's possible that innovators prefer to publish on arXiv first (e.g. Wide ResNet) and let others with more GPU resources compete ImageNet.,3,0
2016-09-26 10:19:13,"Results still getting incrementally better, but this year mostly applying ensembles of existing architectures. Last year: ResNet breakthru.",4,1
2016-09-26 10:04:37,Hard to shake feeling that deep learning for image tasks has reached a plateau this year. How long will it last? https://t.co/WSmySr0iUR,19,3
2016-09-26 07:28:14,@s_bura @kylebrussell You're going to automate expertise just like they're doing with truck driving? Will watch when they release video!,0,0
2016-09-26 07:23:03,"@s_bura @kylebrussell Unless you build up the relationship, this ""trustworthy"" ""expert"" can simply ignore your email or Tweet ;-)",1,0
2016-09-25 14:22:12,6/ Then the best matching edges are refitted onto the target image. (Glad they have great visualizations in the pap‚Ä¶ https://t.co/zGmOiPCgVw,3,0
2016-09-25 14:20:23,"5/ Around each edge, they build parametric maps (""paramap"") to capture a rectangular region around the edge. https://t.co/gZ3JcgvE5N",6,0
2016-09-25 14:17:56,"4/ To match image regions, the edges are extracted from images in patches of 32x32‚Äîdone in parallel for extra speed. https://t.co/nbPsnQ1FX6",4,0
2016-09-25 14:13:17,"3/ The paper cheats a bit by pre-selecting 12 relevant example images. It's less computation, could scale that up w‚Ä¶ https://t.co/64HUd266pD",1,0
2016-09-25 14:11:23,2/ This works so well at injecting detail into low-resolution images thanks to a database of reference images to draw examples from.,5,1
2016-09-25 14:08:27,"1/ Unlike most of the other papers I post, this isn't based on machine learning or E2E deep neural networks. It's h‚Ä¶ https://t.co/t8tcxJMbdF",8,3
2016-09-25 14:07:24,"Hyper-Resolution: Image Detail Reconstruction through Parametric Edges https://t.co/H1coJRJ2OJ 11 years old, still‚Ä¶ https://t.co/kWQCXeToGS",41,10
2016-09-25 13:40:05,"@steverockan @CasualEffects I think it's the opposite way around, building number of shapes up incrementally rather than simplifying.",0,0
2016-09-25 09:03:56,"@samim @FogleBird Cool, I thought it looked familiar!",0,0
2016-09-25 08:50:34,"Reproducing images with vector primitives (optimization, hill climbing). https://t.co/EQ2k7lt0TA by @FogleBird https://t.co/PhIUOo2wIa",94,52
2016-09-24 21:04:22,@shahidkamal Can you bring me up to speed on bytebeat? Only just discovered Sporth now...,1,0
2016-09-24 21:03:38,Sometimes you stumble on alien-like technology and wonder what hit you! This bot is exploring an impressive space: https://t.co/bESg8VHAO8,7,4
2016-09-24 20:57:43,"Brian is primarily built around the Sporth stack language, which borrows many fundamental ideas from the modular sy‚Ä¶ https://t.co/hjWoFwyVIN",8,0
2016-09-24 20:56:22,"""Brian will not write symphonies, doesn't use MIDI, doesn't care about pop music."" But impressive procedural sounds: https://t.co/10GSQ0dkaA",10,0
2016-09-24 19:29:33,When your language model isn't very good and you try to brand it as #CreativeAI ;-) Great post by @deliprao!‚Ä¶ https://t.co/1abhQ44oFA,59,24
2016-09-23 16:09:51,@gpakosz Links still count for me. Images and polls don't.,0,0
2016-09-23 15:24:14,"@poolio I haven't yet looked at the paper yet, thanks! That should speed things up if it works out ;-)",0,0
2016-09-23 13:50:36,@nerdworldorder I think Stochastic Depth Network of depth=N becomes more shallow and wider implicitly because of dropping out layers.,1,0
2016-09-23 13:29:04,"6/ There's still a benefit to depth, but residual representation reduces this benefit IMHO. 1,000 depth isn't significantly better than 100.",5,0
2016-09-23 13:27:30,"5/ This partly answers the question if F(x_l) could just as easily be a parallel residual block, like this: https://t.co/GBIPUCegBD",2,0
2016-09-23 13:22:28,"4/ A particularly interesting bits though was the evolution of model for &gt;1000 layer ResNets, it becomes ""additive""‚Ä¶ https://t.co/H2Ird3SCj4",3,0
2016-09-23 13:19:44,3/ Not sure where that leaves academic conferences! I suspect most of audience found 75% of He's talk obvious from paper and derived work.,1,0
2016-09-23 13:18:19,2/ It's amazing to watch academia and industry move so quickly on ResNets. So many implementations and derived research despite this.,1,1
2016-09-23 13:17:21,"1/ Technically, He was presenting a tutorial on a technique that had yet to be officially published (paper at CVPR2016).",3,1
2016-09-23 13:15:17,"Watching this #ICML2016 tutorial by Kaiming He, of residual network fame, ""Deep Learning Gets Way Deeper"". https://t.co/MQ3LFUbhWj",28,6
2016-09-23 11:58:40,"Found via /r/ProceduralGeneration: https://t.co/69WmNSzVWi
Here's one of the Ruby scripts in full: https://t.co/AqybKkADLB",6,0
2016-09-23 11:57:19,"Procedural Drum Loops for Lazy Composers https://t.co/EaclXsBY9t
A ""generative score"" in Ruby picks instrument/rhyt‚Ä¶ https://t.co/w6or358M0m",18,5
2016-09-23 09:43:16,Impressive shader effect! Feels like style transfer but much faster ;-) @tuan_kuranes https://t.co/EGN20t9042,26,7
2016-09-23 08:33:44,"@MadmanWithPie If you go back in my timeline there are indeed lots of 4x super-resolution algorithms, even better than waifu2x now.",0,0
2016-09-23 08:31:30,"@MadmanWithPie Yes, it's realtime but not very high resolution yet...",0,0
2016-09-23 08:27:49,"Neural Photo Editing project source, built with Theano and Lasagne and includes training+sampling code: https://t.co/NOMG4IjPJL",9,4
2016-09-23 08:26:19,"@anders_breakin There's some research in progress for this, quality is not great but it's getting there.",0,0
2016-09-23 08:18:22,Neural Photo Editing with Introspective Adversarial Networks https://t.co/YrSnthlFAn (Paper + Video) #ml #hci https://t.co/qzQbDLnDT5,297,157
2016-09-23 07:54:47,"@drtowerstein @skittlesolives I think I need textbook to get started, summarizing overall research rather than individual papers. Favorite?",0,0
2016-09-23 07:47:16,@drtowerstein @skittlesolives I mean theory being useful beyond studies with 10 participating students ;-),0,0
2016-09-23 07:30:57,"@drtowerstein @skittlesolives Oh, I mean the gap in the other direction ;-) But I'd love some book names that you think are applicable!",0,0
2016-09-23 07:22:12,@drtowerstein @skittlesolives Any book in particular? I perceived the gap between theory and practice to be very big until you mentioned it.,0,0
2016-09-23 06:49:01,@edersantana @_DaveSullivan I've been thinking about this too! Big challenge would be keeping photo parts consistent (color/lighting/fog).,2,0
2016-09-23 05:46:57,"@xiaojidan2011 Scroll up through the thread, right at the top before reply 1/.",0,0
2016-09-22 18:26:22,Playing around with Wordnet's synsets. It's more fun than expected ;-) https://t.co/6v2GjJzKeJ,8,2
2016-09-22 18:00:30,"@yoavgo Depends on X? ""next level of &lt;technique&gt;"" sounds incremental, ""next level of &lt;domain&gt;"" sounds innovative.",4,0
2016-09-22 16:05:13,11/ I've been pondering all day how all this relates to style transfer... some ideas brewing! Their edge detection‚Ä¶ https://t.co/lyoZBfhYJ2,8,1
2016-09-22 15:19:34,@skittlesolives Lesson #3 here: https://t.co/kmuA9MCQEB,2,2
2016-09-22 15:17:52,@skittlesolives I read cool article recently about someone optimizing for the best experience of candidates they rejected. Let me see...,0,0
2016-09-22 14:06:35,"@deptstorespook @nrose It's not just popular, it's customized to you. There's feedback when you like a Tweet... Also button to dislike.",0,0
2016-09-22 14:03:59,"@alanmnichol No, sorry. Watching remotely ;-) Will be traveling a lot in the next few months though (Berlin) so we might intersect!",1,0
2016-09-22 13:53:37,"Animation of my iterations over the doodle. Changing the ""semantic map"" affects quality of the outcome‚Äîobviously... https://t.co/n3q9BuMOTu",8,3
2016-09-22 13:52:19,"Then obviously I had to try it out, and a few iterations later I put it into the paper itself :-) https://t.co/HRwGT0JWMc",2,0
2016-09-22 13:51:33,Somehow appropriate for that example to be posted on Twitter. It all started out with a joke by @jordnb! https://t.co/ssd7EniYDd,1,0
2016-09-22 13:49:36,"#NeuralDoodle makes an appearance at #reworkDL, presentation by @DmitryUlyanovML. https://t.co/XzU4Ah6uRW",4,1
2016-09-22 13:19:39,"As @nrose points out, RL is a key part of their ""While You Were Away"" system. I blocked that part out... https://t.co/ztXUMbj7KP",3,0
2016-09-22 11:50:16,"@mark_riedl Yeah, I see what you mean. I suspect innovations outside of Twitter will outpace them internally though, it's small budget.",1,0
2016-09-22 11:37:59,@mark_riedl I wondered that... But then they'd be hiring the wrong people for their core business IMHO. (This was an intern project tho.),0,0
2016-09-22 11:23:25,@botminds @spysamot For sure. I just don't expect that to come from Twitter...,1,0
2016-09-22 10:38:48,"@spysamot I don't think so, they'll lag behind the DeepMinds and the OpenAIs. This was done by an intern anyway, so not strategic.",1,0
2016-09-22 10:32:14,"@spysamot Twitter should reuse whatever the community comes up with (they can do it faster), except for core business (img/text).",1,0
2016-09-22 10:29:22,"@spysamot Twitter doesn't need AI, it needs pattern recognition and maybe some pattern generation. But first a clear plan for business!",1,0
2016-09-22 10:20:52,@quasimondo I have wondered about this before! @samim How do you measure your mood?,1,0
2016-09-22 10:11:25,"@ivanassen In blog post, they say ""Twitter invests in novel state-of-the-art machine learning methods to improve the quality of products.""",1,0
2016-09-22 09:37:41,"@y0b1byte Haha, when you fix it does it improve?",0,0
2016-09-22 09:36:05,"It's possible such initiatives could help hiring, but that wouldn't be as relevant for business as (images|text) √ó (processing|generation).",2,0
2016-09-22 09:34:13,@y0b1byte It was an externally submitted entry for a contest at Dagstuhl. I don't know that bot's code and it's not really maintained...,0,0
2016-09-22 09:33:28,This is beyond exploratory research... Best justification I found is helping to promote Torch against strong competition from TensorFlow.,2,0
2016-09-22 09:29:29,What are the benefits for Twitter of working on reinforcement learning and releasing a framework for it? https://t.co/ggbZ4tGOrJ,12,1
2016-09-22 09:11:30,"10/ This direction is interesting for training convolution-only networks faster. Statistically, few sampled pixels per image are required!",1,0
2016-09-22 09:04:50,"9/ I suspect pixel-level predictions could improve by using deeper/wider/denser network (or more residual), but tha‚Ä¶ https://t.co/Eob3JAfmGA",2,1
2016-09-22 09:02:49,"8/ For more background on this approach, see ""Network In Network"" paper from 2013. Used quite frequently these days! https://t.co/znvLOumMfi",1,0
2016-09-22 09:00:29,"7/ For each pixel, they architecture is a simple multi-layer perceptron of 4096x4096x1‚Äîequivalent to 1x1 convolution with *many* channels.",0,0
2016-09-22 08:57:50,"6/ Because memory usage and more ""statistically efficient"" datasets means better training, prediction improves too‚Ä¶ https://t.co/biHgN8VyLf",1,0
2016-09-22 08:53:29,"5/ Sparse sampling is useful at prediction-time, but also at training time. Statistically, only around 2,000 pixels are needed per image.",0,0
2016-09-22 08:52:29,"4/ Here, they implement a new layer to perform sparse sampling of hypercolumns without having to rescale all feature maps. Saves 20x memory!",3,0
2016-09-22 08:45:08,"3/ It's even worse if you need to train more layers on top to perform segmentation, edge-detection, normal prediction‚Äîanything per-pixel.",0,0
2016-09-22 08:43:27,"2/ Hypercolumns capture many properties of pixels &amp; neighborhoods, but expensive to compute and memory intense (must rescale feature maps).",3,0
2016-09-22 08:39:15,"1/ This paper is based on the idea of hypercolumns, expressing multi-level multi-scale features for each pixel.‚Ä¶ https://t.co/1QroEGkYhZ",6,2
2016-09-22 08:32:27,"PixelNet: Towards a General Pixel-Level Architecture https://t.co/HyE57xT0cL Insightful paper, incremental improvem‚Ä¶ https://t.co/ejku9Ek3Tk",66,21
2016-09-22 07:54:48,@domipheus Best of luck with your new ventures! Keep us posted ;-),1,0
2016-09-22 07:22:32,Animated visualizations of convolution operations used in deep learning. https://t.co/hTLtk7dviW (via /r/MachineLea‚Ä¶ https://t.co/pxWoINIq3T,29,14
2016-09-21 14:59:59,"@unicodemonkey Yeah, I don't enjoy people using auto-correct either. It's more authentic and manually crafted without ;-)",1,0
2016-09-21 14:03:35,"OK, fair enough. I may need to remove 1) from the list... @bchjam https://t.co/3amBv4eum7",0,0
2016-09-21 13:55:16,"An exhaustive list of the things Google gets positive coverage for:
1) A.I. / Machine Learning

https://t.co/bT6PRk8PTp",9,0
2016-09-20 19:00:08,@YadFaeq I haven't noticed any issues with Theano performance except compilation step (but worth it). It's more about training problems.,1,0
2016-09-20 18:26:05,15/ You'll notice that MSE+VGG22 result in dithering patterns typical of generative neural models. The GAN loss fixes that; easy to detect?,0,0
2016-09-20 18:24:43,14/ Now browsing through newly released PNG outputs for all algorithm variations. Fascinating to see! via @LedigChr‚Ä¶ https://t.co/uwlzawShIZ,2,0
2016-09-20 16:34:38,@jurieongames Sure if you do it by hand.,1,0
2016-09-20 15:32:31,Perfect illustration why perceptual models are important when it comes to procedural generation: #procgen https://t.co/ykQsyXCmPm,27,4
2016-09-20 13:16:19,@mtrc @mjntendency Do you know the broken window theory? What's going to happen to the whole lab!,1,0
2016-09-20 12:59:45,"Notice, for historical reasons, how #CreativeAI is currently about 2.5% of the whole AI startup space. https://t.co/eRFOYSdFPS",23,3
2016-09-20 12:51:28,@gcpascutto So around TitanX performance? Curious to see the price then!,0,0
2016-09-20 12:35:43,@gcpascutto This is good news. So the only thing that's missing is good OpenCL support in deep learning frameworks?,0,0
2016-09-20 07:34:16,"Source for ""SeqGAN: Sequence Generative Adversarial Nets w/ Policy Gradient"" https://t.co/KDj5gZ4LIk on GitHub:‚Ä¶ https://t.co/HQTsU25t8k",33,7
2016-09-20 06:55:01,"@chrisnovello So while my filters remove most non-professional, design/technical topics, Twitter still makes it insensitive to ignore those.",2,0
2016-09-20 06:53:45,@chrisnovello Twitter exposes those communications more than Instagram/snapchat. World isn't great but platform magnifies it to ridiculous.,1,0
2016-09-20 06:11:44,M-m-m-multi Residual Networks https://t.co/BuvGKZuivE New architecture variant outperforms wide resnets with fewer‚Ä¶ https://t.co/xC2idFckdw,28,10
2016-09-19 17:56:00,"Austrians joke that things are 10 years behind, but HDMI was standardized in 2003 and this venue was renovated late‚Ä¶ https://t.co/i3donRkDsc",2,0
2016-09-19 17:53:26,@jurieongames ;-) Renovated less than 3 years ago! It's the TU south of MQ.,0,0
2016-09-19 17:50:50,You might be surprised to hear we found a public venue for ~400 people in Vienna that has an HDMI projector ;-) https://t.co/D7lDQ3EqVX,8,0
2016-09-19 14:47:47,"@glouppe Oh, I see. Curious to see updated statistics!",0,0
2016-09-19 14:43:24,"@glouppe Back in 2009. Submissions are all scheduled and released in batches each day now, you don't get much choice AFAICT.",0,0
2016-09-19 12:58:55,"@NewoGame Lots of things have been built with planners, less familiar with DbC though‚Äîseems like language support lacks.",0,0
2016-09-19 12:28:45,@bchjam That's my impression too. Surprised to see so few cross references!,1,0
2016-09-19 12:10:42,"@bchjam The DbC frameworks I checked rely on it only at execution time, basically procedurally. Have you seen any theorem provers using DbC?",0,0
2016-09-19 09:46:32,"@bowie7070 Otherwise, I agree with your analogy. I wonder if it was invented in parallel without much cross-pollination.",0,0
2016-09-19 09:46:03,"@bowie7070 In terms of authoring the pre-conditions and post-conditions, in both cases it's done by a human‚Äîjust used differently.",0,0
2016-09-19 09:13:38,"Superficially, both rely on pre-conditions and post-conditions (sometimes, invariants); is the first procedural and second declarative?",1,0
2016-09-19 09:12:05,Question for Programming Language Geeks ‚à© A.I. Enthusiasts: what are similarities/differences between Design-by-Contract and planners?,4,3
2016-09-18 10:22:11,https://t.co/fGHtaX5F1W,3,0
2016-09-17 19:09:30,"@DamageOnAHit Sorry, I don't know so much about the real-time aspect or formats suited to this. I'm doing YUV but not real-time.",0,0
2016-09-17 19:08:39,@deliprao I think it's only for startups that are very liquid.,3,0
2016-09-17 09:08:15,"@inconvergent
1) Solve the halting problem.
2) Make generative bot.
3) ...",1,1
2016-09-17 09:00:59,"@inconvergent Yes, sounds cool. I'd make it the same bot (displaying randomness) but either way would work!",0,0
2016-09-17 08:47:09,"@inconvergent ;-) But glitches make the bot fun! Can you add more of them, maybe some you don't expect?",2,0
2016-09-17 07:09:57,"@volkuleshov @fhuszar This other project is 16x16 only, likely uses fully connected layers. The new one is convolution-only, any res works.",0,0
2016-09-16 14:59:38,@newakamo High-level and low-level.,0,0
2016-09-16 14:37:19,Also thanks to @ngutten for helping dig up the paper by Dosovitskiy that I couldn't find anymore ;-) https://t.co/2TmQCyPIvY,1,0
2016-09-16 14:35:50,#FF @trustswz @fhuszar (two of the authors). Great response to comments here and on Reddit: https://t.co/lwSCJTqcVJ https://t.co/Pa8rOfsLwg,5,1
2016-09-16 08:53:46,@trustswz @fhuszar Thanks. Other papers didn't use batch-norm and noticed various desaturation or hue shift artifacts. Looks OK here!,1,0
2016-09-16 08:48:13,"@trustswz @fhuszar You mean the training would diverge? What weight update rule are you using, plain SGD+momentum?",0,0
2016-09-16 08:46:51,"@fhuszar Hehe, of course. Paper is still solid despite all that ;-)",0,0
2016-09-16 08:37:01,"@fhuszar Cool! Then one other minor issue: page 10 has ""NEEDS TO BE UPDATED"" placeholder text left ;-)",1,0
2016-09-16 08:36:09,@fhuszar Glad to help! Results are very impressive ;-) So there were no major issues to report in training this thing so deep?,1,0
2016-09-16 08:33:07,"13/ I'd like to see better study of tradeoffs for loss components, their weights and capacities. Otherwise mostly best-practice engineering!",4,0
2016-09-16 08:31:44,"12/ In summary, getting super-resolution this impressive was low hanging fruit knowing background research‚Äîand predictably it succeeded.",5,0
2016-09-16 08:27:21,"11/ Other papers claim very deep generative networks are hard to train. Here they do it more sensibly: residual, batch-norm, low-res input.",4,0
2016-09-16 08:24:02,"10/ Overall results are impressive by combining perceptual (HL), adversarial (mid) and total-variation (LL). Exmple: https://t.co/vX5WZ2aNMY",5,1
2016-09-16 08:19:51,9/ The idea is to adversarially learn an alternative to total-variation loss (hard-coded equation) that leaves freedom to inject texture.,0,0
2016-09-16 08:18:40,"8/ I can't find the citation from today's paper to this original paper by Dosovitskiy, which suggests they may have missed it? :-|",0,0
2016-09-16 08:16:00,"7/ This is balanced out by using a low-level adversarial loss, as suggested in this paper: https://t.co/5etBypwPsN https://t.co/lPbXXubyV5",12,2
2016-09-16 08:13:25,"6/ Interestingly, this paper uses VGG layer 5.4 as the perceptual loss, which is very high up compared to #NeuralStyle using 4.1 by default.",1,1
2016-09-16 08:10:44,"5/ MSE is the main cause for blurred images, as the network only ever learns to minimize its mistakes on average, so no re-textured patches.",1,2
2016-09-16 08:08:57,"4/ Perceptual Loss means avoiding pixel comparison w/ mean-squared error, instead use another DCNN (e.g. VGG) to compare like #NeuralStyle.",1,1
2016-09-16 08:07:13,"3/ Overall, this paper is a very sensible (hence predictable) next step in their research to use ""perceptual loss"": https://t.co/IAKRPhtntL",0,0
2016-09-16 08:04:51,"2/ This paper is by the Magic Pony team, now part of Twitter, related to their previous work on mobile-friendly SR: https://t.co/EBaSEgl5Hu",1,0
2016-09-16 08:01:49,1/ I was going to review this later but people will keep sending it my way until I post ;-) via @Smerity @Miles_Brundage @graphific ++,5,0
2016-09-16 08:00:41,Photo-Realistic Super-Resolution Using a Generative Adversarial Network https://t.co/MwKde7Y8sA (Thoughts below.) https://t.co/jdjuvg0q8X,68,28
2016-09-16 07:55:39,"@ngutten Yes!! You nailed it first time, thanks ;-)",0,0
2016-09-16 07:43:19,@ngutten They basically use a combination of two networks (high and low) + TV loss as adversary. Do you remember it? (Have trouble digging.),0,0
2016-09-16 07:42:20,@ngutten Hey. You once pointed me to paper about auto-encoding using adversarial learned loss functions and high-level perceptual loss too.,0,0
2016-09-16 07:19:31,"@madebyollin @DmitryUlyanovML I saw it, will be posting a mini-Twitter review later ;-)",1,0
2016-09-15 19:46:57,"@paniq Lapsus at 2:49 ""if this technology was real"" ;-)",1,0
2016-09-15 15:04:46,"For context, the Jungle Rock Face example from above does not use textures as input apparently. https://t.co/Vf5IBKbyFE",0,1
2016-09-15 15:00:40,"Terminology: do you consider node-based shaders or textures authored by a technical artist to be ""procedural""?",0,1
2016-09-15 14:49:40,"This paper is derived from research in 1999. Seems to require less manual work, but benefits not 100% clarified. https://t.co/slKcl8UfxB",3,0
2016-09-15 14:47:30,@danlowlows Paper from '99 was used as inspiration &amp; mentioned in background research. Apparently this requires less manual initialization.,0,0
2016-09-15 14:40:35,"@dougbinks Thanks. For me it would depend if any textures were used as inputs, which seems like it's supported but not encouraged?",0,0
2016-09-15 14:39:53,"@danlowlows I'm looking into the difference now. Research from '99 uses 3D model DB and establishes mapping, From '16 is single-image based?",0,0
2016-09-15 14:31:44,3D Face Reconstruction by Learning from Synthetic Data https://t.co/5vE0SPqS11 (Hybrid DCNN/rendering architecture.) https://t.co/I1ncATgTSB,66,25
2016-09-15 14:14:03,"@dougbinks I haven't used Substance Designer so I'm not sure how much texture data is used as input, and if that counts as procedural.",0,0
2016-09-15 14:03:44,The parallels between procedural node-based modeling today &amp; #GameAI 15 years ago are very obvious! @richardmatthias https://t.co/9RQEU7bZwY,3,0
2016-09-15 14:01:45,"@dillchen Ego. ""We will win self driving cars"" from his GitHub page.",0,0
2016-09-15 13:56:39,"How about this one, @samim? Body Horror by Mark Foreman in Substance Designer too. #procgen https://t.co/J4PMtlVmuz https://t.co/FSFLc3zlUi",26,4
2016-09-15 13:47:25,Jungle Cliff by Mark Foreman using node-based editor Substance Designer. Semi-#procgen? https://t.co/UFpt5wX1f5 https://t.co/oeIqkaNoEg,44,9
2016-09-15 13:37:15,"@dillchen But if the kit is on the market, no large corp is likely to buy as it'd be a huge liability (e.g. lawsuit for running over kids).",1,0
2016-09-15 13:34:33,"@dillchen Hard to say. Purchasing company would need proof of traction / technology, so rushing to market is one of few (bad) options.",1,0
2016-09-15 08:46:48,"It doesn't yet match backprop, struggles on convolution, but MNIST results are surprising and doesn't require careful weight initialization.",3,2
2016-09-15 08:44:44,"Another paper trying to break away from back propagation. https://t.co/9cA8g35A25 ""Direct Feedback Alignment"" #dnn https://t.co/S6aoNg5hlA",42,13
2016-09-15 08:22:05,@lmenus Do you want a hacker with small team prematurely rushing a self-driving car to market where mature industry is taking time to test?,1,0
2016-09-15 07:14:14,"Best case: team gets acquired, we never hear about it again
Worst case: sets back adoption of autonomous cars years
https://t.co/EcgyBCFnNa",16,4
2016-09-15 06:13:29,"@botminds If their goal was indeed wide adoption, then setting up an online service would have been a better way to try that.",0,0
2016-09-15 06:12:40,"@botminds They used 3.5GHz E5-1650 v3 IntelXeon CPU, 32 Gb RAM. If they wanted accessibility Matlab was not the way to go ;-)",0,0
2016-09-14 18:10:55,Congratulations to the @event0game team for launching today; great reviews! AI-based game design in action. #chatbot https://t.co/J6CsZ4fv6x,24,9
2016-09-14 16:56:08,@nikete @nuclai Any country in particular? ;-),0,0
2016-09-14 15:48:13,"@soumithchintala Oh, that's very cool! Thanks for pointing it out ;-)",0,0
2016-09-14 13:30:10,"@xiaojidan2011 No, haven't checked if it's online. Let me know if you find it!",0,0
2016-09-14 11:51:12,"4/ That said, I'm glad there's investigation of different approaches, especially patch-based. (Not a fan of this long report format though.)",0,0
2016-09-14 11:49:39,3/ Their hierarchical patch-based search + matching takes 50s at 400x400. Not significantly better than neural style running on GPU.,1,0
2016-09-14 11:47:11,"2/ They also discuss benefits of semantic maps, but no mention of #NeuralDoodle's paper or code either. https://t.co/9OzV2EIXVD",1,0
2016-09-14 11:45:57,"1/ Since the algorithm they introduce is also patch-based, the biggest omission is #NeuralPatches: https://t.co/sElUWbN3Gx",0,0
2016-09-14 11:39:02,"Style-Transfer via Texture-Synthesis https://t.co/JmSOgJ0y2Y (Long report, different approach, but some omissions.) https://t.co/tkPHlHnGJU",33,10
2016-09-14 11:26:50,@void995 Thanks! Looks like Microsoft's is made custom but using SVG in browser. Seems like that will help a lot ;-),0,0
2016-09-14 10:56:23,"@josefajardo Oh, cool. I saw the SVG part but couldn't see any other graph JS library. That explains it! Do you know the team?",0,0
2016-09-14 09:10:53,"Only found out about Microsoft's Azure ML yesterday: https://t.co/AsYkar8zgn Slick UI, ideas what it's built with? https://t.co/oEzlcTxglF",12,5
2016-09-12 12:01:57,11/ An in-painted football team photo: left is reconstructed from right using this improved #NeuralStyle ;-) https://t.co/K5VCj6MDX3,4,2
2016-09-12 12:00:11,10/ I'm impressed with breadth of examples studied (Appendix). Should be made into GitHub repository &amp; HD benchmark! https://t.co/BkFC4EZusS,9,1
2016-09-12 11:53:08,"9/ For HQ style-transfer or in-painting, also looks OK but #NeuralDoodle repository (main branch) does better IMHO. https://t.co/nZL9PjrUIO",1,0
2016-09-12 11:50:44,"8/ Overall, results are better than work from 2015. Still get desaturated and decolored areas though: https://t.co/GLjH7O6jRB",1,0
2016-09-12 11:48:00,7/ It's the same reason that patch-based approaches like #NeuralPatches are generally higher quality‚Äîalbeit slower: https://t.co/sElUWbN3Gx,1,0
2016-09-12 11:46:26,"6/ By offsetting the layers (1D or 2D), it helps the gram matrix model spatial co-occurences of patterns without needing extra layer above.",0,0
2016-09-12 11:44:07,"5/ For experts, big idea can be summarized in a half Tweet: compute the gram matrix with an offset layer ouput. https://t.co/JK4UC4aJ2d",7,1
2016-09-12 11:40:38,4/ This gram matrix representation explains why texture output feels like a mashup. Using deeper layers helps a bit: https://t.co/3CLNNxzblS,2,0
2016-09-12 11:38:52,"3/ This covariance of patterns is computed for each ""neural pixel"" (inside network) and aggregated, which discards positional information.",0,0
2016-09-12 11:36:08,"2/ This kind of style transfer works with so-called ""gram matrices""‚Äîexpressing global statistics for which patterns tend to appear together.",1,0
2016-09-12 11:31:32,1/ This paper is (of course) based on the original work by Leon Gatys from last August. https://t.co/7tJIRL8Vhu https://t.co/WT0TTNYNhs,5,1
2016-09-12 11:30:17,Incorporating Long-Range Consistency in CNN-based Texture Generation https://t.co/LfekXWa3Mw (Thoughts below.) #ML https://t.co/vG7jfWA003,40,12
2016-09-12 08:54:46,@rodolfor @samim Interesting! Going to have to look at the reaction in the press. How was it framed?,0,0
2016-09-12 06:37:04,"@MikkoMononen Your knowledge of AI will grow along with your child ;-) Congratulations BTW, missed this originally. Wish you all the joy!",2,0
2016-09-11 08:24:19,@ngutten Of course! What bothers me most is attitude tht one aspect is somehow objectively more important and others should get off my lawn.,1,1
2016-09-11 06:58:22,"@KerwinFranks Depends whether you consider statistics and probability distributions ""understanding"" ;-)",3,0
2016-09-11 06:51:50,"If you need more math to use ML as a tool (e.g. dealing with dataset bias), why not create another tool that helps make it more accessible?",10,2
2016-09-11 06:48:43,"I'd suggest we need to make ML intuitions as widely understood as possible, even if it involves dropping math when people use it as a tool.",21,7
2016-09-11 06:44:08,Only a small population percentage will ever understand machine learning formally. Does that mean we should make that technology off limits?,11,1
2016-09-11 06:42:08,"I'm with @arbesman on this topic, the notion we can fully understand complex man-made systems is a romantic one. https://t.co/sgJ4zKctHo",7,3
2016-09-11 06:39:21,Do you think we'll ever be able to fully understand and explain deep learning systems mathematically?,3,2
2016-09-11 06:35:53,@atroyn Curious why they did drop out then... Did you have words with admission in the end? https://t.co/Ag6NYm2VST,0,0
2016-09-11 06:31:39,"@atroyn @Smerity @jackclarkSF If you wanted, you could easily explain data bias and its solutions without alienating half of your students.",0,0
2016-09-11 06:30:56,"@atroyn @Smerity @jackclarkSF Hehe, we can't even fully understand deep learning mathematically anyway. Why so elitist about it?",0,0
2016-09-11 06:28:59,"While knowing math helps you understand parts of ML (esp. research), there's  another part that's exclusively intuition (esp. applications).",13,3
2016-09-11 06:25:21,"Do you need to understand rigid-body physics to use a sledge hammer? If you don't, does that make you less serious? https://t.co/KNmHfE8odq",58,12
2016-09-11 06:19:02,"@Pranaryx I mean, if one of the sides present video evidence at last minute, it gives no time for other side to alter it &amp; claim authentic.",0,0
2016-09-11 05:01:06,"@Pranaryx Assuming both sides had access to the original video, that sounds likely! Can one be withheld until the last moment?",1,0
2016-09-10 19:06:13,@gpakosz Fully generated? In 5 years. ;-),0,0
2016-09-10 19:00:14,@mark_riedl Good luck recruiting reviewers then :-) Regardless how it works out I think there'll be many changes ahead!,1,1
2016-09-10 18:54:57,@mark_riedl They are a finite resource though. How much did submissions grow from last year?,1,1
2016-09-10 18:49:32,"@mark_riedl So if you get submitters to review each other, the larger the group the worse the outcome.",0,0
2016-09-10 18:48:55,@mark_riedl True. The case can also be made that smaller conference have more specialized topics and higher-quality submissions.,0,0
2016-09-10 18:45:30,@jurieongames @adurdin Getting evidence from one place to another involves many fallible / corruptible people. https://t.co/QqcGXfOiB1,2,0
2016-09-10 18:43:28,"@mark_riedl Looking at NIPS post-review debacle, reviewing breaks down at this scale. If it happens for AAAI too, public review only option.",1,1
2016-09-10 18:38:32,@jurieongames @adurdin Chain of custody is not a technical problem.,2,0
2016-09-10 18:38:03,"On bright side, 2018's Bond 007 film was recorded with monkey in green suit, replaced with viewer's favorite actor:",1,1
2016-09-10 18:31:15,Testimony is struck from record. Case is dismissed and everything is buried. Word still gets out and people realize:,1,1
2016-09-10 18:20:44,"Photoshop experts can fake photos given time, but doing videos and/or automatically in near real-time will be new! https://t.co/PhBg5OXe4K",6,3
2016-09-10 18:17:53,"@jurieongames Hehe, ""untamperable"" is a marketing word not a technical one.",4,0
2016-09-10 18:10:53,"I'm a Law n00b, so focusing on AI part, but struggling to finish it ;-) Maybe you can write two alternative endings? https://t.co/NL3Zw44UeL",3,2
2016-09-10 18:03:39,"Tricks like camera cuts, fast movement, and compression artifacts cover up any flaws in early iterations of this generative technology.",7,2
2016-09-10 18:01:49,"The researcher also admits that online advertisers have likely done this already for 15 months, increasing brand awareness subliminally.",4,3
2016-09-10 17:59:01,"In turn, the prosecutor invites researcher at social media company who testifies they've been modifying videos online already for 9 months.",5,2
2016-09-10 17:56:14,"The defense brings in an ""generative adversarial"" expert that reports the footage has 54% probability of being real; jury is convinced.",14,9
2016-09-10 17:54:00,"Neural network technology will have reached a state where it can modify facial expressions, posture and audio to tell a different message.",22,19
2016-09-10 17:52:38,"In 4 years, a court case will take place where jury cannot tell if submitted video evidence is real or has modifications to audio/image.",85,63
2016-09-10 17:49:40,"@tombielecki I think photo-realism has been reached already in VFX, IMHO. You'd have trouble telling what's filmd unless you were an expert.",1,1
2016-09-10 17:11:28,@tombielecki Which one of those are current VFX filters not 100% yet?,0,1
2016-09-10 15:31:24,@edersantana @graphific @samim I'm sure you'll hear more soon ;-) Stay tuned!,2,0
2016-09-10 15:18:48,"@tombielecki If you can define ""directed"", then at least there may be a chance ;-)",0,0
2016-09-10 10:11:39,"""It requires 90 minutes to generate 1 second of audio."" #surprise Deployable in 3 months or less, realtime 1 year? https://t.co/SjcVPKfnE4",16,1
2016-09-10 09:24:49,I'll look into the paper in more depth as soon as things settle down; thanks everyone who sent it my way! https://t.co/54f3rO7weO,15,3
2016-09-10 09:22:50,Historical week in #CreativeAI: DeepMind releases #WaveNet Thursday and huge milestones Friday around the corner! #‚öò https://t.co/3dkLKjsKTj,35,2
2016-09-09 17:49:24,"@JoanieLemercier Hi, yes normally but I'm away and it went down so it'll have to wait 4h or so.",1,0
2016-09-08 18:06:37,@dejobaan @grahamboree Thanks! Funnily enough working on something based on that right now ;-) https://t.co/St4tlYLotf,2,0
2016-09-07 18:42:14,Some poor marketing intern had to comb through a thesaurus for this. Next: #generative ad copy powered by WordNet. https://t.co/aDw9Fly9h9,7,5
2016-09-07 15:31:44,"@Donzanoid You need to be able to test each component to 5-6 sigma (more) in isolation, and formally specify (or prove correct) integration.",3,0
2016-09-07 15:30:31,"@Donzanoid Agree. End-2-End deep learning for cars is irresponsible IMHO. Even if NN math was 100% understood, system is too complex. [1/2]",3,0
2016-09-07 15:27:56,"@Donzanoid If your process is able to deal with testing/quality control for one instance of a neural network, then should work for next one.",0,0
2016-09-07 15:27:07,@Donzanoid You can in generally guarantee that the new training will find near (enough)-optimal solution as the original solution.,0,0
2016-09-07 15:26:05,"@Donzanoid Yes, the change will be proportional to the percentage of data added and the degree to which it agrees with existing data.",0,0
2016-09-07 15:25:12,"@Donzanoid If you need 100% answers, you basically specified all inputs/outputs and just need a lookup table or expert system.",0,0
2016-09-07 15:24:45,@Donzanoid That's machine learning in general. You build your system knowing that underlying decisions have certain minimum confidence.,0,0
2016-09-07 15:20:31,"@Donzanoid 2) For high-level explanation, results are merely a reflection of the data‚Äîeven if training doesn't always converge to optimal.",0,0
2016-09-07 15:18:51,"@Donzanoid Multi-level question. 1) You can low-level explain an output number exactly, it's a consequence of deterministic calculations.",0,0
2016-09-07 11:59:53,"@Thomas__Arnold ""Transcended human abilities"" doesn't quite have the same catchy length as the other items in the list!",0,0
2016-09-07 11:51:44,"For the last one I'm torn between that and ""g-g-g-godlike"" or even ""HULK!"" Original is more formal, depends on the situation ;-)",4,2
2016-09-07 11:50:47,"My scale to assess the quality of #generative systems:
1. Machine
2. Child
3. Adult
4. Expert
5. Deity",16,3
2016-09-07 10:32:55,I figured out what bothers me about grand AI startups: their pitch is trans-humanist but somehow lost humanist part. https://t.co/ZKRIrfe6n3,11,2
2016-09-07 09:44:21,@yoavgo I suspect NVIDIA is licking its lips like a wolf in fairy tales. #DGX1,5,0
2016-09-07 08:50:24,@stcymsn This was the last information point I saw on this topic: https://t.co/geagLzMLs3,1,0
2016-09-07 07:53:22,These autonomous trucks in Legoland's miniature cities stay on track by following magnetic field from under road. https://t.co/lWOsVJmpBr,16,3
2016-09-07 07:50:45,"It should be quite an entertaining ride. (Yes, we went to Legoland last week before term started! ;-) https://t.co/j1VeVmQWdm",4,0
2016-09-07 07:48:55,Various projects in the pipeline looking great. Hopefully can share more soon! https://t.co/BVblfEgiJ8,4,0
2016-09-06 22:33:28,"@JonOlick If you randomly sample a patch, it'll likely load more data in the same cache line. Are there algorithms to make the most of that?",0,0
2016-09-06 22:30:49,"@JonOlick Has anyone tried to optimize this by sampling strategy? Update both patches when sampling, or sample from linear scanned patches.",0,0
2016-09-06 22:26:53,"@JonOlick I suspect most are using PatchMatch on GPU by now? There's a version custom-designed, so cache matters less...",0,0
2016-09-06 22:24:56,"@JonOlick In some (most?) image types you can balance global random search by smaller local searches, propagation, then more iterations.",0,0
2016-09-06 22:13:52,"@JonOlick Why does it reduce quality? Do you change the algorithm to constrain to tile edges too, or just take cache hit if it overflows?",0,0
2016-09-06 22:09:17,"@JonOlick In my voxel terrain engine years ago, tiling helped a lot with those worst cases accesses‚Äîbut you pay price as overhead.",0,0
2016-09-06 22:08:02,@JonOlick Maybe tiling could make PM faster? Reduce hit for nearby searching and improve worst case scan from bottom-right to top-left.,0,0
2016-09-06 22:05:58,"@JonOlick It's still faster than alternatives I know, incl. brute force. When you work with NNs, mostly stop caring about cache misses ;-)",0,0
2016-09-06 22:03:38,7/ It's fun to think about because convolution networks would struggle with almost every part of this algorithm‚Äîlikely outperformed too ;-),3,0
2016-09-06 22:00:53,"6/ Results on upsampling (4x) urban images are very convincing, but surprisingly good also on natural images (3x). https://t.co/4YTE2idjqn",2,0
2016-09-06 21:58:13,5/ The image is reconstructed iteratively (i=20) by repeatedly copying transformed 5x5 patches that match. Not sure how fast this is...,0,0
2016-09-06 21:54:06,"4/ Then, the usual PatchMatch algorithm can be extended to find relevant image sections under various 2D transforms. https://t.co/dbjCjJDNsb",6,1
2016-09-06 21:51:01,"3/ The big insight here is to first extract image planes (if there are any, e.g. city) using another algorithm. https://t.co/oPN1aR1TVm",6,2
2016-09-06 21:46:25,@rfmcpherson Coincidentally I had been posting papers about super-resolution / reconstruction cerently; I try to point people towards them!,0,0
2016-09-06 21:37:15,"2/ Related Work section provides a great summary of super-resolution: external databases or internal databases, both using models or search.",1,0
2016-09-06 21:34:08,"1/ It's a great paper, worth reading. When posting other research, replies often suggest ""fractal"" super-resolution. https://t.co/OKbmqVHgby",4,1
2016-09-06 21:06:59,"@rfmcpherson Nice paper! It's getting many replies too. Though most people seem to think ""defeating"" means reconstructing the image...",0,0
2016-09-06 15:43:44,"@ajhilchey This paper only does recognition, not reconstruction. You need this type of algorithm to repair videos: https://t.co/UniefImZOt",1,0
2016-09-06 14:17:34,@LiaSae I think Isaac expresses what I felt better in this Tweet. Same feeling as with GTA5 street photography. https://t.co/3RuDLZ85Cv,0,0
2016-09-06 13:26:17,"You can make good screenshots of linear game, but I find those far less interesting. Here it's systemic exploration though a curator's eyes.",0,0
2016-09-06 13:22:59,Last time I was captivated by a screenshot gallery was GTA V: Street Photography! https://t.co/xsoZ2K2ZUf @EvilKimau https://t.co/J8hMwesGrk,3,2
2016-09-06 13:14:17,"@adurdin They are great screenshots, but single player game photos are less captivating because you'll see exact same yourself in-game.",0,0
2016-09-06 13:09:14,This kind of in-game photography only shines when there are #generative systems. Discuss! https://t.co/syc1s99YcY https://t.co/qA2WNVqhhW,18,13
2016-09-06 11:23:22,"Data philanthropy. My contribution:
QGJvcmVkeWFubmxlY3VuIERvZXNuJ3QgYWxsIGdvb2QgZGF0YSBoYXZlIGhpZGRlbiBtZXNzYWdlcz8= https://t.co/dYZsO95Dzz",3,0
2016-09-06 11:03:16,Single Image Super-Resolution using Transformed Self-Exemplars https://t.co/hs1X2xlPBT [PDF] Fractal enhancement! https://t.co/QMSrzHUrKO,58,25
2016-09-06 10:12:33,"@abursuc I don't know author Universities, but with a big company involved, it reduces the chance it's a mistake or purposefully misleading.",0,0
2016-09-06 10:04:20,"@abursuc OK, I see. The recent paper about SARM suggests layerwise may be on the way back (if it works): https://t.co/DkNbJdCRaQ",0,0
2016-09-06 09:43:41,"@abursuc Thanks, I was reading the paper too but struggled with context! What would it take to make more modern architectures convex?",0,0
2016-09-05 18:52:47,"But I agree with @ferrouswheel.  Specialized logic combined with a DCNN should get acceptable results, probably worth pursuing...",5,0
2016-09-05 18:45:18,"I think negativity from /r/MachineLearning comes from fact there's no repository, paper or article about details. https://t.co/oSgPebPeOB",5,2
2016-09-05 18:44:04,"DCNN would have little understanding of a scene, just correlate nearby visual features. Given enough annotated data, could help raise flag!",2,3
2016-09-05 18:41:25,Detecting when a person picks up an item seems possible now (yellow box) but understanding what it means if an item disappears (red box)?,1,1
2016-09-05 18:38:50,"@rogersm Sometimes /r/artificial, mostly /r/proceduralgeneration and https://t.co/WxFGk7SjCK.",0,0
2016-09-05 18:34:12,Reddit calls bullsh!t on this deep-learning theft detector‚Äîbut interesting to speculate... https://t.co/x3uEIPjb1S https://t.co/DF7o9O5qeL,32,9
2016-09-05 18:05:38,"Looks like a template that worked out particularly well! With enough templates and no history, few would notice... https://t.co/KQ3N3PohPi",1,0
2016-09-05 18:00:57,Sometimes I wonder if there isn't a human typing Tweets for this bot... https://t.co/lFHDLLTEWu,0,0
2016-09-05 15:36:53,@danmarce This approach doesn't reconstruct images. You'd need something more like this: https://t.co/UniefImZOt,0,1
2016-09-05 15:11:50,"@Marker013 I guess it comes down to definitions of ""virtual""? Not such a fan of philosophy without context‚Äîand a beer.",0,0
2016-09-05 15:01:53,"@azeem I also like the quote attributed to McCarthy ""AI is the set of ill-defined domains."" https://t.co/AtJYplyOJ7",1,0
2016-09-05 14:47:40,"@Marker013 I implied his message to be ""performing the action of style transfer is not Art"". Maybe you're right, misquoted for clicks?",0,0
2016-09-05 14:40:03,"Bonus:
- Arrange scene before taking photo
- Plan series of posts to tell a story.

Takes time for new tools to become accepted! #CreativeAI",3,1
2016-09-05 14:35:11,"Infinite possibilities:
- Decide where to point your camera.
- Select any app and style to use.
- Craft the message and post it online!",7,1
2016-09-05 14:33:27,Professor says neural style transfer is not Art. I wonder what his exact words were ;-) @prostheticknowl https://t.co/HW7w7UFwLl,10,3
2016-09-05 12:14:12,@saltyhorse They were likely just down-sampled.,0,0
2016-09-05 12:07:03,"@AngeBassa Ah, you're one of few then ;-) Trying to cover up my mistake selecting the image‚Äîgives wrong impression. https://t.co/5nW9ASvRWc",0,0
2016-09-05 12:01:51,"Yes, in retrospect. Though both super-resolution papers I posted yesterday do reconstruction surprisingly well! ;-) https://t.co/5nW9ASvRWc",0,0
2016-09-05 11:59:01,"@AngeBassa It's not random pixels, it's a dataset that you can learn to predict‚Äîe.g. by color. Random would be 10% accuracy.",0,0
2016-09-05 11:56:43,"@AngeBassa It has 70% accuracy with pixelized obfuscation that's 4px by 4px, drops to 50% accuracy for 8px by 8px. https://t.co/ny8WIXwq9z",0,0
2016-09-05 11:34:18,This approach doesn't restore images; it simply uses remaining information/context to make reasonable predictions. https://t.co/6JpNFl168b,5,4
2016-09-05 11:12:29,"@richardmatthias It's making decisions based on the data that's still there. Some predictions better than others, multiple frames help.",0,0
2016-09-05 10:56:53,@jackclarkSF So it's a bit like Technology+Credibility? Does knowing the team help address this credibility factor if no demo is available?,0,0
2016-09-05 10:53:56,"@jackclarkSF Good one! Do you consider those a subset of ""technology"" enough to vote for that option, or is this a 5th option for you?",0,0
2016-09-05 10:49:11,"@deptstorespook Maybe trying to emulate Ouya, then sell out?",0,0
2016-09-05 10:48:28,"When a new AI project/startup/kickstarter launches, what contributes most to your first impression?",2,3
2016-09-05 10:38:35,"@GET_TUDA_CHOPPA Right, if you isolate the ""bad"" bits to bugs and if the game is fun, then it's a success overall!",0,0
2016-09-05 10:34:21,I thought it was some kind of motion capture‚Äîbut with intelligent playback for interactions. But this makes sense! https://t.co/jp6Sw8Hqoo,2,4
2016-09-05 10:32:33,"@GET_TUDA_CHOPPA In the Course, I use the bugs angle too. It went down well knowing all the games were not recent releases ;-)",1,0
2016-09-05 10:31:32,"@GET_TUDA_CHOPPA This is best angle I found: https://t.co/ppgh3MjpJX It's a funny bug in complex system, laugh and learn!",0,0
2016-09-05 10:29:06,"@GET_TUDA_CHOPPA If you go through, say N=5 things one #GameAI does well, then you could do one failure alongside. Good lessons...",0,0
2016-09-05 10:27:46,"@GalaxyKate @GET_TUDA_CHOPPA By making it $400 hardware, they reduce their chances of delivering and could conceivably run with the money.",1,0
2016-09-05 10:25:14,"@rhymebyter They aren't selling hardware, they are selling procedural game creation. Could be on PS4 or Steam easily. Now there's two risks!",0,1
2016-09-05 10:23:53,@GET_TUDA_CHOPPA @AIandGames There's some educational value there either way. Maybe you can pull it off with pure charisma ;-),0,0
2016-09-05 10:23:04,"@GET_TUDA_CHOPPA @AIandGames Ah, ""Bad AI"" angle would be hard to pull off without it being destructive or burning bridges...",0,0
2016-09-05 10:03:00,"The fact they released this as hardware-first Kickstarter is suspicious, likely scam? More sensible would be to release $30-$60 Steam game.",9,2
2016-09-05 10:01:51,"It only supports 2D platformers now, but thanks to a $25k crowdfunding goal they'll build a full 3D game engine in the next few months ;-)",7,1
2016-09-05 10:00:19,"@F_Vaggi This paper only does classification / prediction, not reconstruction.  See papers I posted yesterday for that ;-)",0,0
2016-09-05 09:58:44,"""It's truly a self-sufficient system without the heartache [...] of standing in long lines waiting for new game releases."" Wow, such pitch!",2,1
2016-09-05 09:57:53,This console with automated game design algorithms built-in has an entertaining #Kicstarter pitch. #GameAI https://t.co/HlSQoX31Q4,5,2
2016-09-05 09:49:51,"@saltyhorse Yes, I'm not exactly sure how they approach that. Could predict ""features"" of the face and map those to database.",0,0
2016-09-05 09:48:57,"@saltyhorse Yes, that's what paper says. They also say a DNN makes it easy for that to work without understanding what information leaks.",0,0
2016-09-05 09:45:06,"@saltyhorse It can recognize the digit 2 with 90% accuracy, but not necessarily reconstruct it as it was.",0,0
2016-09-05 09:38:13,"@saltyhorse There are no image ""results""; it doesn't restore the image it just tries to recognize what was there and return a prediction.",0,0
2016-09-05 09:01:56,Defeating Image Obfuscation with Deep Learning https://t.co/dTjpjvVJgP ~57% to 80% accuracy despite blur/pixelation! https://t.co/KwhyuaCIwg,129,80
2016-09-05 05:42:02,@danebaker @madebyollin They mention it in the introduction: super-resolution is an ill-posed problem. I'd be interested in seeing attempts!,0,0
2016-09-04 20:46:57,"@madebyollin If the images fit into memory, it will work! It'd be like applying the patches fractally at 2x zoom.",1,0
2016-09-04 20:38:27,"See my previous experiments at example-based super-resolution, applied to pixel art: https://t.co/vbWMjbfcT4 https://t.co/cPPBdJlljH",12,5
2016-09-04 20:34:30,"@madebyollin Patch-based approach have significant advantages here, because it's more information results look better than ""statistics"".",1,0
2016-09-04 20:33:41,"Most super-resolution papers use metrics that encourage smooth results, rather than reconstructing plausible detail. https://t.co/MboMH15FuW",13,4
2016-09-04 20:26:16,"11/ Recursive layer for style transfer would be harder to train, but using ensemble approach should help stabilize process. Worth a try!",2,0
2016-09-04 20:24:38,"10/ For style transfer, could consider middle N=16 layers with shared weights as iteratively applying style to intermediate representation.",0,0
2016-09-04 20:21:40,9/ I find the architecture interesting for feed-forward style transfer. It's fast but not as good as iterative: https://t.co/bTbPzYGUPc,2,0
2016-09-04 20:16:45,8/ There's a skip connection directly from the input to reconstruction layer; seems to play similar role as residual from other paper?,1,0
2016-09-04 20:12:56,"7/ To address this, the architecture averages output of each iteration (like an ensemble) which helps regularize. https://t.co/OhPHJbUxFC",2,1
2016-09-04 20:07:56,"6/ It's harder to train a recursive CNN, especially as depth increases, due to vanishing/exploding gradients; it's similar to RNN problems.",0,0
2016-09-04 20:05:53,5/ Visually seems to do a better job at fixing compression artefacts and removing noise. Side-effect of the recursive approach?,0,0
2016-09-04 20:04:47,"4/ Overall, the results are surprisingly good! This one in particular, right column is recursive network: https://t.co/tsBZmfgAh0",7,2
2016-09-04 19:58:08,3/ The first two layers convert the image to an intermediate representation and the last two convert back to the usual 3-channel RGB format.,1,0
2016-09-04 19:56:05,"2/ In this paper, N=16 layers in the middle share weights. It's equivalent to an iterative approach to super-resolution, could increase N.",1,0
2016-09-04 19:52:22,"1/ This paper is by the same authors/lab as the one earlier, performs slightly better overall‚Äîplus more interesting! https://t.co/UniefImZOt",4,0
2016-09-04 19:50:04,Deeply-Recursive CNN for Super-Resolution https://t.co/eYroH7fzml [PDF] Interesting architecture! (Thoughts below.) https://t.co/dHvoJcz34P,95,22
2016-09-04 18:38:26,"@mphuget @pkmital @samim @Jnatanh Little busy for the next few weeks, but you know where to find me. DM is open!",1,0
2016-09-04 18:13:13,"@mphuget @pkmital @samim @Jnatanh You could start with something like generating scenes/faces from example images, then go from there.",0,0
2016-09-04 18:12:03,"@mphuget @pkmital @samim @Jnatanh For context, both these ideas seem like 3-5 year projects at the cutting edge of research ;-)",1,0
2016-09-04 18:04:45,"@mphuget @pkmital @samim @Jnatanh nucl.ai will help most with inspiration, connections, friendly environment to ask questions.",2,0
2016-09-04 18:01:13,@mphuget @pkmital @samim @Jnatanh It might be easier to get started if you narrow down what part of #CreativeAI you are most interested in!,1,0
2016-09-04 18:00:30,@mphuget @pkmital @samim @Jnatanh There are some repositories that are open and on GitXiv. Hard part is tweaking/tuning beyond white paper!,2,0
2016-09-04 17:42:21,@aasensior It should work almost exactly as described in the paper if you have the HD training data! ;-),1,0
2016-09-04 17:01:01,"13/ Super-resolution is quite boring IMHO, but architecture &amp; training insights apply to image transformations in general ;-) Worth reading!",6,2
2016-09-04 16:56:12,"12/ Code and data is available from the project page: https://t.co/5c4SLEsKEH It's Matlab, but should be easy enough to reproduce.",11,2
2016-09-04 16:44:31,@jfischoff @kylebrussell Do you have a link to PSF papers? This research claims significantly better results than other approaches.,1,0
2016-09-04 16:32:07,"11/ Larger networks should have capacity to understand a picture &amp; reconstruct texture: ""This looks like a buffalo's bottom, it needs fur.""",8,0
2016-09-04 16:30:31,"10/ Since it's now easier to train deeper and more complex image transformation networks, next focus should be injecting missing detail!",3,1
2016-09-04 16:29:12,"9/ This idea of using an ""artificially"" high learning rate is validated in different contexts too. See this paper: https://t.co/HHDV07KtKz",4,1
2016-09-04 16:26:53,8/ It's not clear exactly what value of Œ∏ they use for clipping gradients; Œ≥ is the learning rate. But it's fast! https://t.co/EgBpSYLnC8,4,0
2016-09-04 16:25:27,"7/ The fix: crank up learning rate to 0.1, decay it over epochs as usual, but also clip gradients inverse proportionally to learning rate.",2,0
2016-09-04 16:19:17,"6/ The authors suspect that previous attempts did not converge, even within a week of training due to the small learning rates (1E-5).",1,0
2016-09-04 16:13:01,5/ They make the problem even harder by training a very deep network of 20 layers each with 64 channels of 3x3. https://t.co/q2aw49n3bF,5,0
2016-09-04 16:12:01,"4/ In this paper, they throw out the shallow network and just use a residual from the low-resolution image‚Äîwhich is even harder to train!",4,0
2016-09-04 16:10:49,3/ Training deep networks for image transformation is hard. In 2/ they address this by introducing shallow network then learn its residual.,6,0
2016-09-04 16:07:59,"2/ This paper instead focuses on increasing quality, which is similar to this paper from last month too: https://t.co/7at1ZBxRip",9,2
2016-09-04 16:04:38,"1/ For context, read this series of Tweets about a previous paper focusing on accelerating super-resolution: https://t.co/cJqe7pP5kN",10,2
2016-09-04 16:03:05,New! Accurate Image Super-Resolution Using Very Deep CNN https://t.co/BOyVOuwBOp [PDF] (Thoughts below.) #ML #dlearn https://t.co/uXbkBCKXXK,133,59
2016-09-04 14:13:15,"@DanielJBrewer Yeah, turns out it's just RYB. I didn't realize the B from RYB was usually different than the B from RGB.",0,0
2016-09-04 06:41:20,@Deeder It's not that simple. The hue is warped compared to usual HSL / HSV.,0,0
2016-09-03 18:44:46,RYB Color Compositing https://t.co/2cM1zM2ItO Includes equations to convert to/from RGB easily. (via @MikkoMononen) https://t.co/9u7qehp9Vd,43,13
2016-09-03 18:39:58,"@MikkoMononen @runevision RYB fits actually. I didn't realize the B in Itten's was not the same ""pure"" B from RGB. https://t.co/QCKlhsdsHm",1,0
2016-09-03 18:15:42,@runevision It's very easy to make! scikit-image can do color conversions quickly. Not sure what color wheel Gurney uses though ;-),0,0
2016-09-03 18:10:51,"@runevision Yes, I think it's worth trying! Would also love to see analyses of classic paintings... I got 2k paintings for @DeepForger ;-)",0,0
2016-09-03 18:09:53,"@runevision I suspect by adjusting the colors, Adobe's simpler model (for logos/websites) would let you approximate something similar.",0,0
2016-09-03 18:05:22,"@runevision At this stage, it's a similar approach to Adobe's Color tool‚Äîjust using those key colors as triangle corners. [2/2]",0,0
2016-09-03 18:04:32,@runevision The screenshots from Awesomenauts have many saturated colors. But you could constrain triangle size and shape. [1/2],0,0
2016-09-03 18:01:30,"@runevision Plus, this model doesn't help you pick the triangles. Here it's just an analysis tool... (Haven't read the book yet.)",0,0
2016-09-03 18:00:13,"@runevision You still need to select the triangles/polygons to pick your colors from, and many more parameters: potentially more random? ;-)",0,0
2016-09-03 17:29:13,"@CasualEffects Hmm, interesting! @MikkoMononen found a forum thread from 2007 where they admit it's just RYB color wheel.",0,0
2016-09-03 17:13:05,"@runevision @gillianmsmith @anneandkita @mtrc It reminds me, did you see this blog post last year? https://t.co/O9Wa73CYgw",7,1
2016-09-03 17:10:34,"@MikkoMononen Thanks Mikko! I initially thought RYB too but now slightly off. Maybe they changed it, does not seem very formal. @runevision",0,0
2016-09-03 16:12:14,"@mmalex Yes, piecewise linear works. Curious if there is a basis for that, and what it is. How come it looks good? https://t.co/IKMHDerQ1x",3,0
2016-09-03 14:35:36,"@gordonbrander @pmawhorter You can perform a mapping from HSL to HSV easy enough, so maybe addressing ""mushy"" HUSL is similar?",1,0
2016-09-03 14:33:59,@gordonbrander @pmawhorter I prefer HSV for this reason. Would love a perceptual version of that color space!,1,1
2016-09-03 14:32:51,@gordonbrander @pmawhorter The problem seems that decreasing or increasing L (away from 0.5) basically fades to black or white.,1,1
2016-09-03 14:27:17,"@rzubek Yes, the yellow / orange part of the spectrum is expanded whereas green is more compressed. @runevision noticed yesterday!",2,0
2016-09-03 14:19:22,"It's not a regular RGB color wheel, or Munsell or RYB. Have to admit it produces pretty good color combinations! Any other research on this?",4,1
2016-09-03 14:17:24,Does anyone know if there's published research behind the color space used by Adobe's tool? https://t.co/NmA0Zzkjl1 https://t.co/2iiNtAD1qR,27,6
2016-09-03 09:40:04,@runevision @bastianlstrube There's research. Found nothing amazing so far: https://t.co/a3PKQItn58,0,0
2016-09-03 09:29:35,"@runevision @bastianlstrube Results look good though! In terms of Hue, what &amp; where is the maximal amount where it's different from Munsell?",0,0
2016-09-03 09:25:59,@IgorCarron Secondary currencies for the win! Now if only we can design those to fix the flaws in the primary currencies...,1,1
2016-09-03 09:20:54,"@bastianlstrube @runevision It's non-linear mapping, apparently hard to express analytically. Will look into approximations when I get time.",0,1
2016-09-03 09:09:19,Can five megacorps (as the product of modern capitalism) get together to fix the symptoms of that very system? https://t.co/5cjE5qsLGF,1,4
2016-09-03 08:52:56,"@bastianlstrube @runevision In RGB space, the space around orange is more compressed so small changes mean big impact on human perception.",1,0
2016-09-03 08:51:56,"@bastianlstrube @runevision If you change color value in a perceptually uniform space, you notice the difference everywhere proportionally.",0,0
2016-09-03 08:50:36,@memotv @fchollet There's significant value in open models even if the data is not available (privacy/legal). It's easier to achieve too.,0,0
2016-09-03 08:47:43,"@bastianlstrube @runevision Likely why Munsell is still used to find perceptually pleasing ""opposite"" colors. https://t.co/cj4TofJdrV",0,0
2016-09-03 08:45:26,"@bastianlstrube @runevision The more recent CIE L*a*b* is, Munsell too but uses one component for ""hue"": https://t.co/xNc671579l",0,0
2016-09-03 08:44:00,"@bastianlstrube @runevision It's hard to follow the thread, but my follow-up tweets touch on this. RGB is not perceptually uniform.",0,0
2016-09-03 07:39:10,Making Deep Learning more accessible to artists/designers is going to take effort... A step in the right direction! https://t.co/cCoSgpkLbq,16,7
2016-09-03 06:57:48,Luckily @antovsky reports this approach works and uses it on #DreamsPS4! For #procgen fewer conversions are needed. https://t.co/nHIazhYqKq,2,1
2016-09-03 06:55:49,But @runevision is getting good results using a piecewise linear approximation for modifying the hue value. https://t.co/IKMHDerQ1x,2,1
2016-09-03 06:54:34,Apparently there are no simple equations for converting to/from RGB like other color spaces. @antovsky https://t.co/l5o6vojNg0,0,0
2016-09-03 06:50:02,Using the Munsell space for picking color combinations has become common. First book on this dates back to 1921! https://t.co/o2kajbTr8T,4,0
2016-09-03 06:47:11,"Both Munsell and CIE L*a*b* are perceptually uniform, so changing color values proportionally affects how humans see the difference.",0,1
2016-09-03 06:44:34,"The Lab color space is a modern version, but Munsell has #procgen advantage of using a single component for hue. https://t.co/aQOJt0ELdy",2,0
2016-09-03 06:42:49,More insights from yesterday: Adobe's Color tool likely inspired by Munsell's color system. https://t.co/xNc671579l Thanks @CasualEffects,3,0
2016-09-02 21:24:26,"@boschma @runevision That said, we're still not sure what representation Adobe uses for ""Hue"" here so unclear how best interpolate.",1,0
2016-09-02 21:18:56,@boschma @runevision I you take RYB components and just interpolate you wouldn't get all colors of the same saturation/lightness.,0,0
2016-09-02 21:09:46,@runevision @William_Malo https://t.co/HCs1WRVPIA,0,0
2016-09-02 21:06:38,"@runevision The wiki page shows no interpolation, if you use spherical interpolation it should be the same.",0,0
2016-09-02 20:18:44,@William_Malo @runevision Past experience? Is this one RYB: https://t.co/ZEhxtY8FOj,0,0
2016-09-02 19:39:14,"@botminds Well Baidu has money. For academics, PR is still a skill that you can achieve reasonably without cash. Some better than others.",0,0
2016-09-02 19:20:35,"@botminds Sure, technically it was a huge achievement. I'm saying marketing and PR was up to the challenge, and helped kick off branding.",0,0
2016-09-02 18:59:59,"@larsiusprime There's a link to Wikipedia in that same Tweet. Not very obvious in the context of thread, but it's there ;-)",1,0
2016-09-02 18:59:23,@larsiusprime The Adobe color tool actually seems to use this (closer than a RGB color wheel) to select great-looking color combinations.,0,0
2016-09-02 18:58:33,"@larsiusprime That RYB color wheel is &gt;100 years old, based on insights mixing paint. Possibly more ""perceptually accurate""?",1,0
2016-09-02 18:48:08,"Wherein I descend into a rabbit hole of color representations suitable for #procgen. (See thread, scroll up!) https://t.co/DseBK0Tq20",31,8
2016-09-02 18:40:11,"@runevision I think I'm done now. Learned something new! ""No scientific basis"" maybe great for #procgen? ;-) https://t.co/ZtuFmPWIql",4,0
2016-09-02 18:38:43,"@runevision OK, my last tweets were on the right track. It's tertiary colors of RYB space. https://t.co/1oSfZeOA2p https://t.co/u2vkNmDOwS",9,2
2016-09-02 18:20:43,@runevision It looks like a color wheel made from tertiary colors. Not sure if there's an equation to map hue. https://t.co/OZzYKTiPzm,1,0
2016-09-02 18:00:18,"@runevision Looks similar to RYB, but the B doesn't quite match as exactly as RY. https://t.co/Lc9Msochrk https://t.co/3ZltnhTs2T",0,0
2016-09-02 17:54:28,@runevision @mtrc @anneandkita Might be a non-linear transformation similar to Lab (which is also perceptual) but for hue alone?,0,0
2016-09-02 17:53:30,"@runevision @mtrc @anneandkita Oh crap, I never noticed. I presume it's a perceptual mapping on that ""hue"" wheel. Yellow squashed normally.",0,0
2016-09-02 17:50:47,@runevision @mtrc @anneandkita It nicely separates tone/hue from saturation from lightness. Using HSL increasingly for #NeuralDoodle too!,0,0
2016-09-02 17:48:29,@runevision @mtrc @anneandkita It's HSL or HSV space. I find that color format much better for procedural code for exactly these reasons.,0,0
2016-09-02 17:39:50,"@runevision I've no idea if such a model exists already, but likely you can train simple machine learning from ~100 samples you provide.",0,0
2016-09-02 17:38:42,"@runevision Using fixed relative hue is hard-coded solution, otherwise you need perceptual model answering ""do these colors work together?""",0,0
2016-09-02 17:33:42,"@runevision @mtrc @anneandkita In this tool, the complement is +180¬∞ hue, triad also fixed rotations. If not fixed, you need a model ;-)",1,0
2016-09-02 17:06:58,@davegershgorn Once I have more time I'll setup a stream of paintings made with photos from a reliable source... User submissions DM only.,2,0
2016-09-02 17:04:26,@davegershgorn ... and it will be exploited if it gets interest anything close to @DeepForger. Twitter provides no easy fix.,1,0
2016-09-02 16:09:47,@alan2here Firefox?,0,0
2016-09-02 15:33:23,@alan2here Log-out and try again? Works fine for me... forgery takes some time as usual.,0,0
2016-09-02 14:43:38,"@runevision I only used this approach for logo/website colors, but not generation of substantial textures and worlds.",0,0
2016-09-02 14:42:21,@runevision Use an abstract representation of palette (complement/triad) and just blend base hue? https://t.co/ZEhxtY8FOj @mtrc @anneandkita,2,1
2016-09-02 13:54:27,@davegershgorn Hmm. That Tweet looks familiar...,2,0
2016-09-02 12:50:53,"@Dom3D Yeah, I know what you mean! https://t.co/AN5KhGqxEP",0,0
2016-09-02 12:37:54,"@mark_riedl Hehe, I had the exact same thought‚Äîobvious name ""Zuckerbot"".",2,0
2016-09-02 11:13:01,"@agibsonccc More than 57% NVIDIA? Those are numbers from general ""gaming"" population. https://t.co/pHrlecRoOZ",0,0
2016-09-02 11:00:06,@agibsonccc Interesting! Do you know the ratio of NVIDIA to AMD?,0,0
2016-09-02 09:45:39,"Congratulations Micha√´l. Excited to see what comes out of your group! #FF AI, VFX, crowd simulation: @michaelrouille https://t.co/n42hgVr9Ah",4,0
2016-09-02 09:35:11,"11/ Take-away for anyone else watching: Open Source is a solid opportunity for marketing, but get a strong PR team on board from the start!",2,1
2016-09-02 09:33:05,"10/ Assuming the release was primarily branding, it's safe to say the bar was much higher since TensorFlow released. Needs stronger PR imho.",3,2
2016-09-02 09:29:21,9/ I'm still very surprised by the naming (associates low-tech w/ Baidu) and subsequent discussions why it matters: https://t.co/gUgymKIMYZ,1,0
2016-09-02 09:27:48,"8/ Launch timing was also strange: GitHub first but PaddlePaddle site had an empty ""coming soon"" page until last night, now news coverage.",0,0
2016-09-02 09:25:48,"7/ From a PR perspective, it's strange timing as a story of NVIDIA and Baidu collaborating is also hitting outlets: https://t.co/f2A5ZZzDRb",1,0
2016-09-02 09:25:14,6/ Would rather see more Lasagne/Keras/scikit-learn inspiration. It's cosmetic but that leaves an impression every time you use it...,1,0
2016-09-02 09:23:19,"5/ The API feels a bit uncomfortable, reminds me of PyLearn2: framework with opinions rather than reusable library. https://t.co/t2M2kxrM0x",1,0
2016-09-02 09:19:37,"4/ Democratizing Deep Learning could involve Windows and OpenCL support (advantage over TensorFlow), neither of whch PaddlePaddle addresses.",3,1
2016-09-02 09:16:28,3/ The article mentions the ability to use libraries such as BLAS and MKL for CPUs; Theano has had that for as long as I can remember.,2,0
2016-09-02 09:14:14,"2/ When TensorFlow released, it had a pip installable binary ready. PaddlePaddle has compilation instructions: https://t.co/2pr4v9GDLC",6,2
2016-09-02 09:13:14,"1/ Baidu's main justification for PaddlePaddle seems to be ease-of-use. Digging deeper, I'm not clear how it's more intuitive for beginners.",4,1
2016-09-02 09:09:55,Baidu's new deep learning framework is now hitting mainstream news. Almost dozen articles so far! (Thoughts below.) https://t.co/5FcJsSnjUr,10,5
2016-09-02 08:47:14,@TomNullpointer Doing it in 1080p HD will consume an unrealistic amount of the best GPU to pull off in real-time though ;-),0,0
2016-09-02 08:45:29,"@AmirSaffari Yeah, @DeepForger (now website only) uses this since January. DeepArt's results don't match though, looks different.",0,0
2016-09-02 08:44:21,@TomNullpointer It's there now if you assume a pre-baked style. See the #Prisma app: https://t.co/Uq1asWse3b,0,0
2016-09-02 07:58:48,"@iAmKeevee Currently you need a GPU to do these things, though some branches of #NeuralDoodle have prototype code to speed it up.",0,0
2016-09-02 07:51:06,@iAmKeevee What kind of thing do you want to do? Do you have Linux with CUDA setup?,0,0
2016-09-02 07:44:09,"The author claims that DeepArt.io uses ""Markov Random Field Regularization"" which is basically #NeuralPatches. Not sure, is there a source?",2,0
2016-09-02 07:43:01,"Yet another Neural Style implementation, this time in Keras: https://t.co/JvzbtDy76e Supports preserving colors: https://t.co/iUgj4RP4aB",35,10
2016-09-02 07:25:11,"@botminds By repeating the message that Google is great at AI (with actual substance), the subsequent news stories become easier.",0,0
2016-09-02 07:24:39,"@botminds If the bar is indeed lower (e.g. ParseyMcParseface), IMHO it's because Google's PR team strategically lowered it (e.g. AlphaGo).",0,0
2016-09-02 07:21:52,"Interesting result! The 9% surprises me the most, followed by the 24%. https://t.co/iEf4e9GKUi",0,0
2016-09-02 06:15:15,@deliprao @Smerity @edersantana It is incredibly uncomfortable for my primitive human brain how it work out. Relatd: https://t.co/e25NTrKm2b,10,0
2016-09-02 06:11:56,@deliprao @Smerity Mine was here: https://t.co/ppC8WndRBV but AFAIR @edersantana did it too ;-),6,0
2016-09-01 20:58:39,"@botminds Seems the only coverage they got was as ""also ran"" in TensorFlow announcements ;-) I don't think they did any PR at all!",0,0
2016-09-01 20:53:51,"@botminds @IgorCarron @F_Vaggi This one? https://t.co/eYMfso4Cm7 Name is fine, but never heard of it. What was missing?",0,0
2016-09-01 16:14:36,@basecamp Is there a status notification to know which participants are online? We currently rely on having Skype open to know...,0,0
2016-09-01 16:10:50,"@botminds @IgorCarron @F_Vaggi You're right, IBM is doing a pretty great job of its PR‚Äîregardless of the technology (not sure either).",0,0
2016-09-01 16:08:21,@botminds @IgorCarron @F_Vaggi Google == AI comes to mind first because they planned it that way. Opportunity was there for others too!,0,0
2016-09-01 16:06:56,"@botminds @IgorCarron @F_Vaggi The way Google handled AlphaGo showed deep PR strategy, was second-to-none for such technical breakthrough.",0,0
2016-09-01 16:05:24,"@botminds @IgorCarron @F_Vaggi It doesn't need to be (Baidu), but in Google's case it is very much a pro-active and the results show IMHO.",0,0
2016-09-01 15:58:31,@botminds @IgorCarron @F_Vaggi Interesting! Awareness vs. number of users is actually great way to measure PR. TensorFlow did amazing IMHO.,0,0
2016-09-01 15:49:24,"@botminds @F_Vaggi @IgorCarron Sorry, but the bar is much higher! If you want your DL framework to get attention you'll need to be clever.",1,0
2016-09-01 15:47:50,@botminds @F_Vaggi @IgorCarron I assume Baidu wanted to compete with Google for public mindshare about AI? Can't do that without PR now.,1,1
2016-09-01 15:45:10,"@botminds Why is company branding different than ""project"" branding (which includes the project name)? Why not apply same principles?",0,0
2016-09-01 15:44:12,"@F_Vaggi @botminds @IgorCarron Did you see how much press coverage they got for ParseyMcParseface, effectively second-grade technology?",0,0
2016-09-01 15:43:20,"@F_Vaggi @botminds @IgorCarron Yes, the difference is Google has the PR skills to play with mainstream awareness‚Äîincl. solid naming.",0,0
2016-09-01 15:39:40,"@botminds @IgorCarron @F_Vaggi The same mindset that decided it should be named ""paddle"" is what would prevent it from mainstream awareness.",0,0
2016-09-01 15:36:31,@botminds @IgorCarron @F_Vaggi So you're saying it had niche success despite its terrible name? IMHO that's the best case for paddle.,0,0
2016-09-01 15:33:24,"@F_Vaggi @botminds @IgorCarron Sure, poor naming problem is just one reflection of having no PR department involved. https://t.co/EV3pJaGZ5e",0,0
2016-09-01 15:28:12,@botminds @IgorCarron @F_Vaggi Do you think marketing and public relations is a skill or just random luck based on other factors?,1,0
2016-09-01 10:52:44,@JustusEapen I would suggest that those who don't know the difference are not familiar enough with marketing or PR as a professional field.,0,0
2016-09-01 10:51:52,"@JustusEapen I think it's possible to separate. An experienced PR person would notice, can then compare PR tasks to other big companies.",0,0
2016-09-01 10:29:59,@F_Vaggi You realize Rust is below Haskell? Niche excitement doesn't mean it's going anywhere‚Äîdespite org support. https://t.co/OdTscGudiw,0,0
2016-09-01 07:50:49,"FYI, I'm going to interpret ""Worse than most"" as ""I don't enjoy hearing about Google's AI in mainstream news so often."" ;-)",1,0
2016-09-01 07:45:17,What do you think of Google and its public relations / branding / marketing for AI:,3,0
2016-09-01 07:29:40,"@botminds Is that supposed to be a tautology, or ""because it's Google"" counts as PR for you? Does that apply to any big company?",0,0
2016-09-01 07:24:40,"@F_Vaggi I gave you two specific examples, incl. one split-tested as close as possible. There's whole scientific field behind it. What more?",0,0
2016-08-31 23:02:29,@grahamboree Don't get me started! :-) https://t.co/AN5KhGqxEP,0,0
2016-08-31 22:22:03,"@bnastic At least Microsoft can take comfort in the fact that everyone else failed too, soon including Baidu.",0,0
2016-08-31 22:20:59,"@bnastic 3) has been huge for community adoption, Python is the only reason TensorFlow picked up so fast. Community was already there!",0,0
2016-08-31 22:19:52,Microsoft's CNTK exposes a Python API (preview) since 1.5! Here's an LSTM example: https://t.co/HFKNHMYAUI #dlearn https://t.co/tG1dmKMcFI,50,38
2016-08-31 22:15:44,"@bnastic 3) is technical, no?

But make no mistake, Google actually delivered with TensorFlow. They got PR right as well!",0,0
2016-08-31 22:09:11,"But huge mistakes also: 1) didn't launch on GitHub 2) project name sucks too 3) custom language for models, no drop-in Python replacement.",5,1
2016-08-31 22:06:45,Microsoft's CNTK was a better attempt at challenging Google's TensorFlow from a PR pespective: clear selling point! https://t.co/BuaeFYctBQ,5,3
2016-08-31 21:39:32,I'd suggest the project name attracted the kind of developers who thought that interface was acceptable! @okayultra https://t.co/YK6d1thg3u,1,1
2016-08-31 21:29:17,"Which reminds me, I'm looking forward to Cialdini's latest book. Should be out in a few days apparently! https://t.co/XfUYSBUmUa",6,0
2016-08-31 21:25:29,Ever wonder why GIMP never hit the mainstream? The name is so bad you could assume a mole for Adobe suggested it ;-) https://t.co/ARnwMCHHda,13,3
2016-08-31 21:22:40,@botminds @F_Vaggi 4) the fact that some replies today still question importance of project names is why Google is winning at PR for AI.,2,1
2016-08-31 21:16:26,"@botminds @F_Vaggi
2) the name casts negative impressions on Baidu (low tech),
3) having a PR department on board early would have helped.",1,1
2016-08-31 21:13:38,"@botminds @F_Vaggi The core of my message is that ""Paddle"" is a terrible name:
1) improving it is easy and would have significant benefits.",1,1
2016-08-31 21:12:12,"@F_Vaggi @botminds You have to split test. A project akin to #NeuralDoodle released similar time, got 1/3rd GitHub likes, much less social.",0,0
2016-08-31 21:02:33,"@botminds @F_Vaggi TensorFlow has converted many ex-Theano users, some even from Montreal itself. It's not just new users.",0,0
2016-08-31 21:01:27,"@F_Vaggi @botminds Assuming you already know the importance of word choice, studied extensively in marketing and persuasion in general?",0,0
2016-08-31 20:57:02,@botminds @F_Vaggi Tensorflow beat Theano because Google learned from it and built a simpler product without compile times.,0,0
2016-08-31 20:56:01,"@botminds Haven't looked yet. If there is no advantage, a PR department would have (correctly) suppressed the release until there was.",0,0
2016-08-31 19:55:41,"@botminds @F_Vaggi Now Baidu will look bad for losing to Google, like everyone else did. Likely negative return from Open Source effort.",1,0
2016-08-31 19:54:26,"@botminds @F_Vaggi ""No compeling reason to switch"" is second biggest clue of lack of PR, should have been core part of messaging.",1,1
2016-08-31 19:53:15,@botminds @F_Vaggi Right. But if they had a PR department on board that would have come up right at the start. Clearly had none here!,0,0
2016-08-31 19:50:45,"@botminds @F_Vaggi Name alone can't sustain a project, but name alone can kill it if there's a full field of competitors. Let's see paddle!",1,1
2016-08-31 19:49:44,"@botminds @F_Vaggi Something still missing, I couldn't tell you what was different about Chainer. Name is definitely better than Paddle ;-)",0,0
2016-08-31 19:46:09,"@botminds @F_Vaggi Torch is a huge success, even promoting Lua. I'd say the branding was a huge success, but language is now an issue.",0,0
2016-08-31 19:43:28,"@botminds @IgorCarron True, product itself also matters too. iPad and Wii both were significant innovations in their respective categories.",1,1
2016-08-31 18:54:10,I felt educating about annotations+neural style was more important than pure tech. It worked well: I estimate reaching &gt;10M people. [2/2],2,1
2016-08-31 18:50:42,"Example: when I came up with the #NeuralDoodle hook, it resonated so well I threw out the paper I had written and started again. [1/2]",3,1
2016-08-31 18:47:34,Here is another good counter argument about the importance of naming algorithms/techniques by @mark_riedl. https://t.co/S5hat2AV3O,1,1
2016-08-31 18:46:07,"Also, think of it the other way around. ""Paddle"" does not reflect well on Baidu, and if it became popular, it would become a running joke.",1,1
2016-08-31 18:45:21,Branding is the difference between reaching 100 people and 100k. Developers may never even know about your project! https://t.co/hOyQH5hzfL,11,3
2016-08-31 18:42:31,@F_Vaggi Watch how many news outlets cover the press release and the tone of the coverage compared to what Google achieved.,1,0
2016-08-31 18:41:37,"I have absolutely no idea what ""third-generation"" implies, but surely Baidu engineers could figure out! Must address TensorFlow implicitly.",0,0
2016-08-31 18:39:04,"""Introducing Baidu Propeller‚Äîa third-generation deep learning library that accelerates the flow of your tensors."" 2m work, better already ;)",4,0
2016-08-31 18:33:32,"@craigperko I'm going to assume it's a joke because it's a good one! If not, let me know so I can mute you ;-)",0,0
2016-08-31 18:30:57,"Unfortunately, this is why Google is winning the AI public relations war. Everybody else lets researchers &amp; engineers pick important names!",3,0
2016-08-31 18:28:59,"Why would you want to paddle if your tensors flow on their own? In terms of branding, Paddle is worse than CNTK‚Äîwhich went nowhere.",1,1
2016-08-31 18:25:57,"Are you up deep creek without a paddle? (Good initiative, terrible branding Baidu.) https://t.co/Ord9bQ06GO",7,0
2016-08-31 07:31:04,"@dasmalle @Nifflas @samim For audio, there are some research projects but not (yet) as advanced as #NeuralStyle for images. Lots for MIDI.",0,0
2016-08-27 08:37:17,@caiitlinz Replacement nutella delivery? ;-),0,0
2016-08-27 08:29:59,"Are there languages today that let you (reliably) serialize a single coroutine/thread/process with its data, then resume execution?",5,2
2016-08-27 07:14:54,@billassault Lots of big decisions to make in the next few days/weeks! More soon...,1,0
2016-08-26 10:41:32,https://t.co/1TsvbEMGZt,7,0
2016-08-26 08:31:01,"@ogrisel True, though the baseline is already pretty reasonable, just some grammar or common sense missing.",0,0
2016-08-26 07:38:43,"Neural Clickbait? ""Title Generation for User Generated Videos"" https://t.co/VLP0utMoY5 Quite surprised by quality! https://t.co/BYmyW4PuLA",49,18
2016-08-24 19:25:31,@okayultra Then you'd better not go out in public!,1,0
2016-08-24 19:13:50,@okayultra You'd have to try it and see ;-),0,0
2016-08-24 18:43:55,"@okayultra Sure, higher confidence ratios.",0,0
2016-08-24 18:30:05,@okayultra It's a question of confidence. With features missing confidence would be lower... You can't predict everything from parts.,0,0
2016-08-24 18:21:42,@okayultra As long as you realize there are multiple valid answers to this problem‚Äîfinding the exact face is not possible‚Äîthen yes!,0,0
2016-08-24 14:46:15,@GalaxyKate Bonus points if I can take a photo of my fridge (or use product RFID) and have it generate my options for tonight!,0,0
2016-08-24 14:39:55,@GalaxyKate That sounds fun actually ;-) The most boring part would be shopping for the ingredients! But $8.99 would be tempting...,0,0
2016-08-24 14:27:16,"EVERY RECIPE PROCEDURAL
One base recipe and 125M variations depending how much salt you put in there :-P #generative https://t.co/VBRvaPkM4t",7,3
2016-08-24 13:14:53,"@sadeq84 @shahidkamal Given the cost, I'm betting one of them is AI: A Modern Approach ;-)",0,0
2016-08-24 10:48:35,@paniq Too many possible replies...,0,0
2016-08-24 10:42:38,@paniq Metal for the bits that need to be Terminator-proof. Fleshy bits to enjoy life.,1,0
2016-08-24 10:39:09,BONUS: There's a mediocre summer blockbuster contained in this Tweet too! Alien vs. Predator for the AI generation. https://t.co/YvomMw2NFC,6,0
2016-08-24 10:18:20,"@dribnet Ah, I see. It may not be novel mathematically, but the details of how it was applied is still interesting to document.",3,0
2016-08-24 10:11:55,@dribnet I can imagine! New section for the paper ;-),0,0
2016-08-24 10:02:48,"@smilevector @dribnet Impressive results! If you re-train a new network, would it be easy to integrate this or need such adjustments again?",1,0
2016-08-24 09:03:33,Sign my petition to start using Iron Man screenshots in Artificial Intelligence press coverage instead of Terminator.,28,3
2016-08-24 09:02:10,"By the time Skynet sends Terminators after us, we'll all be Iron People (with Jarvis). #Automation vs. #Augmentation https://t.co/7fH6KKzyup",34,15
2016-08-22 23:38:49,"Cube Composer: fun-ctional coding game. I end up randomly trying things, feels like Haskell! https://t.co/NFFNt5F1na https://t.co/Uhg4Bqs0YO",87,37
2016-08-22 13:09:26,"@SnstrMephisto Ah, I see. I have plenty of things to say on the technical even design front, just no desire to apply them in-game right now.",0,0
2016-08-21 08:00:03,"@deliprao I laughed at this line: ""on a low-end GPU like a Titan X"" ;-) But thanks for the great post!",4,0
2016-08-21 07:52:40,@SnstrMephisto I have nothing to say through videogames. https://t.co/26HjhTxCk2,0,0
2016-08-20 20:36:16,"@chrisnovello I hate it when people confound ""free market"" and capitalism. The first is/was destroyed by fundamental economic choices.",1,0
2016-08-20 20:32:41,@BobbyAnguelov @AngryAnt An animation paper? Must be worth reading if you spent 3h on it! ;-),0,0
2016-08-20 20:31:13,@richardmatthias No coincidence! All the BT patterns I coined are heavily borrowed from HTN.,0,0
2016-08-20 19:46:31,@neingeist What I'm working on is fiction ;-),1,0
2016-08-20 19:39:01,"This one is quite different from all the previous ones, but also a bit more difficult to get right. Need to see how far it'll go ;-)",0,0
2016-08-20 19:37:50,"If I admit to writing another hierarchical task planner test-driven on Saturday evening, what will you think of me? https://t.co/aGNbO23sZx",9,1
2016-08-20 15:46:49,"@lizardengland Interesting! Do you think we can make less predictable results emerge from generative systems outside games too, somehow?",0,0
2016-08-20 15:37:17,"@xDirtyPunkx So if the generative system was used as a tool by a human (or other) with empathy, it would be different?",0,0
2016-08-20 13:07:32,"@proc_gen Level designers greybox levels w/ annotations, artist create full quality 2m^2 examples, then tools apply the style automatically.",2,0
2016-08-20 12:51:11,"@proc_gen It haven't worked on anything 3D yet, but pushing the 2D technology in that direction. Nice way to split ""design"" from production.",2,0
2016-08-20 12:50:09,"@proc_gen High on my list too! At GDC I presented a ""Generative Pipeline"" for level design, using ideas/inspiration from #NeuralDoodle.",3,0
2016-08-20 12:34:03,"@proc_gen @jurieongames mentioned this, calls it ""invisible PCG"". A bit like SpeedTree does for vegetation.",2,0
2016-08-20 12:32:09,"@proc_gen Like automating the job of a specific artist, without needing a human that knows Photoshop / Z-Brush?",0,0
2016-08-20 12:31:27,"@algotrading_raf @prrgutierrez Code should be relatively trivial, you could use a Lasagne split layer, then convolution on the split chunks.",1,0
2016-08-20 12:29:00,@proc_gen Flexibility to match whatever artifact you need as development progresses?,0,0
2016-08-20 12:22:44,"@algotrading_raf @prrgutierrez Something similar in TensorFlow already, search for ""separated convolution"".",1,0
2016-08-20 07:44:46,@dribnet Impressive! How much data did you need to annotate to help debias? #NeuralPuppet,0,0
2016-08-20 07:18:30,"@jurieongames Or being able to generate custom geometry for #AR that matches your living room. You can't pre-build that upfront, new game.",1,0
2016-08-20 07:17:11,@jurieongames Playing a horror zombie game in VR will have a different impact if the level is based on your old school (layout / style).,3,0
2016-08-20 07:14:19,"@jurieongames (Missed this.) Commodity angle is predominant today, but Personalization direct to end-user opens up new experiences/emotions.",0,1
2016-08-20 06:51:15,@MikeNicolella :-| I find heavy keyword filtering and ad blocking necessary to use the site.,0,0
2016-08-19 20:55:19,Thanks everyone for the thoughtful replies! I will summarize each of the points tomorrow. It was a good day today ;-],6,0
2016-08-19 20:49:29,@sknthla Balancing is often done in Excel spreadsheets then w manual tuning based on play-testing. Lots of room for AI Powered‚Ñ¢ tools! [2/2],2,0
2016-08-19 20:47:55,"@sknthla Only a handful of game developers are using Neural Networks (SupCom2, Creatures, Black &amp; White). None for balancing. [1/2]",2,0
2016-08-19 19:51:33,@paniq @jurieongames @proc_gen I know what you mean. Sometimes I get the same feeling from watching Twitter bots.,1,0
2016-08-19 19:50:06,@paniq @jurieongames @proc_gen Parody fits in very well with this. https://t.co/txpMeUZsfu,1,1
2016-08-19 19:41:04,"@paniq @jurieongames @proc_gen Sure, but taking the ""hard work"" out of the equation. It's a new game type, bridge between roguelike and AAA.",2,0
2016-08-19 19:38:31,"@paniq @jurieongames @proc_gen For SpeedTree nobody will notice the difference between bushes but for, say, Hitman levels it's integral...",1,0
2016-08-19 19:38:00,"@paniq @jurieongames @proc_gen I agree with this. Basically it'll become a part of ""level design"" or ""object modeling"".",1,0
2016-08-19 19:32:41,"@jurieongames So if you imagine the emergent mechanics of Hitman, but put procedural levels or objects into it, it's a different game.",3,0
2016-08-19 19:32:02,"@jurieongames For me, the ""niche"" games define corners of the possible space of games, as we integrate new ideas we'll cover space between.",1,0
2016-08-19 19:17:15,"@jurieongames @proc_gen Good one! Because there are too many options, or trying to foresee the consequences in a specific application?",1,0
2016-08-19 19:13:48,@kcimc So is it about appreciating the human performance behind the piece? The skill itself a machine could replicate.,1,0
2016-08-19 19:11:36,"@kcimc I see: ""A human crafted this with tools."" At some level of smartness the tools would take away too much agency, then ""I could do it.""",2,0
2016-08-19 18:56:39,"@kcimc So it's the ""story"" around the piece itself that creates emotions when consuming the piece‚Äîbut they are not intrinsic to it?",0,0
2016-08-19 18:04:06,"@KenricMcdowell Ah, I see. So challenges integrating the generative component with the rest of the product/game?",0,0
2016-08-19 17:46:24,"@mark_riedl @AIIDEconference That said, I also agree with the statement the way you parsed it‚Äîonly slightly more controversial! :-D",0,0
2016-08-19 17:41:44,"@mark_riedl I understood it from the PR angle: ""If you're interested in #procgen then come and meet the experts at @AIIDEconference."" ;-)",1,0
2016-08-19 17:35:22,@kcimc What is it about human-created stuff that you like more? What if the human uses #generative tools?,2,1
2016-08-19 17:33:19,@GalaxyKate Cool! Can we listen online? It wasn't clear if/where a web-based player would appear...,0,0
2016-08-19 17:30:58,"@LucShelton Does the space of possible levels not cover enough ""unique characteristics"", or just too rare to be noticed by users/players?",0,0
2016-08-19 17:27:37,"@LucShelton Do you think the cause is designers not considering those ""after a while feelings""? Or it's hard to do technically?",0,0
2016-08-19 17:02:34,That's a big one. :-) It's like there are multiple challenges wrapped up in here! What's most difficult about this? https://t.co/wuzzzYIQPY,2,0
2016-08-19 16:44:16,What do you think are the biggest problems in applying #generative algorithms or #procgen techniques in practice?,24,6
2016-08-19 16:06:18,"@okayultra @Wikisteff There's so much data on social media: people too busy to Tweet, which connections, new conversations, job posts!",2,0
2016-08-19 15:45:30,"@agibsonccc Hehe, then a polite reply and close the Issue. Still useful for other people searching, but not worth worrying about!",1,0
2016-08-19 15:35:35,"@agibsonccc If issue comes up many times, I add it to snippet collection that people can copy/paste, then add features to simplify that.",0,0
2016-08-19 15:33:02,"@JonOlick @won3d However, this is hard to standardize as a metric that will remain useful over the years, and also subject to NN quirks.",0,0
2016-08-19 15:32:29,"@JonOlick @won3d The most promising recent ML work involves comparing image similarity in the space of another neural network, e.g. L3-L4.",0,0
2016-08-19 15:25:59,"@JonOlick @won3d I'm curious how you can tell! Visually, or looking at the PSNR from the graphs?",0,0
2016-08-19 14:55:00,"@mtrc @AIIDEconference It's likely down to who pays for the trip. If the company is paying, they might expect their name on schedule!",0,0
2016-08-19 14:00:10,@davegershgorn @alexhern Keep in mind I'm speculating ;-) Graphs do show some short-term gains on problems that we're already good at.,1,0
2016-08-19 13:58:38,"@alexhern @davegershgorn Imagine these adult brain ""modules"" hand-designed and each on their own GPUs: https://t.co/YwnP1Wvi75",5,5
2016-08-19 13:57:14,@alexhern @davegershgorn It's more about long term. IMHO we'll see biggest benefits training huge neural systems each on their own GPUs.,2,0
2016-08-19 13:25:43,"@gcpascutto Ah, I see. So for the MJPG format you could consider JPG's DCT approach as the I-frame coding?",0,0
2016-08-19 12:35:44,@gcpascutto Oh! I remember looking into BGP along w/ H265 but the easy-to-use tools were just not there yet. Can NN help with I-frame pred?,0,0
2016-08-19 12:31:40,"@gcpascutto Not sure, I know Dirac does, JPG2000 too and it's better than JPG. Can't remember other recent image formats... Lots in video!",0,0
2016-08-19 12:25:05,"Curious how this compares to more recent lossy codecs than JPG, in particular those based on wavelets.",3,0
2016-08-19 12:22:54,"Full Resolution Image Compression with RNN https://t.co/JOaC6HcjsD Google gets serious, outperforms JPGs everywhere. https://t.co/SpzEbWhlKA",87,38
2016-08-19 11:57:41,The cartoons by @Lunarbaboon almost always bring a smile into my day. This one is a perfect example: https://t.co/sJw5Ij0Nh7,1,0
2016-08-19 09:29:42,"@FloRicx Me too at first, then people asked questions I couldn't answer ;-)",1,0
2016-08-19 09:27:06,@FloRicx It is but it always felt like a hack. In this case it's a hack in the other direction. They fake restarts by increasing rate fast.,0,0
2016-08-19 08:38:25,Morning! Hope your day is looking as good as these plants on our balcony‚Äîif not flowers always help :-} https://t.co/n8IXsuqS8b,7,0
2016-08-19 08:04:04,My Hobby: reducing tough-ass math from academic papers into an easy to misinterpret (yet potentially popular) Tweet. https://t.co/PsPmBEp2Pj,15,1
2016-08-19 07:40:41,@lexiconjure samim,0,0
2016-08-18 17:26:03,I'm always surprised how much I learn in the process of documenting/explaining/teaching algorithms‚Äîeven compared to coding.,33,4
2016-08-18 15:50:41,"@nrose In this case, they're acquiring a new R&amp;D branch of the company (technology, team, experience).",0,0
2016-08-18 15:48:28,@quasimondo Sounds too easy ;-) I will check the source code when I have time later!,1,0
2016-08-18 15:38:05,"@Nexusdog_UK @McFunkypants @LarryD When done right you don't notice IMHO! In this case, the reaction indicates it was oversold...",1,0
2016-08-18 15:32:41,"@LarryD @McFunkypants Absolutely! Offline PCG will progress regardless of fashion cycles ;-) For online, just integrate pre-built modules?",0,0
2016-08-18 15:25:30,"@McFunkypants @LarryD If you can do it offline just by curation, then the jump to doing it at runtime isn't that big IMHO. Just tuning time!",1,0
2016-08-18 14:46:51,"@quasimondo Disclaimer: I haven't fully digested the paper yet, this is based on a quick scan of the important part.",0,0
2016-08-18 14:46:15,"@quasimondo It's a ""standard hack"" to decrease learning rate over time. Here they specify what to do with momentum and which weights to use.",0,0
2016-08-18 11:32:25,"- It's hard to train a deep network!
- Try turning it off and back on again?
*blank stares*
https://t.co/nuhVrQYQo5 https://t.co/roAwqUPHur",260,142
2016-08-18 09:41:49,"@Wikisteff Yeah, that's the tricky part. I'm also not always on board with inflation calculations / adjustments... Seems like a net drop :-|",0,0
2016-08-18 09:35:30,"@Wikisteff The histograms I saw recently suggest ""middle class"" in western countries is dropping, statistics hidden by developing countries.",1,0
2016-08-18 09:33:26,"@Wikisteff Do you have numbers for what used to be ""middle class""? Curious to see graph from there down to extreme poverty.",1,0
2016-08-18 09:27:32,"@Wikisteff In absolute terms, I presume it's increasing as the population grows. Percentage-wise, probably growing slower?",1,0
2016-08-18 09:23:29,"@Wikisteff I'm very curious about the rate of Poverty that's not ""extreme"". That seems to be increasing...",0,0
2016-08-18 08:17:17,@mjntendency @Autumnsburg I wonder if high-level patterns found by unsupervised learning (e.g. NN) could be an approximation for this...,0,0
2016-08-18 08:16:01,"@mjntendency @Autumnsburg Agreed. First there needs to be a ""perceptual"" representation, then measure the entropy there?",1,0
2016-08-18 06:34:37,@Tuplet Many tools afforded Level 2 because they worked based on axis-aligned bounding boxes (Doom era). Things improved!,0,0
2016-08-18 06:19:11,Great diagram! Seems most procedural generators are at Level #2 and don't check all those rules explicitly. #procgen https://t.co/X7ZONWwrwd,19,10
2016-08-17 13:21:00,"@tenpn BaseCamp seems like an alternative to Slack now. Better structured though, thinking of switching for next project...",0,0
2016-08-17 13:18:12,@tenpn Have you tried BaseCamp?,0,0
2016-08-17 12:48:39,"@_threeWiseMen I'm surprised the code still runs, it was written in 2012 apparently.",0,0
2016-08-17 12:42:10,"Generated Machinery, project by the Google Data Arts Team @ChromeExp https://t.co/3RbDCHIri8 ‚Ä¶ #generative #procgen https://t.co/y1ulQldRRZ",18,20
2016-08-17 12:06:02,@dasmalle Start with Versu then search for papers that refer to it on Google Scholar?,1,0
2016-08-17 11:31:31,"@larsiusprime These days we have Olympics and football World Cups instead! The Queen had a Jubilee in 2012, but no mention of debts :-|",0,0
2016-08-17 11:26:16,Money as Debt dates back at least to the Babylonian Empire. #BasicIncome as proposed would not change this concept. https://t.co/wHSUgewe4T,1,1
2016-08-17 10:18:24,@chrisnovello @graphific @samim https://t.co/iGugCC7mor,2,0
2016-08-17 10:06:46,"Not sure about the metaphor yet, but I think it's a good paper title... and it certainly beats the popular image of AI as Terminator!",3,0
2016-08-17 10:05:22,Subconsciously trying to associate current deep learning tools as crude as a scalpel and tweezers for brain surgery. https://t.co/PC5zGvHBtX,6,1
2016-08-17 09:58:58,"Curious how this would compare to training a pupil network based on a larger teacher, both in computation required and code complexity.",0,0
2016-08-17 09:58:23,"Dynamic Network Surgery for Efficient DNNs https://t.co/gjL4K9uC5C (Better than pruning, reduces AlexNet by 17,7x.) https://t.co/fp4gSw3ao1",13,7
2016-08-17 09:50:22,"@gpakosz @FlohOfWoe Yep, I checked earlier: https://t.co/zQzQorWw1J Looks great, keen to try it!",0,0
2016-08-16 19:18:07,"@Soukhinov See @deepselfie as an example, blog post is somewhere too... Good place to start!",0,0
2016-08-16 19:11:16,"Deep Neural Networks learn to answer the question ""when was that made?"" https://t.co/tnVJFmJPkd https://t.co/4craHx5J1U",37,15
2016-08-16 17:12:37,"@togelius @mike_preuss Oh, good idea! But still waiting for Pier to point me to the 2009 PDFs, they are not online either ;-)",0,0
2016-08-16 17:09:38,"@mike_preuss @togelius I wonder about making a central free/public repository for CIG like AIIDE, individual sites go down often.",0,0
2016-08-16 16:26:46,"@jackclarkSF Woah, fantastic for everyone involved! Congratulations.",0,0
2016-08-16 16:17:45,"@mike_preuss @AiGameDev Great, thank you!",0,0
2016-08-16 14:22:49,"A photo from @samim's presentation at #TheConf, showing #NeuralDoodle and examples by @netputing. Thanks @caiitlinz! https://t.co/4Z3h98j2Rx",5,0
2016-08-16 14:19:16,"@caiitlinz I had insider information, so was expecting it ;-) Feel free to ask the presenter tricky questions! /cc @samim",1,0
2016-08-16 14:12:08,@graphific I saw the slide content before I read @samim's name and was very surprised ;-) Hope it went well!,0,0
2016-08-16 13:09:03,@graphific Interesting. Lots of room for #generative ;-),0,1
2016-08-16 10:21:43,"The paper takes the idea further by integrating with residual approach. It's also a good comparison, but should change title to ""separable""?",1,0
2016-08-16 10:19:17,"@mike_preuss No problem, was reported by @AiGameDev followers so I thought I would pass on the information in case it can be fixed!",0,0
2016-08-16 10:18:51,"It's likely an education &amp; dissemination problem; Keras only added separable convolution a month ago (TF only), and not yet in Lasagne.",0,0
2016-08-16 10:14:25,"As @sedielem points out on Reddit, there are missing references to related architectures: https://t.co/7CfWS9B8Bn https://t.co/vuWsjpMNBT",9,2
2016-08-16 09:40:22,@mike_preuss Is there a chance to fix the redirect for CIG2014 proceedings? Requires sign-up now... https://t.co/mFvdjFNLhA,0,0
2016-08-16 07:49:30,@snagglechud I bet you're glad someone else did the hard part for you!,2,0
2016-08-16 07:32:39,"Factorized Convolutional Neural Networks https://t.co/RCicRmdL3V New layer representation, reduces compute by 3.5x. https://t.co/ulxoX2u6pY",101,55
2016-08-15 15:14:11,"@APreciousPony In some cases, it'd be more valuable for the company if you moved on and built on years of knowledge to solve new problems.",0,0
2016-08-15 15:13:22,"@APreciousPony So if the problem is bigger, you may end up spending time reinventing the wheel as it takes you longer to figure it out.",0,0
2016-08-15 15:12:13,"@APreciousPony It's an interesting topic! If the problem is solved already, likely you're being paid to learn as quickly as possible...",0,0
2016-08-15 14:06:16,@MatthewGuz @mark_riedl Someone needs to start a Name &amp; Shame tumblr or Twitter bot. Or maybe press just needs new photos...,0,0
2016-08-15 14:04:45,"@Strider_3029 +1. I would also drop that number for a Junior, and have a senior nearby. ""I'm thinking of digging into XYZ, make sense?""",1,0
2016-08-15 13:59:16,"In Python, gevent is better IMHO because it makes low-level decisions modular rather than viral. @evolutionalgd https://t.co/ypb1EGdQLO",1,0
2016-08-15 13:58:11,This is clever! It nicely formalizes some healthy team behaviors... Asking for help is harder than it should be! https://t.co/t7738vTEZt,9,7
2016-08-15 13:43:03,"In both cases, I feel guilty for not ending up with const or async keywords‚Äîbut it's often the language's fault for making it unbearable :-]",1,0
2016-08-15 13:37:15,C++ has also such awkward usage patterns: often you end up with duplicate accessors (const or not) depending where they are called...,5,1
2016-08-15 13:35:18,It's also hampered by Python's testing libraries don't work well in async mode: need custom wrappers and must re-implement default helpers.,0,1
2016-08-15 13:32:37,Using Python's asyncio feels a lot like C++'s const-correctness: it sounds good in theory but in practice it has viral impact on all code.,5,2
2016-08-15 13:29:30,"@snikolov If you don't have gradients then you'd end up with optimization that's more evolutionary, in which case it's likely been done.",1,0
2016-08-15 13:25:47,@BrainyBeard Look at all past #GameAI middleware companies and see which ones are still around and thriving.,0,0
2016-08-15 13:24:12,@BrainyBeard Not sure! So far investing in games middleware‚Äîespecially AI‚Äîhasn't been great business.,1,0
2016-08-15 13:11:05,"@xenox12345 Right, so the question is basically ""what games are designed well?"" :-)",0,0
2016-08-15 13:04:07,"@xenox12345 The challenge of AAA is that predictable behaviors are best for gameplay, but you expect human-level believability.",0,0
2016-08-15 13:02:28,@xenox12345 What genre are you looking for?,0,0
2016-08-15 12:54:54,"@xenox12345 What is ""well made""? Any great game you enjoy by definition must fit that label...",0,0
2016-08-15 12:28:29,"In the meantime, most teams are making #GameAI improvements with reliable incremental impact‚Äîas they have done for the past decade.",0,0
2016-08-15 12:26:39,"I suspect most publishers are happy to wait for technology to mature and collaborate with the winners, rather than take technical risks.",3,0
2016-08-15 12:26:03,"Game studios are investing in #AI in places (tools, procgen) but it's not the same level of hype yet. https://t.co/KwjKfbcQQN",6,2
2016-08-15 09:48:01,"@s_bura @rodolfor For everyone it's still useful for search and classification, robotic tone aside.",2,0
2016-08-15 09:40:36,@samim It depends if the net result of the conference is constructive or destructive ;-),0,0
2016-08-15 09:38:37,". @rodolfor The abstract says the results are not great yet, but ""useful"". I agree entirely, suspect companies have WIP versions of this.",2,1
2016-08-15 09:31:44,DeepDiary: Automatic Caption Generation for Lifelogging Image Streams https://t.co/pHSyLSPGw9 https://t.co/Ev2U0cfWQW,64,30
2016-08-15 09:29:56,"@SnstrMephisto However, I think big problems lie with the classical AI community (esp. planning) not promoting Humanism or going backwards.",0,0
2016-08-15 09:18:39,"@GET_TUDA_CHOPPA @mjntendency Right, that sounds like the opposite of Humanism ;-)",2,0
2016-08-15 09:11:06,"@mjntendency If you mean ""HTN are from academia"" so they can't be scorned by the community, you should talk to Dana Nau and Eric Jacopin ;-)",0,0
2016-08-15 09:09:32,"@SnstrMephisto If you look at ""GameAI"" from the late 90s only, maybe you have a point. But it's evolved a lot...",0,0
2016-08-15 09:07:20,"For Machine Learning, then ""Active Learning"" (from little data) is Humanist, where as Unsupervised Learning is mostly opposite: no agency.",1,0
2016-08-15 09:03:49,"@mjntendency Yes it was, about the time that #GameAI started in parallel. HTN was popular in other applied domains first, not games.",0,0
2016-08-15 09:00:01,"This elegantly explains why game studios had to ""reinvent the wheel"" for many #GameAI applications; they needed augmentation not automation.",2,0
2016-08-15 08:56:57,"For example, the planning community that scorns hierarchical solutions (like BTs from games) because they require designer involvement.",0,1
2016-08-15 08:55:36,Are Game AI techniques the Humanist counterpart to classical Artificial Intelligence algorithms?,8,1
2016-08-15 08:44:44,@graphific **Adds `reaping` and `demon` to the list...**,0,0
2016-08-15 08:40:55,@mphuget Only scheme but I never used it for non-educational purposes. Dodged Java by entering the AAA games industry ;-),0,0
2016-08-15 08:37:20,@graphific You're breaking my keyword Tweet filter! Which is worse? ;-),0,0
2016-08-14 18:30:16,"Doesn't include HTML, languages I used at University (Scheme, Prolog, Haskell), and also Perl/PHP because I blocked them out sub-consiously.",7,0
2016-08-14 18:28:02,"#FirstSevenLanguages I used to actually get projects done:
Basic, Pascal, Assembler, C, C++, Javascript, Python",13,0
2016-08-13 20:46:46,"Heh. If @samim and @graphific keep replying to these purposefully cryptic tweets you're going to assume we're working on something, right?",4,0
2016-08-13 17:39:57,"Ah, seems Twitter doesn't handle Unicode hashtags (yet). That would have been useful ;-)",2,0
2016-08-13 17:38:15,"Intense but fun few days in Amsterdam. Found the time to enjoy the city in the evenings. More soon, hopefully! #‚öò https://t.co/Ox6pDGGBae",11,1
2016-08-12 03:35:17,@Soukhinov They address it by testing on real data and show the benefits of training on this dataset alongside video captured images.,0,0
2016-08-11 21:49:54,Great day today! Lots of seeds planted... https://t.co/DmepX9jMsF,6,1
2016-08-11 21:25:55,Hacking GTA5 for Data: Ground Truth from Computer Games https://t.co/deQlry50Pq Clever! #dlearn #gamedev https://t.co/9YXnVvNbwa,56,43
2016-08-11 21:05:32,. @samim Amazon Lambda and Google Cloud TensorFlow are #MLOPS platforms :-D Register mlops.ai ‚Äî instant acqui-hire.,4,0
2016-08-11 21:03:11,Up-and-coming field with talent in short supply: machine learning meets development &amp; operations. Let's call it #MLOPS? Glamorous!,11,0
2016-08-10 18:33:10,"@Palmerin Proven safe within the full simulation, or a simplified model? Somewhat suspicious of the claim because it's complex system.",0,0
2016-08-10 18:17:48,"@bcrypt @saltyhorse Though there was an app based on the original paper (all along) but reached 1,000x fewer people: https://t.co/jDGKmcqkAS",1,0
2016-08-10 18:12:15,"@bcrypt @saltyhorse Not to detract from the work they did picking styles, improving the results, and deploying/scaling. It's impressive!",1,0
2016-08-10 18:11:17,@bcrypt @saltyhorse It's likely based on an open source version. Here's one of the more notable ones: https://t.co/sRyMtcVK2H,12,2
2016-08-10 18:10:01,"@bcrypt @saltyhorse The research they used for Prisma was from a few months ago:
https://t.co/zPxfpPmwEj
https://t.co/bTbPzYGUPc",7,1
2016-08-10 16:03:52,"@EnigmaDeus No, CUDA does not support SLI. You need to change the code to do this.",0,0
2016-08-10 15:02:08,"@jacquesdurden @ulkamilov Do you have a link to a paper on the topic? Likely it's not considered, but could be added as loss function.",2,1
2016-08-10 15:00:46,"@samim Getting frustrated with this ""Made by AI"". It's hand-chosen style, applied manually, and looks only slightly better than filter.",4,1
2016-08-10 13:33:40,"@ulkamilov I suspect NNs will need 10x-100x the capacity of these models, and segmentation-like architectures to better capture context.",0,0
2016-08-10 13:30:39,"@ulkamilov Some ""generative models"" do this already; wondering if anyone has applied this to super-resolution or image repair.",2,0
2016-08-10 13:24:50,@ulkamilov Big question: would increasing the capacity of SRCNN make it tend towards the example-based approach that uses nearest patches.,1,1
2016-08-10 13:23:29,@ulkamilov There's wide spectrum between example-based super resolution https://t.co/vbWMjbfcT4 and hand-coded loss. SRCNN in the middle.,2,1
2016-08-10 13:21:04,@ulkamilov You can say the same thing about how TV is designed.,1,1
2016-08-10 13:20:37,"@ulkamilov They do to some degree, you said they don't as results look like TV. Neural patches does it more reliably because example-based.",1,1
2016-08-10 13:16:08,"@ulkamilov That explains why neural networks do better, then! If you want them to inject speculative data into the image, see patch-based.",1,1
2016-08-10 13:15:19,"@ulkamilov I don't see the link between technology used and your expectations :-) Still better than previous approaches, room for more!",1,1
2016-08-10 13:12:57,"@ulkamilov Neural approaches to super-resolution perform better than other options currently, incl. TV. See the SRCNN paper it's based on.",1,1
2016-08-10 13:10:19,"@genekogan @quasimondo The deeper the network, the worse random initialization performs. https://t.co/k1Vr64CTxm",8,1
2016-08-10 13:08:55,"@ulkamilov It can't recover all the details, but it clearly found some ways to improve the image.",1,0
2016-08-10 11:19:59,"@KyleOrl I haven't read the paper yet, could be true ;-)",1,1
2016-08-10 10:42:54,"@memotv It looks like I may have under-estimated the technology they use, it might not be 90s mathemics (sic) based after all ;-)",0,0
2016-08-10 10:35:18,"@okayultra Maybe, but then they should brand it ""Deep Fuzziness"" or something? ;-)",2,0
2016-08-10 10:30:55,@rodolfor Enough capital to convince folks skilled in ML they don't want to work on Advertising Analytics and try something new instead ;-),2,1
2016-08-10 10:27:32,Later it turns out they hired a #GameAI consultant and the drone just teleports when human pilot is not looking. https://t.co/2kqi4CHsGY,25,11
2016-08-10 10:26:11,Further evidence that no significant advances in AI are required to disrupt technology/business/society as we know it...,8,2
2016-08-10 10:24:17,"Fuzzy Logic! *checks date on article* 2016. OK, so it's the right decade. (via @j2bryson) https://t.co/jFzQNCXx9R",6,3
2016-08-10 10:22:14,AI drone convincingly defeats human pilot in Air to Air combat simulation using Fuzzy Logic. https://t.co/b9fyX88DPV https://t.co/5qaj0DMyq3,13,9
2016-08-10 08:55:32,"9/ Finally, down-sampling the middle layers with convolution stride=2 gets better results than s=1. s=3 much worse. https://t.co/fxm8WNa9l2",0,0
2016-08-10 08:51:26,8/ Authors speculate that transfers work because solutions are similar. Indeed kernel weights look very familiar: https://t.co/yfnDWo3cmz,0,0
2016-08-10 08:48:55,"7/ Transfer learning works well: shallow to deep, HQ to LQ, and general compression artifacts to specific ones. Helps speed up process too!",2,0
2016-08-10 08:42:19,"6/ I mentioned training problems for ""image transformation"" networks here. Suspect batch normalization would help. https://t.co/cJqe7pP5kN",2,0
2016-08-10 08:39:30,"5/ Transfer learning is the idea of bootstrapping the training by starting with a smaller network / fewer parameters, then increasing size.",5,3
2016-08-10 08:38:35,"4/ Most interesting part of paper is about ""transfer learning"" which they investigate as a way to help deeper networks d &gt; 4 (!?) converge.",1,0
2016-08-10 08:36:00,"3/ Abstract makes a big deal out of ""large"" stride convolution (and deconv) but in the end it's the usual step=2. https://t.co/W43tHglgKC",4,0
2016-08-10 08:32:31,"@F_Vaggi I suspect it's both, but easiest way to reverse process is to learn common image patterns in kernels. It's worth studying!",2,1
2016-08-10 08:31:30,"2/ The architecture is pretty standard, heavily based on SRCNN, like many other recent papers: https://t.co/ebXKwWea9N",3,0
2016-08-10 08:25:29,"@F_Vaggi I suspect the network would benefit from being retrained on other compression algorithms, but do reasonably well without.",1,1
2016-08-10 08:23:28,"1/ The application of CNN to cleaning image artifacts is obvious by now (echoed in other papers), but glad it's studied in more depth here.",5,2
2016-08-10 08:20:35,Deep Convolution Networks for Compression Artifacts Reduction https://t.co/4YiPPMiYc0 #dlearn #ml (thoughts below) https://t.co/7EIGZVkZzY,37,8
2016-08-10 07:59:36,"@mtrc OK, let me know the details in whichever format you prefer!",0,0
2016-08-10 05:41:33,@mtrc Sure! Next few days will be busy though... What's your timeline?,0,0
2016-08-09 20:08:55,"The acquisition doesn't come as a surprise, but Intel does! Keen to watch how fast they can make an impact. https://t.co/tgCtpX1wF1",6,3
2016-08-09 10:14:06,This paper is a reference in the study of planning and classical AI in games. https://t.co/HTg9ps4qkX,12,6
2016-08-09 08:39:41,Robust Real-time Object Detection https://t.co/eMje33vicd [PDF] (via @neingeist) https://t.co/ued9XLW4sM,7,1
2016-08-09 07:21:48,@tiagoantao @raymondh But I've not looked at CPython's parser so it's pure speculation ;-),0,0
2016-08-09 07:21:01,"@tiagoantao @raymondh I'm starting to suspect is an implementation side-effect of ""for A in B"" syntax, where B can be a compound expression.",0,0
2016-08-09 07:13:04,"@raymondh Hrmm, maybe more of a questionable design choice for evaluation order :-)",1,0
2016-08-09 07:10:55,"@raymondh That's got to be a bug!

&gt;&gt;&gt; type(5 in range(10))
&lt;class 'bool'&gt;
&gt;&gt;&gt; type(True)
&lt;class 'bool'&gt;
&gt;&gt;&gt; 5 in range(10) is True
False",0,0
2016-08-09 06:16:00,6/ Training against procedural examples address most concerns but there will always be a decision boundary. Must build systems accordingly!,0,1
2016-08-09 06:13:37,"5/ Papers on spoofing machines get a lot of attention from the press, but they are usually &gt;1y behind recognition and fixed pretty quickly.",1,0
2016-08-09 06:10:38,4/ Any study of the decision boundary can be used to improve underlying DNN by using the examples additionally as part of the training.,0,0
2016-08-09 06:04:48,@atduskgreg Detection only? The big social networks and technology companies switched to neural networks for face recognition years ago.,0,0
2016-08-09 06:03:17,3/ The core assumption is that the machine's decision boundary should be similar to what's measured from humans: a fair default assumption.,2,1
2016-08-09 06:02:00,2/ A study of deep neural networks will similarly‚Äîand always‚Äîreveal decision boundaries with adversarial examples that look like exploits.,1,0
2016-08-09 05:58:23,"1/ The research is based on a 15 year-old algorithm (not DNN), which somehow they claim as ""industry standard"". https://t.co/lR5TQNlQ2A",2,0
2016-08-09 05:57:00,Spoofing 2D Face Detection: Machines See People Who Aren't There https://t.co/itlab4UBCB (thoughts below) https://t.co/3B3aa8ckwH,16,6
2016-08-08 19:25:13,. @LorenSchmidt Yes I'd say most people can understand such generative systems from examples too. Would love to hear about related research!,2,0
2016-08-08 19:11:39,"More #AR, doesn't get old. Next year they might have accessible commentaries‚Äîone can hope! https://t.co/00dtMpxRQr",0,0
2016-08-08 19:05:37,"It'll be fascinating to watch the community. Given two extreme instances of creatures/planets/fauna, can players interpolate possibilities?",3,0
2016-08-08 19:04:02,Do players feel they can infer the underlying rules of procedural systems by looking at single instances? #NoMansSky https://t.co/SIMFOBuvq0,10,2
2016-08-08 18:05:54,Augmented Reality visualizations in #TI6's drafts! https://t.co/pyHwSExJ88,4,1
2016-08-08 17:19:12,"@mtrc Oh gawd, they still haven't fixed chat. ** clicks ‚ñ∂ **",0,0
2016-08-08 15:20:48,"The idea of using ""gain maps"" is promising, ties into some of my recent experiments with explicit luminance. https://t.co/MZfbWHpxwb",5,0
2016-08-08 15:17:43,Interesting DNN architecture for real-time portraits. PDF on Sci-Hub: https://t.co/VPPeKG1mAQ (via @AhmedSelimTCD) https://t.co/MtUTK8zqnX,13,5
2016-08-08 15:02:52,Further scenes from the office earlier. More news as the situation develops! https://t.co/7XRJZ8v2CO,5,1
2016-08-08 14:54:02,@davegershgorn MSFT got an active social network for professionals out of the deal too. Still too expensive though!,1,0
2016-08-08 14:49:41,"Back to work after our vacation today, so many things to do. Feels a bit like this... https://t.co/kT1CPWbOks",5,1
2016-08-08 14:01:21,"In ~5 years, will DNN reconstruct any view from New York photos in 1800s? https://t.co/1pYa5OAccw via @BiellaColeman https://t.co/HbTX1WHzGo",11,0
2016-08-07 18:13:46,"@mykola The grand finale is over the top too, but I think it was required to prevent anti-climax.",0,0
2016-08-07 18:13:07,"@mykola I noticed they stepped up but in a good way: music, direction. Other episodes in S05 are closer in line with previous seasons...",1,0
2016-08-07 18:08:42,"@mykola I thought S05E01 was awesome, then enjoyed it until the finale. Not sure it'll get any better from your perspective then...",0,0
2016-08-06 11:33:43,"That's profound, bot! Censorship as an artform? https://t.co/y8zBsXUCa3",4,0
2016-08-06 10:35:12,"@dndn1011 If you give them a name descriptive of ""practice"", and people felt they needed a tutorial, maybe that's enough?",0,0
2016-08-06 10:05:52,"@dndn1011 How about making a tutorial as a sequence of mini-sandboxes with no explicit goals: dribbling, passing, shooting.",0,0
2016-08-06 09:17:06,"Yes, I realize that's the point of virtualization but knowing the state of graphics drivers it amazes me it works at all ;-)",6,0
2016-08-06 09:12:49,"GPU virtualization feels like black magic to me, but factor in slow-down &amp; you don't notice. https://t.co/IzyJOb4KBz https://t.co/vMmI0bVFd2",10,2
2016-08-05 18:30:28,"@noorshak DNN is now separate library, scikit-neuralnetwork. Just add all variables and use pipeline to normalize data. Keras may be better.",1,0
2016-08-05 14:21:27,@noorshak I may release an aggregate version of the data I had later this year with the @nuclai course.,1,0
2016-08-05 14:18:26,"@noorshak Yes, @DeepGabe had added value but the amount of work for a minor improvement over SteamSpy was not worth it for me.",0,0
2016-08-05 14:17:32,"@noorshak For example, @DeepGabe scored best overall by hedging its bets (lowering MSE) but that made for mediocre reviews / Tweets ;-)",1,0
2016-08-05 14:13:14,@noorshak SteamSpy has an API; could get the information out to do some predictions similarly too.,0,0
2016-08-05 14:12:25,"@noorshak Correct. Predictive is dependent on data and SteamSpy gathered more. Also, prediction depends on what you want to do with it.",0,0
2016-08-05 14:05:31,"@noorshak @DeepGabe It's not technical, I stopped the project. SteamSpy does a good job.",0,0
2016-08-05 07:40:57,@lexiconjure neuralize,0,0
2016-08-05 07:40:44,@lexiconjure neuralise,0,0
2016-08-04 21:12:15,"- Our goal is to prevent concentration of AI power.
(audience imagines House Of Cards theme tune)
- Now an overview of academic ML research!",17,3
2016-08-04 20:19:19,@feynmanliang I'm curious to see scores too. Other clips in survey were easier to notice differences. Was original work multi-instrument?,0,0
2016-08-04 20:17:07,@feynmanliang It's a pleasure! Avid follower of the field and your work is right up there ;-) BTW were there many differences in first clip?,0,0
2016-08-04 14:52:42,@j2blather The interesting part is how to design the model such that it does not require centralized action to function healthily.,0,0
2016-08-04 14:52:01,@j2blather Simple models are fascinating for this reason. You have to assume government(s) do not have intention to solve this.,0,0
2016-08-04 13:58:06,"@shinjipons @DeepForger Yes, couple more days then processing backlog.",1,0
2016-08-04 13:08:13,Semi-supervised Deep Hashing for Large Scale Image Retrieval https://t.co/cOfIaiFj9u (Insights into image search.) https://t.co/KMn9xyiOoc,39,13
2016-08-04 10:40:27,"@IgorCarron @samim It seems to be happening, e.g. giving up claims in the Arctic ring. Owners must realize their power is at risk.",0,0
2016-08-04 10:35:29,@samim @IgorCarron Yes. As long as you realize the magnitude of the radical scope required!,2,0
2016-08-04 10:33:25,"@samim @IgorCarron Government is so intertwined with these companies, hard to make a prediction disconnected from radical change.",1,0
2016-08-04 10:25:39,"@spysamot Read the thread, client-side applications need operating system support. Windows is dominant on PC.",1,0
2016-08-04 08:04:27,@spysamot Really?,0,0
2016-08-03 20:31:55,"@samim @AMarkdalen @bitcraftlab @liabru @graphific Some faster than others, recording issues will hold back certain ones. Behind schedule :|",0,0
2016-08-03 17:25:53,@BrainyBeard Film.,1,0
2016-08-03 17:20:18,@BrainyBeard Depends who you're talking about!,0,0
2016-08-03 17:19:36,"Oh, that's a great business move @codeplaysoft ;-) #TensorFlow https://t.co/veezeEe0Ho",9,0
2016-08-03 16:12:52,"I'd love to be proven wrong about this, but based on what I know it's likely going to take a while to see this one resolved!",1,0
2016-08-03 16:07:54,"@carlesgelada @RecklessCoding @jackclarkSF They wouldn't hire Windows developers, that's their mindset anyway‚ÄîTF acts as a filter.",2,0
2016-08-03 16:02:27,"Not supporting Windows makes client-side harder since you must port to Caffe, and as a bonus encourages users away from Microsoft ecosystem.",4,0
2016-08-03 16:00:16,Convinced myself TensorFlow is defective by design: no client-side deployments helps make cloud services profitable! https://t.co/yc2JOc0khg,6,1
2016-08-03 15:57:45,"@carlesgelada @RecklessCoding @jackclarkSF Not supporting Windows as first-class makes client-side deployment impossible, it's cloud only.",0,0
2016-08-03 15:53:55,"@carlesgelada @RecklessCoding @jackclarkSF It's not so much a ""position"" but a reflection of mindset. Check GitHub issues for interest!",1,0
2016-08-03 15:41:57,@carlesgelada @jackclarkSF It doesn't change my concern about the team's attitude to Windows.,2,0
2016-08-03 13:37:29,"@EvilKimau I don't either, but it's far ahead in other engagement metrics too.",0,0
2016-08-03 13:33:18,"Theano, even with a smaller team of volunteers and without luxury of redesigning from scratch, supports Windows‚Äîalbeit painfully for CUDA.",7,1
2016-08-03 13:30:25,"Sure you can use Docker as workaround for development, but second-class support makes client-side deployment on Windows impossible.",1,1
2016-08-03 13:28:17,"This trend particularly worrying given Google's attitude towards Windows support, it borders on disdain. https://t.co/biAh5Bx6Zt",11,4
2016-08-02 22:04:37,"@feynmanliang Wondering if you could exclude the seed from the sample played back, and making the clips shorter? But maybe it's a quiz bug.",0,0
2016-08-02 22:03:52,"@feynmanliang Hi, very impressed with #BachBot! Trying to take the quiz and having trouble even noticing differences, let alone assessing.",0,0
2016-08-02 21:01:50,If we didn't live in the city I think I'd be a dog person... https://t.co/DnkTSfAm4e,6,0
2016-08-02 12:31:52,"Indeed, insights from Inception v3 could likely speed up super-resolution too. https://t.co/dwcQUUovRh @graphific https://t.co/caDdzi76Ku",11,2
2016-08-02 11:44:19,"11/ Overall, it feels like the kind of paper that could be entirely automated using tools that search through possible NN architectures ;-)",7,1
2016-08-02 11:42:29,"10/ Idea is to let cheaper filters capture simpler patterns to reduce number of parameters, hence multiplications. https://t.co/1IaTQhr38U",4,0
2016-08-02 11:40:28,"9/ One obvious optimization missing is flattened convolutions: 3x1 and 1x3 alongside 1x1 and 3x3, then concatenate resulting channels.",2,0
2016-08-02 11:37:52,"8/ The idea of bottleneck features was popularized since 2013 with the ""Network in Network"" paper (NiN) https://t.co/53uVEoYFws",7,0
2016-08-02 11:34:45,"7/ FSRCNN uses bottleneck layers extensively: 1x1 filters to reduce number of channels in middle, then 1x1 to expand again before output.",1,0
2016-08-02 11:31:28,6/ Magic Pony has even better performance as this last layer operates at low-resolution using a new layer type for sub-pixel convolution.,3,0
2016-08-02 11:27:50,5/ This type of architecture is the same (but a few months later) as Magic Pony's that earned $TWTR's interest: https://t.co/IO4ESdV8rI,5,1
2016-08-02 11:20:08,"4/ Second speed-up trick involves processing image data at low-resolution, then up-scaling with deconvolution at lastest possible layer.",4,0
2016-08-02 10:48:37,3/ Performance actually increases thanks to this architectural change; it's a best practice since VGG paper in 2014: https://t.co/jMwGfHjVpM,8,0
2016-08-02 10:46:50,2/ First trick is reducing filter sizes from 5x5 or 9x9 to a series of 3x3 steps‚Äîwhich require fewer operations and perform well on GPUs.,4,0
2016-08-02 10:44:09,1/ The paper uses a subset of best practices in optimization to reach HD super-resolution at 24 FPS. Can trade off performance for quality.,4,0
2016-08-02 10:42:36,Accelerating the Super-Resolution Convolutional Neural Network https://t.co/KLabFv1oAQ 40x speedup. (thoughts below) https://t.co/7V4F42Sjfb,105,49
2016-08-02 10:16:30,"@dasmalle Things like adding variations, adjusting difficulty. If you use existing codebase/levels could work in the time you have left...",1,0
2016-08-02 10:15:49,"@dasmalle I'd look up some open source games and see what could be improved, most of the time there's an AI project there.",2,0
2016-08-02 09:52:37,"@dasmalle How many months will you work on it in total, project work + writing up? What are your favorite game types?",1,0
2016-08-02 09:36:07,@BrainyBeard Interesting question. Did you intend to attach a poll?,1,0
2016-08-01 19:34:12,@lucasa I'm not sure about that one; I'd consider it a separate field of research.,0,0
2016-08-01 19:18:21,@lucasa There are soooo many papers about this! Had this other tab open for a few days too: https://t.co/WKQhxkGEFy,1,0
2016-08-01 17:11:56,But it's Papert's ideas about using computers as tools for learning and enhancing creativity that will shine longest and brightest. RIP,6,1
2016-08-01 17:08:06,"In 1969, #SeymourPapert co-wrote the book Perceptrons w/ Marvin Minsky, proving some limitations of NNs at the time. https://t.co/iJr79zPTe5",5,2
2016-08-01 16:48:35,@j2bryson Acquired? Like you would a Roomba? :-),1,0
2016-08-01 16:03:27,"@YadFaeq @jackclarkSF No, likely this plus many ""production-level"" improvements: https://t.co/7XY5v1OcpZ",1,0
2016-08-01 16:01:36,"@edersantana @yoavgo Ah, I see! That's new to me. This one is very interesting too: https://t.co/5etBypwPsN",3,1
2016-08-01 15:52:13,"@edersantana @yoavgo Yeah, I wrote that just above ;-) https://t.co/UiNK9au4zN",0,0
2016-08-01 15:36:01,"@davegershgorn @mcwm Definitely cloud-based, I think you could almost manage 10-20 images per second on one Amazon g2.2xlarge EC2 instance.",2,0
2016-08-01 15:34:32,@davegershgorn @mcwm It's more recent technology. See this and the Tweet above: https://t.co/vOGiigoqsT,3,0
2016-08-01 14:21:54,@samim It's making an economic argument. What percentage of them use this approach?,1,0
2016-08-01 11:20:02,"Correction: I tried YUV and will experiment with LAB too. HSL/HSV don't work, hue is a discontinuous dimension. https://t.co/TEyr5pg71A",2,0
2016-08-01 11:05:15,10/ There's a great student project here: comparing performance of various combinations of deep &amp; shallow representations for images. EOT,3,0
2016-08-01 11:01:48,"9/ Architecturally, maybe introducing skip connections &amp; bottlenecks but avoiding potentially more complex ""image residual"" representation.",0,0
2016-08-01 10:57:03,"8/ Well, batch-normalization isn't mentioned in the paper above, so that would surely help. I found using ELU activations improves training.",0,0
2016-08-01 10:52:44,"7/ The problem then becomes as difficult as the original, and may suffer from hue or luminosity shifts again! What can you do? ¬Ø\_(„ÉÑ)_/¬Ø",1,1
2016-08-01 10:50:09,6/ I'm sure it could be addressed by inter-connecting the deep and shallow networks together‚Äîin the spirit of end-to-end training. However..,0,0
2016-08-01 10:48:07,"5/ I speculate it's harder because residual is highly dependent on base signal, yet both networks are separate so must re-learn patterns.",2,0
2016-08-01 10:45:01,"4/ I've noticed the residual signal for images is harder to learn. It looks like this, column (c) from the paper: https://t.co/rP3e2APXUP",2,1
2016-08-01 10:40:01,"3/ In the paper, shallow network is used as anchor and deep network learns residual, which resolves those problems in hue/luminosity shift.",0,0
2016-08-01 10:35:01,"2/ I've noticed similar problems also, and when switching to HSL the learned hue can also shift slightly, but visibly.",1,0
2016-08-01 10:33:00,"1/ The deep network alone can learn complex task of super-resolution, but authors claim it suffers from illumination changes. Local minima?",2,0
2016-08-01 10:31:22,End-to-End Image Super-Resolution w/ Deep &amp; Shallow Convolutional  Networks https://t.co/v6qNdTaBWy (thoughts below) https://t.co/qGoEycM5gE,60,25
2016-08-01 09:37:53,"@tenpn For comparison, try doing the same promotion in a month but announcing an old feature ;-)",0,0
2016-08-01 09:35:04,"@tenpn Congratulations! Did you promote/advertise the feature? If so, how?",0,0
2016-07-31 17:00:19,@tristanbergh I'm not sure what you mean. Merging the two seems possible but could be quite some effort!,0,0
2016-07-31 09:51:20,"Conversely it's missing resolution, photo-realism and high-frequency details which patch-based approaches could provide a bit easier.",3,1
2016-07-31 09:49:47,I find this interesting because it complements patch-based approaches well: using large data-sets to capture structure of specific images.,2,1
2016-07-31 09:44:02,Semantic Image In-Painting with Perceptual and Contextual Losses https://t.co/JdTw2iy2K5 Uses an adversarial DCGAN. https://t.co/WKUNJk9gx0,50,28
2016-07-30 10:02:57,"@Pentadact To be sure, you could also bias the probability of selecting the other option based on the streak count. @damian_isla",1,0
2016-07-30 10:01:02,"@dribnet If so, it confirms theory that dithering helps network make the most of its capacity to capture features at cost of pixel quality.",1,1
2016-07-30 09:59:31,"@dribnet Also, is it just me or do the reconstructions on the right capture more subtle details if you ignore the dithering?",2,1
2016-07-30 09:55:05,@dribnet It's a great sign you can reproduce these problems so fast. Should help isolate a fix much quicker!,0,0
2016-07-30 09:54:19,@dribnet What kind of reconstruction penalty? Were the network architectures the same?,1,1
2016-07-29 22:12:42,@dribnet I'd hope it would force some of the lowest level neurons to serve as dithering detectors.,0,0
2016-07-29 22:11:44,@dribnet Could use 2 of the 3 losses from that paper: combine low-level discriminator with high-level (same as now) into single decision.,0,0
2016-07-29 22:09:33,@dribnet Wondering also about benefit of shortcut from discriminator's lowest layers directly to the final decision. https://t.co/5etBypwPsN,0,0
2016-07-29 22:07:42,"@dribnet For dithering, I'd guess the discriminator is under-performing. Is that easy to notice as you increase its capacity?",0,0
2016-07-29 21:55:43,Evening walk. Lots to think about! https://t.co/JLEoN44DEl,16,0
2016-07-29 21:35:54,"@dribnet Ah, that makes sense ;-) Is dithering as obvious in 64x64 with 1/16th of the capacity?",0,0
2016-07-29 20:13:25,"@hernaez Not directly, in research maybe. I think these kinds of styles will reach kitsch status very soon...",3,0
2016-07-29 18:07:45,Would love to hear more about this approach to Delaunay stylization. Seems like that's worth it's own short paper too! ;-) @DmitryUlyanovML,0,0
2016-07-29 17:54:38,@DmitryUlyanovML My mistake. Conceptually different since activations are normalized separately vs. gradient that's normalized afterwards.,0,0
2016-07-29 17:49:46,"@DmitryUlyanovML Yes, for optimization-based approach all that matters is the gradients in the end... Equivalent to value normalization?",0,0
2016-07-29 17:48:17,Improving feed-forward style transfer w/ instance normalization. Right: 1080p Delaunay style https://t.co/KiNgYaZs1Z https://t.co/P9367DFPQT,61,20
2016-07-29 17:46:09,@DmitryUlyanovML Per-instance normalization at various convolution layers.,0,0
2016-07-29 17:05:49,"@DmitryUlyanovML You could also cite Anders who introduced the trick to Gatys' algo, later adopted by Justin. [3/3] https://t.co/OSamBQkfLB",0,0
2016-07-29 17:03:28,"@DmitryUlyanovML By normalizing, you're basically making assumptions about how style should be transferred, which is style-specific? [2/3]",0,0
2016-07-29 17:02:15,"@DmitryUlyanovML OK, gotcha. IMHO instance normalization helps with iterative style transfers too, but in those cases it's less clear. [1/3]",0,0
2016-07-29 11:40:51,"@dribnet I'd be curious to see comparisons with increased network capacity, though I understand it'd be harder and longer to train.",0,0
2016-07-29 10:21:30,"@memotv Worse, pointless rivalries within society are cultivated, whereas the real issues (rich vs. poor) are masterfully suppressed.",4,0
2016-07-29 10:19:20,@memotv A significant amount! What starts off as legitimate concerns that could be addressed turns into a crusade by ridicule and dismissal.,1,0
2016-07-29 09:46:56,@yoavgo If it's a loss function more flexible than MSE then it'd be an interesting experiment! I haven't yet researched alternatives.,1,0
2016-07-29 09:44:05,@dribnet Maybe weighting the smoothing factor with strength proportional to how late it's introduced? Likely less optimal though...,0,0
2016-07-29 09:41:58,"@yoavgo It will work, not sure about the quality. What kind of reconstruction loss?",0,0
2016-07-29 09:40:59,"@dribnet In my experiments training an auto-encoder (takes 4h to 6h) with perceptual loss, it's too late to add smoothing at the end.",0,0
2016-07-29 09:40:16,@yoavgo Just using MSE on pixel level isn't a good loss function for most image-generating architectures for this reason.,1,0
2016-07-29 09:39:04,@yoavgo If you plug in Gatys' network as the loss calculator then you end up with Justin's architecture. Otherwise results are more blurred.,0,0
2016-07-29 09:36:25,"@dribnet Not sure exactly, mostly on Page 1. But there are traces of dithering in many images. How long does it take to train from scratch?",1,0
2016-07-29 09:26:48,@yoavgo I mean loading and saving JPG files and shuffling them around takes more time than the GPU feed-forward part ;-),1,0
2016-07-29 09:20:06,"@yoavgo
https://t.co/bTbPzYGUPc
https://t.co/zPxfpPmwEj
Recent trick re-normalizing image features helps a lot for feed-forward.",19,3
2016-07-29 09:19:12,"@yoavgo Yes, it's feed-forward neural style. Likely takes 50ms on GPU, but even more work on CPU + network side.",4,1
2016-07-29 08:43:50,"10/ TL;DR, gradient descent is too smart for its own good. Could domain knowledge help re-architect networks to prevent dithering patterns?",1,0
2016-07-29 08:38:44,9/ For B. could increase the number of low-level convolution channels (performance cost) and add short circuit connection to final decision.,0,0
2016-07-29 08:37:13,"8/ Multiple fixes are possible: A. hard-code a total variation loss, B. try to bias the lower-level features of the discriminator network.",0,0
2016-07-29 08:34:49,"7/ If gradient descent ""decides"" to allocate capacity this way, then it's likely close to optimal according to the training objective ;-)",1,0
2016-07-29 08:31:43,"6/ If the discriminator cannot distinguish dithered images from original, then it's likely allocating its capacity to higher-level features.",2,0
2016-07-29 08:25:03,"5/ When the adversary of generator is learned, it should be able to detect these artificial patterns with a combination of simple neurons.",1,0
2016-07-29 08:20:18,"4/ The dithering is context sensitive, e.g. shades of brown or highlights. Here, black hair is reproduced perfectly. https://t.co/I1ZfFOKp0j",3,1
2016-07-29 08:18:05,3/ It seems dithering is a trick that networks can learn to generate perceptually accurate images with fewer convolution neurons/channels.,6,2
2016-07-29 08:16:14,"2/ If you increase smoothing (total variation), then results look OK but more blurred‚Äîas you'd expect if generator's capacity had dropped.",1,0
2016-07-29 08:13:52,"1/ When training a generator against a fixed adversary like VGG, dithering appears when you drop the capacity down and don't smooth enough.",3,1
2016-07-29 08:12:11,"Did you see @dribnet's amazing faces? Going to speculate about the dithering patterns, hopefully to learn something. https://t.co/KRR7jSMnYj",15,1
2016-07-29 07:22:32,"@TheAdamRomney RO2 are in the SDK from Steam Store under Tools. Requires running their editing tool to open, also from SDK.",1,0
2016-07-28 20:22:26,"@TheAdamRomney Most presentations about AAA BTs include examples or slides, but rarely the whole tree. But enough to determine granularity!",0,0
2016-07-28 20:20:45,"@TheAdamRomney The CryEngine used to have XML-based BTs too (Crysis series, Warface) but not sure how easy to extract.",0,0
2016-07-28 20:18:24,"@TheAdamRomney With full data? Red Orchestra 2 has them in SDK online, Alien: Isolation apparently had XML BTs.",0,0
2016-07-28 20:02:37,"@GalaxyKate @amzeratul For nationalities represented, finding it hard to reach beyond Mediterranean and middle east. Stream helps a bit...",1,0
2016-07-28 20:00:20,"@GalaxyKate @amzeratul For gender it's improving noticeably every year,  topics too. Rich part hard to measure, but getting worse I suspect.",1,0
2016-07-28 19:48:26,@mark_riedl TL;DR. Some kind of MCTS? @diego_pliebana,0,0
2016-07-28 17:30:12,"@EnigmaDeus Each render does not speed up with disk access, but SSD generally faster if you do a lot of image pre- or post-processing.",0,0
2016-07-28 17:20:49,@EnigmaDeus No preference.,0,0
2016-07-28 17:16:29,"@EnigmaDeus Based on current open source implementations, yes. If you want to future proof and have the cash, upgrade RAM and CPU.",0,0
2016-07-28 17:09:55,"@EnigmaDeus It depends on how the code handles out-of-memory errors, likely no faster to parallelize with current open source projects.",0,0
2016-07-28 17:08:33,"@EnigmaDeus There are ways around the problem if you can't afford the second machine, e.g. rendering overnight.",0,0
2016-07-28 17:03:29,@EnigmaDeus You can probably just take your current PC and upgrade the GPU. Technology is moving fast so next versions will improve.,0,0
2016-07-28 17:00:36,"@EnigmaDeus Memory is the biggest factor for resolution, better the card the faster the result. It'll take a bit of work to get reliable HD.",0,0
2016-07-28 16:57:57,"@EnigmaDeus Get the NVIDIA graphics card with the most memory you can afford then. Linux much easier to setup, works out-of-the-box.",0,0
2016-07-28 16:56:27,"@EnigmaDeus The rest of the PC's build is not important, just the graphics card given current technology.",0,0
2016-07-28 16:55:55,"@EnigmaDeus Depends on the resolution you need, can work with NVIDIA's 970 to 980 all the way to Titan X or latest 1080. Linux is easier.",0,0
2016-07-28 16:54:39,"Shame the images are only 300x300 at most, doesn't help scaling up resolution of GAN/VAE. But original URLs are listed for manual download.",3,2
2016-07-28 16:53:16,"Find the ""aligned faces"" version as 59GB download here: https://t.co/PSMGVT7ZdW https://t.co/rZiENTQXqi",12,5
2016-07-28 16:49:59,10M photos of ~1M celebrities by Mcrosft. How much better will generative models become now? https://t.co/JndbHOJJ1m https://t.co/bTJPjKJWOc,45,16
2016-07-28 13:17:15,@DmitryUlyanovML I had some normalization in the #NeuralDoodle branch but disabled it because it sometimes made things worse...,0,0
2016-07-28 13:16:31,@DmitryUlyanovML The results look great! Did you evaluate (formally or not) which styles need instance normalization and which don't?,0,0
2016-07-28 09:14:57,"@ngutten However, there's no guarantee it'd impose human-like encodings: dark means sad or angry, implies minor keys, etc.",1,0
2016-07-28 09:14:14,"@ngutten As long as you enforce perceptual constraints on the various media (images, music) the encoding used should be interesting!",1,0
2016-07-28 09:04:23,"@ngutten It'd be interesting to see how it stores ""hidden"" information in the musical encoding!",1,0
2016-07-27 08:36:29,"@ilyaeck ""Able to get a good review from a random user in their GitHub repository."" :-)",0,0
2016-07-25 20:29:22,@ivanassen I know what you mean. I rant about this regularly then delete tweets. It takes me ages and I've done it before!,0,0
2016-07-25 20:28:22,@ivanassen Google basically is anti-Windows and they drag their feet to make TensorFlow work there. Theano works but it's a pain...,0,0
2016-07-25 20:27:19,"@ivanassen I know, that's why Docker is recommended. The new branch is so fast it doesn't require GPU, which means it should be easier.",0,0
2016-07-25 20:26:30,"@ivanassen Docker is in a transition and has many rough edges, but the new beta is much easier to work with if it runs on your machine.",0,0
2016-07-25 20:04:56,@skittlesolives Filter makes it look Mediterranean ;-),1,0
2016-07-25 18:35:52,Flew on Sunday to join the kids on Summer vacation. Need to find some time to finish wrap-up the conference :-) https://t.co/pArNnVthaH,15,0
2016-07-25 09:16:13,@jmatosziuk Thanks. I appreciate you taking the time to dig up and old thread to troll me. Original question about visuals remains open!,0,0
2016-07-25 09:13:56,@vivek_kumar @ColorizeBot @samim I know! I had the same problems. Just keep an eye on it daily (or so) and it should work out...,0,0
2016-07-24 13:58:18,"@jmatosziuk It's a company name ;-) Besides there was no criticism, it was Kirk who lashed out publicly after sensible question.",0,0
2016-07-24 08:51:28,@ColorizeBot @samim @vivek_kumar Porn. Abuse. Trolling. @DeepForger was suspended twice and it was only replying not posting publicly.,0,0
2016-07-24 08:48:14,"- Did you know I set up a Tweet filter for violent keywords?
- Your feed must be nice!
- Don't know yet, it hasn't updated since 2015.",11,0
2016-07-24 06:44:48,@samim @ColorizeBot @vivek_kumar Nice! I just worry that sharing submissions publicly will become a risk as the bot gains popularity.,0,0
2016-07-24 06:25:58,"@bitshifternz @KeirRice Could take a bit to build up good defenses, I have ~100 filter patterns now! Also miss occasional false positives.",0,0
2016-07-24 06:24:35,@bitshifternz @KeirRice I still use it now. https://t.co/DwFiZhTtAX,2,0
2016-07-23 18:56:42,"@KirkDBorne @AlexCEngler I'm sorry, I don't understand your perspective. Going to unfollow and may re-assess if/when things calm down.",0,0
2016-07-23 18:47:32,"@KirkDBorne I'd like to hear discussion/answers for @AlexCEngler's original &amp; honest comments about the visuals, not publicly attacking him.",0,0
2016-07-23 18:46:29,"@KirkDBorne The first statement is qualified and likely true, the second is a question. Both were thoughtful and respectful. @AlexCEngler",0,0
2016-07-23 18:33:51,"@AlexCEngler @JDavidMorris The whole thread is surreal from a Professor. Contradictions, ignoring honest questions, and outraged Reply-All?",0,0
2016-07-23 18:07:55,"@KirkDBorne I'm one of your followers and did not get it, nor did I feel criticized. @AlexCEngler brought up a good topic in thoughtful way.",2,0
2016-07-23 17:59:25,@AlexCEngler @KirkDBorne Agree with this. Are there any good visuals you know of to use instead?,0,0
2016-07-23 17:35:54,"@KirkDBorne Oh, I'm getting confused... Not sure if it's terrible or humorous.
https://t.co/0ocmR2X8xd
https://t.co/qIQtyz78jz @AlexCEngler",0,0
2016-07-23 17:29:33,@KirkDBorne I've followed you for a bit without knowing field well and didn't realize such tweets were humorous. Agree with @AlexCEngler!,2,0
2016-07-22 22:42:51,@ferrouswheel I'm expecting the economy to slow significantly more towards the end of this year. They're just planning ahead.,0,0
2016-07-22 15:56:15,"@brenoazevedo Sure, but it's also not the focus of the question, I'm asking you to assume that to answer ;-)",0,0
2016-07-22 11:34:08,@dribnet Looks very cool! It's often the simple tricks combined with the more advanced techniques that perform best ;-),1,0
2016-07-22 11:13:18,@dribnet The nearest neighbor is surprisingly effective at making the problem simpler. Could help a lot with #NeuralDoodle too.,0,0
2016-07-22 10:26:34,@Donzanoid Is there anything you didn't do? ;-) Did you have positive or negative impressions afterwards?,1,0
2016-07-22 10:22:16,I attribute this to bringing together people from different fields &amp; backgrounds; it helps new ideas emerge where you least expect them.,5,0
2016-07-22 10:18:07,Love it! It's only been two days since #nuclai16 and ideas are already making their way into development... https://t.co/R0NoqhEdPG,13,2
2016-07-22 09:24:55,"Quad espresso? When @speedingdeer was here last week he increased our coffee settings, took a twitchy day to notice! https://t.co/MDKo2ffihU",3,1
2016-07-22 08:41:20,"@ivanassen I didn't see much research on generating good textures to match the terrain (a few #NeuralDoodle recently), seems easy enough.",0,0
2016-07-22 08:40:17,"@ivanassen For terrain, multi-layered noise works fine‚Äîbetter if you overlap some set pieces from data. https://t.co/BFIvenIQnz",2,0
2016-07-22 08:39:44,"@ivanassen It's possible to generate all components of a landscape to very high-quality with standard tools, just requires art direction.",0,0
2016-07-22 08:20:19,"You can try the algorithm on their site by submitting an email, though still in beta: https://t.co/6ner1MEk7k https://t.co/w5BPNcgqCi",6,4
2016-07-22 08:19:15,"An image query engine that morphs outputs to match input: https://t.co/8pDR9DZbki ""Transfiguring Portraits"" [PDF] https://t.co/eaWwRfkpgU",163,114
2016-07-22 07:57:58,"@nathansttt Agree. I was trying to phrase the question in more personal terms, assuming research had already been done.",0,0
2016-07-22 07:56:32,"@BrainyBeard My question was more about the ""what if it's not"" and its personal impact on you.",1,0
2016-07-21 23:32:47,"@Autumnsburg I think blogs do because of social media, possibly more so. You look stupid in front of your peers *publicly* if you don't.",0,0
2016-07-21 23:30:58,@Autumnsburg Most of my closed review comments never get implemented into academic papers. At least Reddit discussions are public.,0,0
2016-07-21 23:30:05,@Autumnsburg The notion that only academics do scholarship feels as pretentious as the introduction of most papers ;-),0,0
2016-07-21 23:28:42,"@Autumnsburg The review is public, there's back-and-forth discussion, thoughts are rated/voted. It's changing the way research works.",0,0
2016-07-21 23:27:14,"@Autumnsburg If you include ""social media"" in this format, then I think it's a far superior way to review than most conferences.",0,0
2016-07-21 23:25:32,"@Autumnsburg The balance is useful. But applies elsewhere: if you make aggrandizing claims on a blog, you'll get called out on, say, Reddit.",0,0
2016-07-21 23:23:57,"@Autumnsburg The best papers do it well, but for many it can be simply misleading. Why not admit it's just the same as artistic drive?",0,0
2016-07-21 23:22:58,"@Autumnsburg @mjntendency @togelius The reviewing is much more valuable than notion of ""scholarship"" IMHO, like in Open Source.",0,0
2016-07-21 23:20:46,"@Autumnsburg I reviewed enough papers to know there are many ""motivation sections"" that are just nonesense. Sometimes obvious only later.",0,0
2016-07-21 23:19:06,"@Autumnsburg @mjntendency Practitioners may not pretend they have justifications. Researchers must, but may get it wrong. Is any better?",0,0
2016-07-21 23:17:25,"@Autumnsburg @mjntendency ""Researchers put the thing they have done into context."" On average, this is no better than random justification.",0,0
2016-07-21 23:16:28,"@Autumnsburg @mjntendency Not sold. Blogs are based on general consensus, assuming it does not need repeating. In fast field, it does not.",0,0
2016-07-21 23:09:32,"@mjntendency @GET_TUDA_CHOPPA After a talk, you could just as easily refer people to read your blog with code snippets or GitHub link.",0,0
2016-07-21 23:08:51,"@mjntendency @GET_TUDA_CHOPPA I like the paper format too. However, their conventions have lots of self-aggrandizing pretensions too!",0,0
2016-07-21 23:07:42,"@spysamot Based on the poll, the word ""researcher"" seems to cover engineers solving problems with new science and artists exploring for fun.",0,0
2016-07-21 22:51:48,@spysamot Why would you move? Because you want to work on something novel rather than your enjoyment of arithmetic?,0,0
2016-07-21 22:36:34,@Frozen_Pixel That's OK I think. I don't presume all researchers have personal interest and I want the poll to measure it.,0,0
2016-07-21 22:32:31,"@spysamot Oh, you mean a past example? Basic arithmetic.",0,0
2016-07-21 22:30:29,@Frozen_Pixel So far 57% are not. More engineers dedicated to solving problems?,0,0
2016-07-21 22:29:45,@pmawhorter @GalaxyKate Is it the objective exploration of such edges that drive you rather than the subjective enjoyment of it?,0,0
2016-07-21 22:28:11,@Frozen_Pixel So you'd consider researchers and artists to have similar traits?,1,0
2016-07-21 22:24:09,@spysamot Let's say we could reinforcement learn any computable problem.,0,0
2016-07-21 22:23:40,"@dribnet @genekogan Yes, definitely given appropriate random seeds. I added a --variety parameter though, not sure about that.",2,0
2016-07-21 22:22:52,"@GalaxyKate The novelties are likely subjective, in this and many cases. Wonder if researchers would continue if their exploration was too.",0,0
2016-07-21 22:20:04,"@dribnet @genekogan I like patch-based methods for this reason. IMHO they are better tools for many specialized purposes that are not ""Art"".",1,0
2016-07-21 22:18:59,"@dribnet @genekogan It's because feed-forward networks are unable to replicate ""global"" style distributions, unintended side-effect. [2/2]",3,0
2016-07-21 22:18:10,"@dribnet @genekogan I'm not surprised by frame-to-frame consistency, it's similar to localized patch-based approaches. [1/2]",2,0
2016-07-21 22:17:16,"@GalaxyKate I realize you're trying to say it's an infinite space, but I'm trying to separate personal enjoyment vs. exploration of ""novel"".",0,0
2016-07-21 22:13:56,@GalaxyKate I tried to cover both artistic exploration &amp; technical solution. What if it had all been covered by generations before?,0,0
2016-07-21 22:06:09,"Researchers: if you knew your subject had been explored or solved before, would you still be working on it?",3,1
2016-07-21 21:58:34,"@ivanassen Like everything, it depends. What's the purpose?",0,0
2016-07-21 21:57:08,"@GET_TUDA_CHOPPA Streaming, broadcasts, blogs interviews, conferences are for real people and papers are (pretense to) future investment.",1,0
2016-07-21 21:55:19,"@GET_TUDA_CHOPPA To me it's like a duality between doing things that help people today vs. doing something that feels more ""permanent"".",2,0
2016-07-21 16:57:37,"Academic practices are hard to identify with, but the community behind it resonates louder anyway. Focus on that, Tommy! @GET_TUDA_CHOPPA",1,0
2016-07-21 16:45:23,"What kept us going? It was friendly hugs, sincere handshakes, emails with thanks, tweet compliments. Commit those to read-only memory!",2,0
2016-07-21 16:41:31,I remember in the early years of @GameAiConf it would take us months to build up the courage to start preparing for the next year.,0,0
2016-07-21 16:39:58,"Tommy wrote some thoughts about recognition. I don't think it's specific to YouTube, actually‚Äîanything different: https://t.co/nkQ1AZUQyw",1,0
2016-07-21 16:38:39,"It grew despite the audio streaming issues, and without me doing much promotion (due to being so busy). Interest in the field is growing!",1,0
2016-07-21 16:35:30,"Didn't have time to check the statistics until now, but the @nuclai stream this year got many more viewers than last year! #CreativeAI",3,0
2016-07-21 16:30:51,This is what @tweetgameoflife had to say about the #nuclai16 stream. Started slowly then into a crescendo: https://t.co/737SECNmNm,3,2
2016-07-21 16:27:00,@tweetgameoflife Did you watch the #nuclai16 stream? ;-),1,0
2016-07-21 16:26:14,@tweetgameoflife Is life a game?,1,0
2016-07-21 16:22:35,@tweetgameoflife What's the meaning of life?,1,0
2016-07-21 16:14:39,@smilevector @dribnet Soon time to switch with the #NeuralPuppet hashtag? ;-),1,0
2016-07-21 16:12:31,I'd happily watch a live stream of this on loop with generative music ;-) https://t.co/lHBC8an6C8,2,0
2016-07-21 16:09:28,"@avyfain It was announced short notice, but you have another 18h if that helps ;-) https://t.co/CWIxg1QpVL",0,0
2016-07-21 15:46:25,"@nrose No, you can disable it in the options.",1,0
2016-07-21 15:34:49,@dribnet Many thanks for tweeting under #nuclai16bot. Will you DM an address we can send a #nuclai16mug? ;-),0,0
2016-07-21 15:34:10,@inconvergent Many thanks for tweeting under #nuclai16bot. Will you DM an address we can send a #nuclai16mug? ;-),1,0
2016-07-21 15:33:18,@zefyear Many thanks for tweeting with #nuclai16bot. Will you DM an address we can send a mug?,0,0
2016-07-21 15:28:04,Is this Prisma vs. Pikazo? ;-) https://t.co/wbfwbwZG7c,2,1
2016-07-21 12:39:47,"@chrisboden Can I add more superstars? Alphabetically:

@ahandvanish
@aparrish
@dribnet
@inconvergent
@GalaxyKate
@genekogan
@rossgoodwin",10,0
2016-07-21 08:41:06,My @nuclai mug shot this year. It's a tradition now ;-) #nuclai16mug https://t.co/PNTj9NkZMK,7,1
2016-07-21 08:05:54,"If you're still in Vienna and want to meet indies and game developers any time during the day, head over to MQ! https://t.co/rE7P2QByhG",4,2
2016-07-21 08:05:00,"Two thirds of the recordings will be online relatively soon, we hope. For the rest, I considered this is an option! https://t.co/wpaDLttPIO",8,3
2016-07-21 08:03:52,"It's part of the job, I guess. Here's my puzzled selfie face from yesterday before I read your inspiring tweets ;-) https://t.co/6QOj2IrMZs",11,0
2016-07-21 07:52:07,"Before starting, we thought of @nuclai as a protective bubble. Took more effort to maintain that metaphor this year! https://t.co/b3mt9UxkBu",4,2
2016-07-21 07:25:43,Independent and 100% neutral reports indicate it was the best #nuclai16 conference so far! ;-) Awake already as my brain is buzzing.,22,2
2016-07-21 07:06:30,"@clodericmars Thanks again for all your help this year. Have a safe flight, Clod√©ric!",2,0
2016-07-21 06:59:46,"@BrainyBeard Audio will take some work for 25% of talks, fingers crossed we can come up with creative solutions.",1,0
2016-07-21 06:56:19,"@BrainyBeard Extremely well! Reports indicate best ever on-site, but I was sad we couldn't get good audio on stream.",1,0
2016-07-20 17:05:32,Done. Success! Now empty nest syndrome. https://t.co/Yzpdf4AbC4,19,0
2016-07-20 10:37:37,"Just adding vocalizations ""Everything's under control, step aside."" and ""Nothing to see here."" was enough to sell it for second iteration!",2,1
2016-07-20 10:36:47,"Funny stories in systemic panel: when first adding ""body dragging"" to HITMAN, NPCs ended up going past shops and nobody noticing. #nuclai16",4,1
2016-07-20 10:23:14,@ngutten I think so. @graphific is talking about it later!,1,0
2016-07-20 10:22:07,"@AsserFahrenholz Ah. We have indie packages, though you can't buy it automatically you need to email us so we can confirm you!",0,0
2016-07-20 05:54:11,"In fact, @smilevector does afantastic job of summarizing #nuclai16 for me. Extreme highs (people) &amp; lows (stream). Hoping not many noticed!",0,0
2016-07-20 05:53:00,"The affiliation is a human error, but the #NeuralPuppet is automated genious ;-) https://t.co/LE95NfksAi",1,0
2016-07-20 05:48:22,"It can be a new bot, or an existing bot. Not sure how many mugs we'll have left, but we'll save at least three to send out randomly...",0,0
2016-07-20 05:47:38,"If you want to win an amazing limited-edition @nuclai mug, have your generative bot tweet with #nuclai16bot! https://t.co/1aXgDZfQJl",3,4
2016-07-19 23:01:50,"@skinjester Having trouble making an automated build from an organization, silly things :-P",1,0
2016-07-19 23:00:37,"@skinjester Yes, I'm making it now. ;-)",0,0
2016-07-19 11:32:08,All under control today. Plan F and G combined fixed everything. Time to enjoy the conference now! https://t.co/N5zf6D3uTC,10,0
2016-07-19 11:21:24,Great place for hiring in general. Use hashtag #nuclai16 to share/find opportunities!,9,4
2016-07-19 11:18:17,Trending in Austria :-) Thanks to social media team @skittlesolives @meowstations! If you need professional help you know who to contact.,4,1
2016-07-19 05:09:00,"Start-ups are the new unions. Developers group together to get better hiring terms, both financial and contractual!",11,1
2016-07-19 04:54:04,"@smilevector Haha, that's scary ;-) #nuclai16bot Thanks for joining in.",1,0
2016-07-18 22:43:16,"It was really great day otherwise; the people make this conference! Think I briefly talked to a third of attendees, two more days to go ;-)",4,0
2016-07-18 22:21:45,Sorry for audio on live stream; there's Plan F and Plan G in the pipeline to fix it. Amphitheatre was quite OK if that's any consolation!,0,0
2016-07-18 22:14:48,Tom√°≈° is OK and we'll try to setup on online event about Deliverance: Kingdom Come with him once things calm down on both sides.,0,0
2016-07-18 22:13:02,Especially thanks to @mark_riedl for letting us reshuffle his talk on short notice. Takes an experienced speaker to do it so smoothly \o/,0,0
2016-07-18 22:11:30,"Not my best organizational performance, but extra thanks to the speakers and volunteers for helping make it work today!",2,1
2016-07-18 21:50:31,@richardmatthias @alihelmy Speaking on Wednesday too ;-),0,0
2016-07-18 21:48:52,@amzeratul I think you're an early bird compared to most attendees! ;-),0,0
2016-07-18 11:54:58,"@libovness Talking about the most advanced technology in AI, but cables don't work reliably.",1,0
2016-07-18 11:50:20,"Fixed the stream/recording finally. Unplugged, rebooted, threatened to use random cables. Seems to work! https://t.co/IOSIeyUWRQ",10,0
2016-07-18 08:01:04,"But the stream is up and running, somehow... Will make incremental fixes as we go along!",5,0
2016-07-18 07:56:00,"Everything that could go wrong, did go wrong‚Äîtechnically and we lost our first speaker :-| Hopefully everything will resolve itself...",5,0
2016-07-18 04:35:25,"Morning! Likely you slept better than I did but I'm more excited than you. HAHA, who needs cofeffefefe. #nuclai16",11,0
2016-07-18 04:33:08,"@HappyHorseSkull More rumours that the code is using Texture Networks, but I'm not as sure: https://t.co/zPxfpPmwEj",2,2
2016-07-18 04:31:26,@GET_TUDA_CHOPPA You're on last anyway ;-),1,0
2016-07-17 20:41:45,"@mark_riedl You're setting a very high bar for expectations now ;-) Looking forward to it, should have more time to chat tomorrow too!",1,0
2016-07-17 20:37:07,"@LukeD Thanks, I expect things will work out somehow ;-)",0,0
2016-07-17 19:56:30,"Better prepared than ever before, but still hit a variety of technical problems‚Äîlike an endless runner with ever increasing difficulty :-|",0,0
2016-07-17 19:54:55,I remember in disbelief the times we used to setup @GameAiConf the morning before the event. Very glad we take the afternoon before now!,0,0
2016-07-17 19:41:36,"But after spending a few hours with attendees, speakers, volunteers, my brain is buzzing. Think I can do better :-) https://t.co/2V4yylgwLk",8,0
2016-07-17 19:37:44,"After yet another difficult week, my angle for my intro slides tomorrow was basically ""2016 sucks, enjoy this while you can."" [1/2]",1,0
2016-07-17 19:31:17,"@karoly_zsolnai Oh, read @RichardKogelnig's tweet assuming he knows about both Pixel and CEGC ;-) See you at the (open) party tomorrow?",0,0
2016-07-17 12:02:08,Volunteers arrived early! Mood picked up right where it left off last year... @nuclai https://t.co/jxuEpXXPud,9,2
2016-07-17 10:23:49,"@Treff We'll be jumping into the taxi soon, setup for 2h then official registration.",0,0
2016-07-17 07:11:07,@sroecker It's trained on auto-encoding with minor additional difficulties to make it learn nice features. Don't understand well yet!,0,0
2016-07-16 21:31:36,@mtrc I miss it too. But will return with a facelift!,0,0
2016-07-16 21:31:05,@mtrc Twitter is in a strange place. Hard to make bot that re-posts images from random people. I have plans for using other sources...,1,0
2016-07-16 21:13:44,"Just added the semantic map support back in for Tuesday. Should make it more interesting to experiment with, let's see how it works out :-]",0,2
2016-07-16 21:12:25,Those of you that tried the `forward` branch you can now experiment with `layerwise` too. It's faster on CPU and more options to curse at!,2,0
2016-07-16 21:11:25,"I don't get extra points for adding a new feature the day before @nuclai starts, but it feels good! #NeuralDoodle https://t.co/Lukvoz4oOf",10,0
2016-07-16 20:44:38,@mark_riedl Should be a walk in the park for you! Enjoy your flight ;-) https://t.co/lEVOlw0FTI,1,0
2016-07-16 20:10:26,@mstravag Welcome! I suspect everyone will be speaking Pokemon soon anyway...,1,0
2016-07-16 20:02:04,@Klohto @nuclai We'll be here!,0,0
2016-07-16 18:58:18,"@fchollet @jackclarkSF The classical AI approach has many more advantages for the planning, then use DL to communicate it.",3,1
2016-07-16 18:57:24,"@fchollet @jackclarkSF Unless there's human data in the loop like Facebook M, I don't see need to replace classical AI with ML if it works.",1,0
2016-07-16 18:54:51,"@fchollet @jackclarkSF @samim Short term, I expect assistants to be planning based (Viv). Likely take years for pure-DL to catch up!",1,0
2016-07-16 18:52:41,"@fchollet @jackclarkSF @samim Oh, I see what you mean. Deep Learning as the core feature? Next up, voice modulation ;-)",2,0
2016-07-16 18:50:04,"@jackclarkSF @fchollet @samim Lots of deep learning backends used for classification don't feel as visible, generative has the limelight!",2,0
2016-07-16 18:48:49,"@jackclarkSF @fchollet @samim Definitely biggest #CreativeAI success with deep learning, but likely Google's DL-powerd tools reach millions?",3,0
2016-07-16 18:38:29,"It's the strided convolutions that fail to compile on CPU, suspect it would work on GPU with full CUDA setup. #Neuraldoodle requires Docker.",1,0
2016-07-16 18:37:35,Update on Theano in Windows: regular convolution seem to work OK on the CPU straight from `conda` and `pip` installed packages.,2,1
2016-07-16 17:40:24,@GalaxyKate Compared to last year it's working out fine ;-),1,0
2016-07-16 17:38:50,Watching people from my feed arrive in Vienna for @nuclai is exciting and scary at the same time. Many things to finish but under control!,16,0
2016-07-16 13:13:43,@GalaxyKate I thought so. Safe travels! Petra is looking forward to meeting you in person ;-),0,0
2016-07-16 13:10:06,"@GalaxyKate What an amazing photo! BTW, do you want to send out install instructions for your workshop or manageable on-the-day?",0,0
2016-07-16 13:03:06,@LutoKamil For that project: Docker with its own self-contained dependencies from Ubuntu 14.04. For a simpler project: Theano/Lasagne works.,1,0
2016-07-16 07:48:26,"@paniq This is SHOP2, for example: https://t.co/oelKJ4lUCi SHOP1 is a better reference, can't PDF though.",2,0
2016-07-16 07:46:30,@paniq A tree is a universal construct! Many BT implementations store them as XML. But HTN that inspired them use S-exps.,0,0
2016-07-15 22:52:09,@deliprao Do you set these expectations going in to the project? How do you approach it?,0,0
2016-07-15 22:47:33,"@deliprao clients. If they did everything perfectly they'd be on your team, right? ;-)",0,0
2016-07-15 20:39:38,"@paniq @glassbottommeg Also, my part of this talk was about the importance of decoupling the tree from state: https://t.co/7IvwcmoIlW",2,0
2016-07-15 20:34:32,"@paniq @glassbottommeg My BT Design Patterns masterclasses on @AiGameDev are still very relevant too. (LMK if you want access, can help.)",0,0
2016-07-15 20:33:33,"@glassbottommeg @paniq Yes oscillation is a frequent problem. If you can describe a way you want it to happen, BT can probably implement it.",0,0
2016-07-15 20:32:10,"@paniq @glassbottommeg I wrote a code-oriented article called ""Behavior Tree Starter Kit"" here. Also design stuff: https://t.co/Fv9WKDFx1g",3,0
2016-07-15 20:30:29,"@glassbottommeg @paniq Yes, the article is like a Chinese Whispers version of stuff I published on @AiGameDev (or elsewhere) years ago.",2,0
2016-07-15 20:27:47,"@glassbottommeg @paniq Yes, in a BT topmost nodes get to decide. The leaf nodes just do the best they can. Gives you better modularity.",1,0
2016-07-15 20:26:49,"@glassbottommeg @paniq This helps decouple tree from state, and you free up the depth-first search to make smart decisions not manage state.",1,0
2016-07-15 20:25:55,"@glassbottommeg @paniq Not sure if it's useful in your case, but I prefer to store state as variables outside of tree in ""blackboard"". [1/2]",1,0
2016-07-15 20:25:01,"@glassbottommeg @paniq Yes if you add ""FSM"" nodes into your BT it's easy to migrate. However, I'm not a fan of this for building complex AI.",0,0
2016-07-15 20:23:55,"@glassbottommeg @paniq If you need a FSM, that's fine too. I'm not a huge fan of that article for a few reasons...",0,0
2016-07-15 20:23:22,"@paniq @glassbottommeg You could as long as your BT has only very simple &amp; specific nodes, nothing parallel or custom.",0,0
2016-07-15 20:21:13,"@glassbottommeg @paniq If you build a stack of FSMs then it becomes more similar to BTs. Basically traversed depth-first, BT is superset.",2,0
2016-07-15 20:18:31,"@paniq @glassbottommeg Yes, until the neural apocalypse. But that doesn't mean you should write your programs that way ;-)",0,0
2016-07-15 20:16:14,@paniq @glassbottommeg It's like saying you could write a structured program with GOTO only. You could but you'd have extra work...,0,0
2016-07-15 20:15:41,"@paniq @glassbottommeg No, BT has stack for context which FSM does not. It would take a whole lot of duplication to work the same.",1,0
2016-07-15 13:05:15,"@nuclai Everything went extremely smoothly this year, despite the new venue. Getting more organized, mostly thanks to Petra of course ;-)",2,0
2016-07-15 12:57:58,"@karoly_zsolnai According to @skittlesolives, there's actually a Pokestop at the lunch restaurant we reserved each day ;-)",0,0
2016-07-15 12:52:22,@nuclai Step 5.5 Run out of battery on phone as it's clearly not equipped for the modern age and snapchat's Always On camera :-|,0,0
2016-07-15 12:50:06,@Klohto It's likely based on this: https://t.co/urGHcMWzjK,0,0
2016-07-15 11:05:10,@nuclai OH: I was sure but I was wrong. Just because I'm sure doesn't mean I'm right.,1,0
2016-07-15 10:46:57,@nuclai Step 1.5 Hold up traffic while I practice reversing truck under pressure.,1,0
2016-07-15 08:39:27,"@drtowerstein Read the email we sent yesterday. May even be refreshing rain, as requested ;-)",0,0
2016-07-15 08:24:33,Want to watch a small team carry 50x its weight in conference equipment and boxes? Then follow this novelty account: https://t.co/kHbmoUeSwg,3,1
2016-07-15 08:18:29,"@drtowerstein @RecklessCoding Using Docker, which is basically the same thing. It works so the conference is back on ;-)",2,0
2016-07-14 22:23:41,@TomNullpointer @SouthernRailUK I love that you can click to charge passengers in bulk while they all leave after cancellation!,0,0
2016-07-14 13:23:32,". @richardmatthias @GET_TUDA_CHOPPA ""To find #nuclai16 conference venue, take U2 to Schottentor, exit south &amp; walk past the Pokestop.""",6,0
2016-07-14 08:52:24,"@ngutten It's style transfer, so expecting 60s computes for each experiment. Not sure there's enough compute; expecting 30 people setup.",0,0
2016-07-14 08:50:45,"@MikeIsaac @minimaxir @jw Right now you can do very fast style applications, but you need someone else to prepare styles for you.",0,0
2016-07-13 22:49:26,"@minimaxir @MikeIsaac @jw The new code is much faster than #NeuralDoodle, but takes ages to pre-train each filter: https://t.co/vcyFPtztbx",2,0
2016-07-13 22:23:56,"@dead_x No, AbstractConv2d has no available implementations in WinPython either.",0,0
2016-07-13 22:12:09,"@AlexMedia Thanks! I saw the announcement but I can't assume @nuclai attendees will be on Windows 10, must work across versions.",0,0
2016-07-13 22:02:13,"@dead_x I'd be impressed, let me try ;-)",0,0
2016-07-13 22:01:54,That moment you realize when Docker might be the only solution to the problem. Move aside! https://t.co/Ilra3ydyJp,60,28
2016-07-13 21:27:57,@RecklessCoding I will likely be done with Python setup by then and we can have a good laugh about it...,1,0
2016-07-13 21:21:42,"@RecklessCoding Lookis like I'm cancelling the workshops anyway, damn Theano ;-)",0,0
2016-07-13 21:14:28,"@RecklessCoding I'm trying to make easy-install instructions for any workshop attendees (no CUDA), if can't type 1ln command then no option.",1,0
2016-07-13 21:05:29,"@RecklessCoding @ferrouswheel mingw works, only need VS for CUDA. Problem is just openblas version clash with conda, it's supposed to help!",0,0
2016-07-13 21:00:05,@RecklessCoding Using Anaconda too. Are you doing convolution?,0,0
2016-07-13 20:59:43,"@seaandsailor Ah, would disabling mkl make any difference to the openblas binary mismatch problems/crashes?",0,0
2016-07-13 20:53:53,"@ferrouswheel Thanks, I want it to work without CUDA though. Just a plain openblas that conda uses to build numpy but doesn't expose...",0,0
2016-07-13 20:52:10,"@ferrouswheel Python 2.7 is built against 2010, which does not have community edition. It works? No ABI mismatch crashes?",0,0
2016-07-13 20:49:33,"@ferrouswheel Did you manage with CUDA? Starting to suspect that would be easier, but can't assume workshop attendees will have it.",0,0
2016-07-13 20:48:46,"@ferrouswheel 2.7 sounds worse, you somehow have to dig up and obsolete and unsupported Visual Studio compiler for CUDA. Who bothers?",0,0
2016-07-13 20:41:24,"Wondering if setting up Python deep learning on Windows is actually getting harder... mingw doesn't support latest Python, fallback to 3.4.",5,1
2016-07-13 12:42:35,@krides Wow. Congratulations! Trailer looks great too :-D,1,0
2016-07-13 09:54:18,"@Games4AI @diego_pliebana Industry noticed already, that quote just makes everyone sound backwards. Need to know context!",0,0
2016-07-13 09:51:46,@diego_pliebana Said by someone clearly without an analytics/data-science department.,0,0
2016-07-13 08:51:32,@ikrimae Realize that most games are designed to have predictable or simple enemies because the game mechanics/feel works better than way.,1,0
2016-07-13 08:48:53,"@drtowerstein Possibly if that's the company's distinguishing factor, otherwise they rather keep their ""IP"" and just release framework.",0,0
2016-07-13 01:47:20,"@srbutner @syhw You could learn to generate stories systemically with ML in less than 10 years, but would require many changes/compromises.",1,0
2016-07-13 01:43:33,"@srbutner @syhw There's low hanging fruit with planners or constraint satisfaction, basically classical AI. Not enough data to learn Story.",1,0
2016-07-13 01:42:40,"@srbutner @syhw If you have a ""narrative"" then timeline for integrating anything based on machine learning is 10+ years out ;-)",1,0
2016-07-13 01:39:37,@syhw Possibly animation pipelines from motion capture clean-up to replacing motion matching. Black-box automated testing from pixels ;-),2,1
2016-07-13 01:37:42,"@syhw It will happen for character behavior, but IMHO only once the studios have tasted the benefits in other places.",0,0
2016-07-13 01:35:03,"@syhw If you use deep learning in that part of the game, you basically have to rebuild pipelines/workflows/practices around it.",1,1
2016-07-13 01:34:18,@syhw I'm not even considering technical side ;-) It's because of production issues and role in overall game design that it'll take so long.,0,0
2016-07-13 01:18:11,@syhw @TimSweeneyEpic I suspect in-game character behavior will be almost last to be disrupted; tough one to crack for variety of reasons.,1,0
2016-07-13 01:16:50,"@syhw @TimSweeneyEpic Agree, though correct that rubber is not yet hitting the road. But scary how fast it's moving and companies investing!",0,0
2016-07-13 01:07:28,"Oh, and it helps to have a systemic game rather than a story-driven one. Harder for NPCs to do anything sensible under narrative pressure!",2,0
2016-07-13 01:05:12,"FWIW, Paragon has all that going and much more... Rumor has it bots are amazing ;-) Keen to find out more next week! https://t.co/BpGVvjYv5o",4,0
2016-07-13 01:02:26,"More important: second gen technology, understanding of game, big &amp; experienced AI team, and dedicated person just on MP bots for ~1 year.",2,0
2016-07-13 00:58:56,"Multiple layers of AI planners (HTN) powered those bots‚Äîplus sequels; it certainly helped, but I don't think that was the secret.",2,0
2016-07-13 00:46:37,"Already in Killzone 2 [2009], multiple players and reviewers had trouble distinguishing humans from AI. We had to add clear labels to bots!",2,0
2016-07-13 00:45:04,It takes a mix of best practices in AI technology along with clever design tricks to make the player notice what you want them to :-D,2,0
2016-07-13 00:43:20,"The next question about ""[Game] AI that passes the Turing test"" misses the point, I think we're already there. It's an easy problem!",3,0
2016-07-13 00:40:45,Interesting interview with @TimSweeneyEpic that summarizes current state of games industry: https://t.co/oWP8IMkUye https://t.co/9aQUx2BTfm,21,8
2016-07-12 22:36:14,"@halhod You could make the same table with AI breakthrough alongside releases of new CPUs or GPUs, claim causal relationship. As credible!",0,0
2016-07-12 22:35:28,"@halhod RL generates its own ""simulation"" data. Facebook's DarkForest used human replay data, AlphaGo beat human because it made its own.",0,0
2016-07-12 22:33:37,"@halhod @benhamner IMHO there are inaccuracies and/or omissions, but you can't just line up facts by date and draw causal relationships.",0,0
2016-07-12 22:30:47,"@halhod There's a much stronger case to be made for computation being the greatest factor in all of this, but that's still misleading.",1,0
2016-07-12 22:30:06,"@halhod If a breakthrough depends only on data then it was only an application breakthrough, not one in AI.",3,0
2016-07-12 22:29:21,@halhod Yeah. Got lots of thoughts about that particular Tweet... misleading at best. https://t.co/a26XRUHtFS,0,0
2016-07-12 18:08:06,". @ibesora The #nuclai16 Amphitheatre will be streamed, see schedule: https://t.co/NfuVWcdfBv Times are CEST.",2,0
2016-07-12 17:46:59,"OK, thanks for the feedback. Done for now, works well :-D Thanks to our Gold sponsor @CAGames and @nvidia for supporting the live stream!",3,1
2016-07-12 17:34:03,"@Dghelneshi OK, that part is likely OBS source configuration. The original video is solid 30 FPS, rendered offline so no frame was missed.",0,0
2016-07-12 17:29:48,"@Dghelneshi Thanks, got it working on two platform but then it only shows one frame of the video ;-)",0,0
2016-07-12 17:03:33,"@Dghelneshi It's playing back a video, not much else going on. Going to check in VLC, didn't realize that was possible ;-)",0,0
2016-07-12 16:56:50,"@Dghelneshi OBS displays output bitrate as over 6000 now. In HTML5 I have audio glitches minor hiccups, seems fine in Flash. Any ideas?",0,0
2016-07-12 16:54:04,"@Dghelneshi We're saving the original to disk so bumping up is always helpful. This machine can handle ""fast"", will try bumping up...",0,0
2016-07-12 16:50:48,"@Dghelneshi Also, could be that the video isn't that fast so it ends up with fewer kb/s. When screencasting I suspect it'll be even smaller.",0,0
2016-07-12 16:49:50,"@Dghelneshi Thanks. Setting is currently at ""5120"" but may try bumping that up... Could it be that YouTube is also transcoding 1080p?",0,0
2016-07-12 16:44:55,"@Alban_C No idea how many, expecting average of hundreds depending on how people share the links! Any audio glitches on Linux? OSX is weird.",0,0
2016-07-12 16:42:18,"@karoly_zsolnai Good to hear, thanks!",0,0
2016-07-12 16:40:50,"@richardmatthias OK, thanks. I have two machines and one is too quiet and the other too loud, so wasn't sure!",0,0
2016-07-12 16:35:00,Testing the live stream for #nuclai16. How does it look/sound for you? https://t.co/HAFNUVY7Gh https://t.co/VbPX8M79bO,2,0
2016-07-12 13:26:47,@nathansttt Australia! Nice. I think Petra is planning a holiday already ;-),0,0
2016-07-12 13:22:19,@nathansttt Many thanks for the live Tweeting! If they announce official dates for IJCAI17 will you let me know? Cheers ;-),0,0
2016-07-12 13:12:12,"@erocdrahs @samim Partly, see here: https://t.co/Je8R1Usr4M",1,0
2016-07-12 12:54:20,"Petra looked like this for a few minutes, apparently one venue reservation was off by two days ;-) Fixed now! https://t.co/Svxv15b6pm",10,0
2016-07-12 12:21:28,#CreativeAI Challenge: A bot that can identify trending memes and participate creatively. https://t.co/GH4uGpWzl2 https://t.co/FjWdDUHR5F,10,1
2016-07-12 11:52:35,"@KyleOrl Yeah, that's why I mentioned special allowances for early embargo dates: undisclosed, they feel very similar to me.",0,0
2016-07-12 11:46:28,@KyleOrl It's a scary time because the jobs (and money) are shifting in that direction. FTC ruling is a step forward. Gambling next!,1,0
2016-07-12 11:45:31,"@KyleOrl In the end it wasn't the contract itself that was the problem, but disclosure (using YouTube description is not enough for FTC).",1,0
2016-07-12 11:42:28,@KyleOrl What bothers me most is the blanket dismissal of YouTubers vs. printed press. There's wide spectrum of behavior either side...,0,0
2016-07-12 11:02:07,In the end it's still a form of compensation that goes undisclosed; contract details don't really matter ethically feels very similar to me.,3,1
2016-07-12 10:59:28,"Also, multiple game publishers allowed reviews to be uploaded earlier than embargo if it was above a certain rating, e.g. 9/10.",2,1
2016-07-12 10:57:05,Game publishers often negotiate exclusive features (helping magazines w/ traffic or sales) that have positive spin. https://t.co/uLHW1Go3vX,3,1
2016-07-12 10:03:54,@graphific The more you understand a domain the more likely you are to engineer that kind of architecture! As long as the results follow...,2,1
2016-07-12 09:13:02,"The case-based approach feels a lot like patch-based + semantic map. It'd never confuse patches, so no eyeball patterns replacing mouth...",0,0
2016-07-12 09:10:21,"It's Sketch Day on arXiv today! Interesting results here compared to neural approaches, c.f. ""exaggeration field"": https://t.co/Z7h0GLkyCl",5,2
2016-07-12 09:08:43,Learning to Sketch Human Facial Portraits using Personal Styles by  Case-Based Reasoning https://t.co/8cjIoBfnEn https://t.co/suGAzFkVtP,20,3
2016-07-12 09:03:02,Adversarial Training For Sketch Retrieval https://t.co/P3XQ3Mgt6s Uses GANs to search for patterns similar to query: https://t.co/8hKcPLGLzH,18,9
2016-07-12 08:36:11,"@Amir_johoob Yes, thanks! I wrote about it a few days ago if you want to see my analysis.",1,0
2016-07-11 17:09:00,"@AngryAnt @richardmatthias Cost would have to be passed on to the attendees, so likely to never happen!",0,0
2016-07-11 16:54:42,@AngryAnt There are four cards and a spare PC. But if something breaks it's bad...,0,0
2016-07-11 16:05:40,"@drtowerstein ""Please step this way, Sir.""",0,0
2016-07-11 15:44:01,"@dharmaone Yes, assuming they can also compress the models to downloads I think the technology is there now.",0,0
2016-07-11 15:29:38,@dharmaone Biggest challenges would be getting the quality up. #Prisma looks better than any of the other examples I saw for this code.,0,0
2016-07-11 15:25:18,"@dharmaone There's no way the classic #DeepStyle would work with 2s turn-around times, even if you have huge EC2 installation.",0,0
2016-07-11 15:24:44,"@dharmaone Apparently they're using this algorithm, no new technology: https://t.co/vcyFPtztbx Quite likely, based on timing.",0,0
2016-07-11 11:20:44,"Pretty soon, all those randomly generated names in the conference database will turn into real people. It's magic! https://t.co/c9tRrZVIfH",4,0
2016-07-11 11:17:44,@Treff @nuclai YAY! \o/,1,0
2016-07-11 09:47:54,"Excitement is building! It's getting harder to sleep in evenings, so I just work later until passing out like this: https://t.co/cg38Ocze0D",4,2
2016-07-11 09:17:42,"@nrose Except you don't have the choice which Bird you use, it's selected for you. If there was a choice, statistics would be useful!",1,0
2016-07-11 00:00:40,"@UAesthete @stephenbalaban They'd just rebuild it, it's probably open source code anyway, +1 month of experience training those networks.",1,0
2016-07-10 23:53:36,"@AtulAcharya @nrose @dribnet @kastnerkyle @ngutten Once you got the basics figured out, staying on top is much easier ;-) Good luck!",1,0
2016-07-10 23:49:30,"@edersantana Also see this paper, a more formal study: https://t.co/e25NTrsLaD",7,0
2016-07-10 23:47:55,"@AtulAcharya @nrose @dribnet @kastnerkyle @ngutten Yes, it could work with feed-forward and SqueezeNet architecture: https://t.co/gvSS6p2yqp",1,0
2016-07-10 23:44:24,"@edersantana There were comments I included in blog post. Random captures high-frequency features, but has poor coverage as net deepens.",1,0
2016-07-10 23:43:08,"@edersantana Based on experience w/ style transfer, the deeper you make the random networks, the worse features get. https://t.co/k1Vr64CTxm",2,3
2016-07-10 23:33:35,@ngutten @kastnerkyle Looking forward to finding out more!,0,0
2016-07-10 23:33:06,@AtulAcharya @nrose @dribnet @kastnerkyle @ngutten Different algorithm. https://t.co/vcyFPtztbx,1,0
2016-07-10 23:31:02,@ngutten @kastnerkyle Is it an existing algorithm or something you're working on now?,0,0
2016-07-10 23:18:59,"@nrose @dribnet @kastnerkyle @ngutten It's not annotated though, needs a segmentation process via mechanical turk ;-)",1,0
2016-07-10 23:17:22,@nrose Some overlap of course... What's the percentage of your users that use the default styles vs. submitting custom?,0,0
2016-07-10 23:06:38,@ngutten @kastnerkyle Could train with a GAN to generate most compact latent space from a hypercolumn. Anyone done this before?,0,0
2016-07-10 22:53:28,"@dribnet @kastnerkyle @ngutten With data augmentation, mixing images with random backgrounds, brightness/hue modification would work!",0,0
2016-07-10 22:52:25,"@dribnet @kastnerkyle @ngutten I manually annotated portraits for #NeuralDoodle in almost the same way, but they have only 70 examples.",1,0
2016-07-10 22:51:50,@dribnet @kastnerkyle @ngutten I'll earegly await the release! This segmentation is useful for close-up portraits: https://t.co/hxOUAOjBVy,3,0
2016-07-10 22:50:36,"@ngutten @kastnerkyle Unsupervised segmentation is ideal, but it needs to be a consistent representation across images (style+content).",0,0
2016-07-10 22:43:16,"@ngutten @kastnerkyle So the answer is: both. ;-) You want leaves to match leaves, trees to match, but any vegetation as fallback.",0,0
2016-07-10 22:42:18,"@ngutten @kastnerkyle It'd be ideal to have a ""pixel embedding"" with distances related to the pixel's meaning‚Äîmaybe semantic hyper-colums?",0,0
2016-07-10 22:39:22,"@dribnet @kastnerkyle @ngutten There are lots! Challenge is always the data, found one good dataset but needs much augmentation.",0,0
2016-07-10 22:37:52,@kastnerkyle @ngutten So basically use existing high-level features for segmentation? I think it's mentioned here: https://t.co/MnYQfl0LbH,1,0
2016-07-10 22:34:42,"@kastnerkyle @ngutten Yes, combination is easy‚Äîwas designed that way :-) I started experiments segmenting faces, but not had enough time!",1,0
2016-07-10 20:11:41,"@ngutten Should be possible, easiest as composite network trained in parts with one part encoder/decoder like #NeuralDoodle's branch code.",0,0
2016-07-10 19:03:38,"@ivanassen It's true, if they develop the business as they did the technology it should fly.",0,0
2016-07-10 18:48:52,"@asif_rehan It's based on this paper, but they did a great job tuning it. Looks better than paper and open-source: https://t.co/bTbPzYGUPc",3,0
2016-07-10 18:44:32,"The default styles are also much better chosen than anything I've seen before, but risk of those styles being pass√© in 1-2 months or so ;-)",1,0
2016-07-10 18:42:21,The easy consumption 2s turn-around has a popcorn effect. It's a significant improvement on #Pikazo or @DeepForger.,4,0
2016-07-10 18:40:13,I've changed my mind on this; I think #Prisma success is mostly due to performance. Quality incrementally better! https://t.co/hsnWvWugFU,6,0
2016-07-10 13:13:27,"@dougbinks There are lots of useful things Twitter could to manage the information stream, but that assumes they have a sensible vision.",2,0
2016-07-10 11:05:36,"@kcimc Original is patent pending, but I presume this approach is sufficiently different that it would require a separate patent.",1,0
2016-07-10 11:04:39,@kcimc There's likely 1- or 2 months of specialized experience for getting such results that fast. It'd be a acqui-hire?,2,0
2016-07-10 11:02:18,@kcimc I suspect the web-based infrastructure for copying/preparing/saving files actually takes longer than the style transfer itself...,2,0
2016-07-10 11:01:35,"@kcimc This technology could process one image in 50ms. If average 20 then 1 GPU, if average 40 then 2 GPUs. Peak g2-8x at 4 GPUs?",2,0
2016-07-10 10:52:15,@kcimc I ran many more GPUs for @DeepForger (even free) back when style transfer was expensive ;-) There's certainly PR value.,0,0
2016-07-10 10:50:59,"@kcimc It's a very fast style transfer implementation, 1-2 GPU? Likely trying to get acquired...",2,0
2016-07-10 10:22:26,Rumour has it the app is using this open source implementation: https://t.co/urGHcMWzjK But magic is still (always) in style selection.,21,0
2016-07-10 10:18:10,This is somewhat unexpected; not mentioned in original paper and I've not seen it discussed either. That insight is why #Prisma went viral.,5,0
2016-07-10 10:16:54,"@azeem No, it's not ""semantic"" since you don't need to add annotations. It's likely an implementation of fast style: https://t.co/lGjaxnCQoz",0,0
2016-07-10 10:16:04,By using smaller neural network to learn a specific style (takes 4h-6h training) it does a better job applying style in localized areas.,7,3
2016-07-10 10:14:36,"Justin's fast style is unable to learn a perfect ""global"" distribution, but coincidentally works better for most! https://t.co/bTbPzYGUPc",3,0
2016-07-10 10:13:19,"Original #DeepStyle imposes a ""global"" style distribution which ruins many pictures that have different composition. https://t.co/7tJIRL8Vhu",3,0
2016-07-10 10:11:12,"Nice! The success of #Prisma is partly due to performance, but also that fast style currently gives better results. https://t.co/8yu0cSbKkR",16,5
2016-07-10 09:19:28,"@dribnet Interesting! I have my own set of artifacts from training with multiple networks together, but haven't seen that one ;-)",0,0
2016-07-10 09:14:46,@dribnet Have you figured out what the vertical lines are caused by? Thought it was resolution but maybe not...,0,0
2016-07-10 09:02:57,@dribnet It's a good format too. What resolution does your network output?,0,0
2016-07-10 09:00:52,"@michaelprivat There's dogfighting in Star Citizen powered by Kythera, multiple videos and we did an interview. Otherwise, Craig Reynolds?",0,0
2016-07-09 16:42:39,"@ankurhandos I don't have labels, and ideally it needs to be cheap to compute as part of the training. I needs ~100k training instances.",1,0
2016-07-09 16:25:36,@ankurhandos So the pupil network has more freedom to generate sharp edges even if they don't exactly match the original position.,1,0
2016-07-09 16:24:56,"@ankurhandos It's basically training image auto-encoder but instead of using pixel loss, it's VGG ""perceptual"" loss‚Äîe.g. from levels 4_1.",1,0
2016-07-09 16:22:23,"@ankurhandos Yes, in a way that's what perceptual loss is doing. Linking it again, it's a cool paper: https://t.co/vcyFPtztbx",2,0
2016-07-09 16:18:35,"@ankurhandos Alternative is just using Euclidean distance on pixel values, which then tends to make results blurred (no TV required). [2/2]",0,0
2016-07-09 16:17:21,@ankurhandos I see the adversarial setup as a way to get sharp results in the same way that perceptual loss does. [1/2],0,0
2016-07-09 16:15:24,"If you're new here, welcome! Earlier I wrote about my deep learning projects from past year: https://t.co/OnmU3KLc02 https://t.co/9hzG2MzyIZ",26,5
2016-07-09 16:11:43,"@ankurhandos Not sure if there's a solution to this except training the loss in adversarial style, but then may still need TV.",0,0
2016-07-09 16:10:12,"@ankurhandos With large weight for TV, it basically makes output overly smooth and defeats the purpose of using a perceptual loss.",1,0
2016-07-09 16:09:21,"@ankurhandos With small weight for TV, the patterns from other network appear as it's easier to minimize loss without smooth constraint.",1,0
2016-07-09 16:08:01,"@ankurhandos 2¬¢: Perceptual loss is another network not trained with TV, likely has filters that are not smooth from one pixel to another.",1,0
2016-07-09 16:02:02,"@ankurhandos I don't see staircasing problems (on edges?) they mention. Either I get dithering if factor too low, or blurred if too high...",0,0
2016-07-09 15:58:28,"@ankurhandos No, not yet. I can try it very easily if there's a Python example you can point me to, otherwise it might have to wait a bit.",0,0
2016-07-09 15:57:44,"@ankurhandos It's the perceptual loss that makes this obvious, but general problem. https://t.co/vcyFPtztbx https://t.co/OZ8FQMjBlM",1,0
2016-07-09 15:55:52,"@ankurhandos Now training feed forward style transfer, and TV is required to prevent ""dithered"" patterns, like diagonal screen door.",0,0
2016-07-09 15:55:13,"@ankurhandos Sure, it's an important topic! It's a constant struggle for me ;-)",1,0
2016-07-09 15:50:44,"Read @ankurhandos's thoughts here, in particular on smoothing (TV) and CNN's inability to capture hi-freq detail. https://t.co/YPwIQEfnSX",11,0
2016-07-09 13:11:53,@ArmyOfBruce What a coincidence ;-),0,0
2016-07-09 13:08:02,"@ankurhandos OK, many thanks! Looks like I have quite some reading ahead of me ;-)",1,0
2016-07-09 12:49:25,@ankurhandos Do you know any references for that weighting strategy in CRF? Not very familiar with the field yet (pun intended :-).,0,0
2016-07-09 12:44:55,@ankurhandos Patch-based approaches require TV because it operates at levels 3_1 or 4_1 after multiple pooling operations.,0,0
2016-07-09 12:44:04,"@ankurhandos The original #DeepStyle by Gatys specified no total variation, but maybe too lowres to tell...",0,0
2016-07-09 12:43:18,@ankurhandos Interesting idea. I read up on alternatives and found nothing particularly new there! Maybe example-based smoothing?,0,0
2016-07-09 12:42:39,"@ankurhandos With global statistics, however, it will distort the output. And with local patches you need significant number of examples...",0,0
2016-07-09 12:42:00,@ankurhandos Indeed. The neural style transfer solutions do so by re-injecting information into the pipeline via statistics or patches.,0,0
2016-07-09 11:28:52,"@gpakosz In this case, the ML algorithm is used as another tool, just one with more power &amp; flexibility.",0,0
2016-07-09 11:28:19,"@gpakosz Agree. But if you look at the system that includes #DeepStyle and the artist providing style, then it becomes a creative act.",0,0
2016-07-09 11:25:31,"@gpakosz Exploring the patterns in input styles is some kind of artistic research, even if you don't tweak the algorithm (should self-tune).",0,0
2016-07-09 11:24:45,"@gpakosz Yes, also the fact it's so slow means there's very little room for tuning. Can't easily throw 10x style images together, etc.",1,0
2016-07-09 11:21:34,"@gpakosz I only really know one artists that's exploring ML-friendly styles, but I have to admit I didn't look as seriously.",0,0
2016-07-09 11:20:16,"@gpakosz I'm glad they're exploring the space, but agree it has expiration date... Do you have any specific names/references?",0,0
2016-07-09 11:10:27,"It seems to be inspired by patch-based approaches, which explains why quality is impressive. Not sure about speed. https://t.co/0BWYlGVq9y",6,1
2016-07-09 11:08:38,Learning Depth Super-Resolution using Deep Convolutional Neural Networks https://t.co/K9s1PuvxJX #dlearn https://t.co/g9sFd2lPzK,66,32
2016-07-09 11:03:50,@dantreble You know too much. Expect a drone to drop by today...,1,0
2016-07-09 11:03:18,@dantreble Though we'll move most @AiGameDev stuff onto a @nuclai subdomain after the conference for clarity. https://t.co/npwFIEjtDb,1,0
2016-07-09 11:02:13,"@dantreble A combination of @nuclai that covers its costs, and @AiGameDev that covers my time.",0,0
2016-07-09 10:50:49,"After the event, I hope to get time to finish research in #NeuralDoodle's branch before someone else publishes it ;-) This field moves fast!",5,1
2016-07-09 10:48:40,"My main job now is organizing @nuclai, the largest conference dedicated to AI in Creative Industries, which takes place soon: July 18-20.",6,0
2016-07-09 10:45:45,"It has useful ideas to bridge gap between ""local"" and ""global"" style transfer, taking 30-60s on CPU, but not yet quality match for either.",1,0
2016-07-09 10:43:49,"My focus recently has been making the algorithm accessible without huge GPU, trying to democratize the technology. See `forward` branch!",1,1
2016-07-09 10:42:06,And another fun prototype generating textures from random untrained neural networks (for the first time): https://t.co/ppC8WmWgKn,5,2
2016-07-09 10:40:09,"This involved, for example, experiments with up-scaling pixel art using example textures: https://t.co/vbWMjbfcT4 https://t.co/sjILIjHqHl",6,2
2016-07-09 10:38:31,"In my spare time, I've been working on improving the algorithm that was released as open-source as #NeuralDoodle. https://t.co/MZfbWHpxwb",11,2
2016-07-09 10:37:07,"It's active only via Facebook &amp; website (for now), and seems to be used for content creation on a game and another graphics project.",1,0
2016-07-09 10:35:08,"In the meantime, @DeepForger got into trouble due to strict copyright laws in France and the usual trolls on Twitter, it was suspended :-|",2,0
2016-07-09 10:32:57,"The paper showed that with semantic annotations, you can actually control these neural algorithms as tools! *gasp* https://t.co/HjDTa8uxRn",4,1
2016-07-09 10:31:27,"I started writing a paper for #ICCC16 about what I'd done, but then threw it all out and did this instead ;-) https://t.co/Cvz0X5oaLt",7,2
2016-07-09 10:29:27,"Still @DeepForger is the only online service to use a patch-based approach, but it has a different set of glitches: https://t.co/l7SUiPQ3Qw",1,0
2016-07-09 10:28:17,"Partly by luck, some forgeries turned out amazing by impressionist standards, others were fun mashups: https://t.co/MFqVk0QVbW",3,0
2016-07-09 10:26:59,It lead to a collaboration with BBC Culture for Renoir's birthday (Feb 25th) hundreds of users submitted landscapes: https://t.co/QDHSiSJTy1,4,1
2016-07-09 10:25:04,This increased photo-realism of style transfers and a new phase of exploration for this second algorithm began! https://t.co/ElO7HozYPr,3,1
2016-07-09 10:19:09,"Within a few weeks of a new ""local"" patch-based algorithm being released, I deployed it to @DeepForger. https://t.co/sElUWbN3Gx",3,1
2016-07-09 10:18:19,"It works for painterly or abstract styles, but I got frustrated with it using ""global"" statistics as it fails to understand the picture.",1,0
2016-07-09 10:15:34,"I tried to identify and fix problems / edge cases, rolling out some mixed experiments independently documented here: https://t.co/MnYQfl0LbH",4,0
2016-07-09 10:13:04,"Thanks to amazing (and odd) user submissions, the bot became a collaborative exploration of the algorithm, poorly understood at the time.",3,0
2016-07-09 10:11:03,"Mr. @DeepForger was the first service for style transfer, online just hours after the code was released ;-) https://t.co/iyRe2Yp1Cu",4,0
2016-07-09 10:06:18,"I've been working with neural style transfer since it was released last August, made a bot called @DeepForger. https://t.co/6vRdTj47TF",8,0
2016-07-09 10:04:38,"Good morning! I got mentioned on Reddit and apparently it's not clear to new followers exactly what I'm working on, so here's the breakdown:",15,4
2016-07-08 16:28:58,"@inconvergent Looking fantastic! For some reason, I imagine the would work incredibly well as coffee/beer mats‚Äîeach unique but it a set.",2,0
2016-07-08 15:36:50,"@pwang Ah, then use the photos for 95% bots who make up the site, like Ashley Madison? :-)",0,0
2016-07-08 15:30:29,"@pwang These are 1024x but slow on GPU:
https://t.co/stDpRnBpcw
https://t.co/O0a1I0cHeA
https://t.co/Ubc0umegKv
Current code uses numba ;-)",3,2
2016-07-08 15:27:36,"@pwang Yes, there are much better ones done on GPU but these take about 100x less compute‚ÄîCPU friendly.",0,0
2016-07-08 15:11:20,@44thats44oars It's very feasible. Just need to get some time to support it once the new core is stable...,0,0
2016-07-08 15:09:55,"@44thats44oars No, they don't ;-)",0,0
2016-07-08 15:07:40,@44thats44oars They are 2D texture. You mean loop seamlessly?,0,0
2016-07-08 15:07:04,"Parameter space takes a bit of time to understand (the trade-off for performance), but I guess that will be part of the workshop! ;-)",1,0
2016-07-08 15:05:45,"On different textures, the same code can get closer to photo-realism in about 2-3 minutes on CPU.... https://t.co/EfLOADY4Ws",6,1
2016-07-08 11:39:26,"@ngutten Yes, imagine having a factor that lets you blend between ""local fit"" and ""global match"" for each patch you select.",0,0
2016-07-08 11:26:33,@ngutten IMHO patch-based is the superset of both approaches. I look at gram matrix as capturing patches L-1 with factorized representation.,0,0
2016-07-08 11:25:38,@ngutten I fixed this satisfactorily already. Using patch-based with bias for individual patch: either encourage diversity or match target.,0,0
2016-07-08 11:24:32,"@ngutten Oh, I see. Not sure what tricks could help with that: just cropping the input and processing that?",0,0
2016-07-08 11:21:32,"@ngutten So basically the same as the backward propagation architectures, but using feed-forward to learn 24 iteration steps at a time?",0,0
2016-07-08 11:20:34,"@adurdin Focus has been on @nuclai, so haven't really thought about it ;-) Maybe once we've recovered!",2,0
2016-07-08 11:15:16,"@ngutten If you use multiple feed-forward passes, you see the result after pass 1. It's very responsive. Not sure either are ""interactive""!",0,0
2016-07-08 11:14:41,"@neingeist `layerwise` branch. It still requires Theano to be setup, but runs fine on CPU.",1,0
2016-07-08 11:12:17,"@neingeist It's mostly online already in a branch, just no instructions and model files missing for now: https://t.co/MZfbWHpxwb",0,0
2016-07-08 11:11:46,"@ngutten Easy enough I presume... However, I'm not sure of the benefits of doing this vs. multiple regular feed-forward passes.",0,0
2016-07-08 11:10:47,"Must be possible to reach photo-realism with incrementally more CPU computation, but haven't yet figured it out. (Alternatives take hours!)",0,0
2016-07-08 11:09:30,"For the workshop, we'll likely focus on painterly or abstract styles. It helps avoid GPU setups and CUDA, so more people can participate.",3,0
2016-07-08 11:07:15,"Alternatives are:
- Transfer with no pre-process on GPU, 3-5 minutes total.
- Pre-baked networks with GPU for 4h-6h, then 50ms per frame.",1,0
2016-07-08 11:05:21,"Trying to make neural style transfer as widely accessible as possible for the @nuclai workshop on Tue, July 19th. https://t.co/VtggRP6oPN",3,1
2016-07-08 11:03:45,It's tough balancing between fast generation on Laptop CPU (these are 60s E2E) &amp; scaling to photo-realistic w/ GPU. https://t.co/Los1MwTpFk,20,2
2016-07-08 09:52:13,"@sknthla People are definitely more angry overall, and there's extreme left abuse to match extreme right. Who knows where this is going :-|",1,0
2016-07-08 09:51:07,"@sknthla Other reddit forums are worse, but then again so were other IRC channels.. Just seems a bit more centralized and hence obvious now.",0,0
2016-07-08 09:49:47,"@sknthla This particular instance feels average for par, moderated an #AI IRC channel for years and trolled about as often.",0,0
2016-07-08 09:33:45,"@fchollet @Smerity Your original troll should be banned, it's a moderation problem not necessarily reddit? Same for all forums / IRCs.",0,0
2016-07-08 09:32:42,"@fchollet @Smerity The responses are not friendly, but if it had been a technical post rather than VC-funded website, it would have flown.",0,0
2016-07-08 09:31:37,"@fchollet @Smerity /r/ML tends to focus on underlying machine learning, so if you post promo indirectly related it's often shot down.",1,0
2016-07-07 22:01:20,"@jurieongames @gwareddm I'm so glad nobody is using browser-based presentations this year... oh, wait! *stern look*",1,0
2016-07-07 21:13:53,@paniq The match was decided off field. They figured #FRA would have a better chance of staying in the EU (and not revolting) if they won!,2,0
2016-07-07 14:54:04,@hitboxliveHelp Thank you! Sent. Greeting from Vienna ;-),0,0
2016-07-07 12:34:23,@hitboxliveHelp None of the emails we tried was associated with the account. Is it really taken already or did we type wrong email?,1,0
2016-07-07 12:32:50,"@hitboxliveHelp Hi, we're planning to stream @nuclai on HitBox but it says 'nuclai' is taken‚Äîwhich never happens ;-) There's no user page.",0,0
2016-07-07 12:10:35,"The state of Seq2Seq open source code in Python comes as a surprise, few actually perform well. One in Torch does! https://t.co/jJmX0mQoZf",38,16
2016-07-07 09:38:27,"@quasimondo Yes, I can confirm. The representation helps me better control the style transfer: e.g. match Y only, leave uv intact.",1,0
2016-07-07 09:23:09,"Things like 'Hardware &amp; Optimization', 'Social Media Bots', 'Compute Frameworks' or 'Indie Games'. Others? It may be Python-esque!",0,0
2016-07-07 09:19:15,"We're turning tables in the lobby at #nuclai16 into ""smart objects"" that help you start conversations. Any requests for topics?",2,1
2016-07-07 08:58:12,"@inversed_ru Yeah, that's next! I didn't port Lab color conversion code to run on the GPU yet (more complex), YUV was much simpler.",0,0
2016-07-06 21:38:17,@AT1ST It's just trying to re-generate the same image from a slight distortion and noise. Done well you can't tell difference!,0,0
2016-07-06 21:31:33,Previous experiment with a residual auto-encoder didn't work well for style transfer. This is looking more promising! #NeuralDoodle,5,0
2016-07-06 21:30:31,"Training a convolutional auto-encoder with YUV inputs, to see how it works out. Random samples from training set: https://t.co/5z3ktkHvsv",12,0
2016-07-06 19:52:37,"@AlanZucconi Indeed! Fast path tracing is a dark art. In most shaders, when you make big changes it just breaks...",0,0
2016-07-06 19:49:52,"@AlanZucconi Yes, rewrote about a third of it. See credits: https://t.co/C4cDRnFFIp",0,0
2016-07-06 19:28:41,"@logodaedalus I think you'd just get 4 arcs? Not sure, need to read the paper‚Äîhopefully it's simpler than most ML papers!",1,0
2016-07-06 18:53:43,"@jannis_r Can't say I'm a fan as a user, didn't consider it as streamer. HTML5 is unreliable, hard to embed, poor chat...",0,0
2016-07-06 18:47:48,"@logodaedalus But if they use ""time alignment"" like in animation research then the timescale wouldn't matter... I presume that's necessary?",0,0
2016-07-06 18:46:56,"@logodaedalus They seemed to use nearest neighbors to match patterns, in which case short stories wouldn't match (different scale).",0,0
2016-07-06 17:33:34,"@SnstrMephisto A test wouldn't get enough viewers, can only go on recommendation. Maybe I'll do a quick check then email them...",0,0
2016-07-06 17:30:07,"@deplorableword Using OBS already, but rather not do both as it's significantly more risk/work‚Äîunless there's a good reason?",0,0
2016-07-06 17:24:39,"Considering streaming #nuclai16 w/ @HitBoxLive rather than YouTube. Pro: works in Germany. Question: reliable enough, even for many viewers?",0,0
2016-07-06 13:29:38,@MikkoMononen Next time you attend I'm sure we'll have a talk on home automation ;-),0,0
2016-07-06 12:56:58,@SnstrMephisto @nuclai Air Conditioning!,1,0
2016-07-06 12:47:15,". @shahidkamal Yes, the amphitheatre will be streaming live online. Spread the word ;-) https://t.co/Je8R1Usr4M https://t.co/kqPRoqBoeY",8,7
2016-07-06 12:41:06,"Exhausted, but very pleased. I want to attend them all :-) Hopefully you can tell it's a conference by developers, for developers!",2,1
2016-07-06 12:36:04,Track Organizers: @AngryAnt @clodericmars @diego_pliebana @GET_TUDA_CHOPPA @HAStark @michaelrouille @MikaVehkala @noorshak @RichardKogelnig,3,1
2016-07-06 12:32:26,"Keynotes:
‚Üí Crowd &amp; VFX AI in SPECTRE
‚Üí Procedural pipelines at Electronic Arts
‚Üí Lessons deploying Pepper the robot https://t.co/DPwwwTiQow",2,8
2016-07-06 12:27:01,"Phew! Schedule is finished. 67 sessions over 3 days, 62 international speakers. #nuclai16 https://t.co/NfuVWcdfBv https://t.co/nwHCRkZK22",42,20
2016-07-06 00:19:15,@bmcnett It's becoming more obvious that sub-groups in the 1st world now have their own disconnected (maybe incompatible) belief systems.,1,0
2016-07-06 00:15:13,@bmcnett I like to read lots of fiction as well as facts. It's entertaining and a nice challenge for the rational part of my brain!,1,0
2016-07-06 00:07:57,"@StStamenkovic Is there any difference in the ""beliefs"" of those who know by fact or science vs. those who just know by faith or doctrine?",0,0
2016-07-06 00:07:13,"@StStamenkovic I don't know, would love to run simulations to find out! Do you behave differently if you know ""for sure"" vs. with faith?",0,0
2016-07-06 00:03:16,"Imagine the Secret of the simulation handed down from one generation to another, while most of the population is mislead with a cover story.",3,1
2016-07-05 23:59:17,"Most interesting would be watching power dynamics between sims who found out it was a simulation, and those (disadvantaged?) who don't know.",2,2
2016-07-05 23:58:01,If it doesn't work out just reset and try with different parameters. Controlling the simulation likely wouldn't lead to interesting results.,1,0
2016-07-05 23:56:44,"If I was running a simulation, I'd love to see how sims reacted if they ever found out! Room for emergent behavior. https://t.co/t7dddviYP3",8,2
2016-07-05 23:13:40,@ZigguratVertigo Very cool! Looks like an amazing opportunity :-D,2,0
2016-07-05 22:33:54,@AngryAnt Utility makes sense then. Carry on! ;-),0,0
2016-07-05 22:07:09,"@AngryAnt I mean, what are you trying to do? Build a useful middleware solution!!!1",0,0
2016-07-05 22:06:12,@AngryAnt You could emulate utility by having your BT emulate the compute on binary representation of the floating point representation.,0,0
2016-07-05 21:49:49,@AngryAnt Sellout. üí∞,0,0
2016-07-05 18:50:23,"@codecow Not sure what would happen if you contacted them! They basically seemed to stop promotion a while ago, not sure about development.",0,0
2016-07-05 18:46:12,"@codecow Kynapse is gone now, so not a long term business or solution. Agree with other low-level things, slowly building on each other.",0,0
2016-07-05 18:43:40,"@craigperko Yes, that's one that's up-and-coming very fast!",1,0
2016-07-05 18:43:04,"Middleware companies that succeeded best in #GameAI are those that addressed immediate needs, then let the developers expand their designs.",1,0
2016-07-05 18:41:45,There's solid market for Blue Ocean products as long as there's demand for them. But in this case they still need to convert from Blue Sky.,1,0
2016-07-05 18:38:54,"Based on the argument in this post, the primary goal of the company should be design: convincing developers there's value in #AI they sell.",0,2
2016-07-05 18:37:36,"Don't agree w/ reasons, but it's strange to admit there's no current market for the product. https://t.co/d0CziDK50f https://t.co/4sKSdWeVK4",1,0
2016-07-05 17:07:42,"There are also indie solutions for Unity:
@AngryAnt's Behave (with tree-style logic).
@tenpn's DecisionFlex (for utility calculations).",6,0
2016-07-05 17:02:45,"Both include navigation and behavior (of course)‚Äîthough increasingly complete packages that includes sensing, memory and architecture.",2,0
2016-07-05 17:01:26,"I should mention other independent Game AI companies for completeness:
@RivalTheory focusing on Unity
@KytheraAI with roots in CryEngine",7,1
2016-07-05 16:52:23,. @richardmatthias I doubt it's easy to make a quick profit from Game AI middleware. Many tried before and most failed. VCs do homework!,4,0
2016-07-05 16:51:15,"The other goals sound like a 2016 reboot of @Storybricks‚Äîwhich closed down. It's a tough business statistically, been watching for years!",2,0
2016-07-05 16:47:43,The website lists Abuse Monitoring as one of their tools. Field is more competitive but also likely easier to sell! https://t.co/i752sf6ZFb,1,0
2016-07-05 16:43:23,"It seems to be cloud-powered by IBM Watson. They can't officially say ""Watson"", but it's the likeliest interpretation from team profiles.",0,0
2016-07-05 16:41:13,"Advisory team is high pedigree, not sure who's doing day-to-day development. Certainly looks very ambitious, but as a startup it has to be!",1,0
2016-07-05 16:37:28,Does #MobiusAI have what it takes to succeed as a games middleware where many failed before? https://t.co/LdWqX5BEKy https://t.co/jckWEXb0pb,11,2
2016-07-05 16:33:26,"@togelius Interesting! Minor technical issue: the post says it's ""By"" simon at the top, but you show up as the author at the bottom.",1,0
2016-07-05 09:28:25,"@RecklessCoding Yeah, I know. Great to have you on board! ;-) Could make a separate bot/script that uploads photos but not sure I have time.",1,1
2016-07-05 09:22:21,@RecklessCoding We were going to have the social media team curate and add a vignette onto the images for official @nuclai account...,1,0
2016-07-05 09:21:34,"@RecklessCoding Remote control? If you have cameras around your neck some of the time, that could turn into an inadvertent crotch pick? ;-)",1,0
2016-07-04 23:44:08,@avyfain Thinking of just having an official hashtag just for bots and displaying Tweets from that search. How does it sound?,0,0
2016-07-04 23:30:30,@avyfain Deep is overrated ;-) The latest code for @DeepForger will be very shallow!,1,0
2016-07-04 23:26:00,I hope I'll have time to bring @DeepForger back to Twitter for this! It'll likely need some company though... Any volunteers?,1,0
2016-07-04 23:23:25,This idea is too good to pass up! Looks like we'll have generative bots live-tweet #nuclai16. World first? ;-) https://t.co/4unKMcRx99,3,0
2016-07-04 23:20:43,"@GalaxyKate Cool, with a special hashtag! Could also show their besht tweets during the coffee breaks on stream/projector.",1,0
2016-07-04 23:15:48,@GalaxyKate We have yet to figure out what registration means for a bot... Maybe a reverse CAPTCHA?,0,0
2016-07-04 23:13:58,@GalaxyKate We designed this registration poster today and I immediately thought it would resonate with you ;-) https://t.co/A4eWnHnaVw,2,0
2016-07-04 21:33:00,"@tenpn He suffered brain damage, can't remember his email. His wife caught him cheating now trying to revenge. He's dead, kids want access.",0,0
2016-07-04 21:29:40,"@tenpn Trying to think of situations where someone with the same name as you would try to recover their accounts like this, none are good.",0,0
2016-07-04 21:27:18,"@tenpn @Greenfaery Google treats all those emails as the same, including anything with +custom as a suffix.",0,0
2016-07-04 20:23:27,@dribnet :-) I'm impressed how it deals with the hair reconstruction here too. There was another recently I thought the same.,0,0
2016-07-04 20:22:24,"@edersantana No, I suspect people will deploy lightweight networks (e.g. SqueezeNet) with binary weights on CPU.",0,0
2016-07-04 20:13:35,"@edersantana Google had been suppressing OpenCL in favor of RenderScript a few years ago, not sure what the state is now. Hardware is there!",0,0
2016-07-04 20:06:52,@edersantana The platform has been the biggest issue in the past. Is Android exposing access to OpenCL when the GPU already supports it?,0,0
2016-07-04 19:55:11,@edersantana OpenCL on mobile has been a disaster! Is it getting any better?,0,0
2016-07-04 19:46:32,"@erocdrahs It's a different algorithm. They have large pre-process times for new styles (4h-6h), but fast per content image.",1,0
2016-07-04 19:44:41,@gcpascutto Intel is guilty too. They both have mature OpenCL implementations but need the industry-topping benchmarks to get DL attention.,0,0
2016-07-04 19:43:36,@erocdrahs Crisp! Were these using #prisma?,0,0
2016-07-04 19:40:14,"Last I checked Theano's OpenCL backend was basically functional, only missing convolution kernels. Opportunity for high-impact work there!",3,0
2016-07-04 19:36:39,"If someone did this for OpenCL and benchmarked on AMD's new cards, that would have significant impact on GPU prices. https://t.co/duTnVqdstn",7,3
2016-07-04 15:06:23,"@edersantana Yes, I think it makes a lot of sense technically. It's the tone from press coverage that's very disconnected from this mindset.",0,0
2016-07-04 14:27:58,LSTM after only 1 epoch inadvertently generates Tweet describing @nuclai. Should be a fun workshop ;-) #ai #ai #ai https://t.co/JAeynb9EsA,14,2
2016-07-04 14:22:33,"@paniq I think non-developers would have already requested a refund by now, but I guess you want answers more than anything? ;-)",0,0
2016-07-04 10:09:00,It's what I'm looking forward to most about #nuclai16: it'll be a bolt of raw inspiration &amp; enthusiasm amidst an otherwise confusing time.,6,0
2016-07-04 10:06:09,"Things also feel off today, but there's an important deadline if you want tickets/upgrades, so can't delay... https://t.co/tMHDWSf1Kw",1,0
2016-07-04 10:04:28,"It's been such a strange few months, so many times we thought: ""The mood on social media is weird, let's hold back on announcing this.""",2,0
2016-07-04 09:26:03,"@danofer Oh, just realized I never tried Freddie and Mia mixed with Gogh and Seth. Likely possible with parameter exploration...",0,0
2016-07-04 08:52:54,"@danofer If you get OMP working with multiple threads (by default on OSX) it can be even faster, 40s-60s.",0,0
2016-07-04 08:51:19,@danofer Since it's faster it's easier to go through many options: https://t.co/rnomw4aALv,0,0
2016-07-04 08:46:28,"@edersantana @samim Ah, no I don't recall but would love to know more! Various articles seem to imply it was E2E.",1,0
2016-07-04 08:36:46,"@danofer Portraits are always tough to get right even in the main branch, there are some settings that work but they aren't the default.",0,0
2016-07-03 22:49:08,"I feel Google is ahead as they made right choice targeting full automation from the start. Tesla's approach was uncertain, even more so now.",5,0
2016-07-03 22:44:29,"@nikete I submitted a bunch that were incomplete and at least partially incorrect, and it thanked me!",0,0
2016-07-03 22:35:45,"@deadalnix And, check out that mean stare in the photo. Bad boy!",4,0
2016-07-03 22:28:30,"And they're probably just using off the shelf deep learning libraries. I guess about 2 years behind Tesla, 5 years behind Google?",6,1
2016-07-03 22:27:00,My cynicism is proportional to hype / substance; in this case it's rather high. They secured $3m for this... https://t.co/v1ocWiSxFE,5,2
2016-07-03 22:02:33,"@sknthla Maybe they'll have each task completed 3x and compare the results. Not sure they'll get much data anyway, obviously exploitative.",1,0
2016-07-03 22:00:22,"Fulfill your passion of annotating in-car views, or submit complete garbage to see how the EU's upcoming ""Right to Explanation"" holds up!",7,1
2016-07-03 21:59:19,"Did you ever dream of being an unpaid Mechanical Turker, creating data for the next startup to be acqui-hired? https://t.co/PsKyjvoWqG",61,29
2016-07-03 17:38:54,"@danofer For Deep Learning, Windows is the problem ;-)",0,0
2016-07-02 11:54:52,"@tenpn @jurieongames No, nothing new... It's many months old. I want the whole slack chat to be (mostly) task-structured. Possible?",0,0
2016-07-02 11:49:02,"@danofer As I suggested above, if you use the `forward` branch you don't even need CUDA. Very fast without!",0,0
2016-07-02 10:53:24,"@jurieongames Hehe, that's not what I meant‚Äîbut glad the humour came out ;-) I mean that Trello/Slack is an ugly and awkward mix.",0,0
2016-07-02 10:51:04,"@jurieongames ""You can do a shitty integration very easily, but you'll be cursing for the rest of the year.""",0,0
2016-07-02 10:50:35,"@jurieongames Oh, we have Trello integrated (not a ""bot"" per-se) but it really sucks compared to what a sensible Slack design would do.",1,0
2016-07-02 10:49:10,"@jurieongames We only use Slack as IRC+pinned docs, not used any real bots yet. I wouldn't know where to start...",0,0
2016-07-02 10:47:28,"@jurieongames Of course, but for well understood tasks (order taxi) for non-experts there's the potential of this approach taking over.",1,0
2016-07-02 10:46:57,@jurieongames Telegram is also interesting here because they expose commands with auto-complete and help inline.,0,0
2016-07-02 10:42:39,"@jurieongames Then once you have a portrait, someone else could come along: ""Like this portrait, but rougher brush strokes and warm colors.""",1,0
2016-07-02 10:41:48,"@jurieongames I'm imagining @DeepForger bot as a way to get the portrait you want without having to learn 1,000x photoshop menus/options.",1,0
2016-07-02 10:35:55,@jurieongames The biggest promise for this interface is having the bot know to skip beginner tutorials and learn common shortcut commands.,1,0
2016-07-02 10:29:55,@jurieongames It's effectively treating any program interface as a search box then attaching a small (optional) tutor/guide onto that.,1,0
2016-07-02 10:26:34,"@jurieongames @mark_riedl It's not built for that, conceptually it's closer to a water-cooler than a desk or tool.",1,0
2016-07-02 10:25:54,"@jurieongames For me, the revolution is having a smart tutor to guide you and easy way to search any feature‚Äîrather than huge cumbersome UI.",1,0
2016-07-02 10:23:06,@jurieongames @mark_riedl I'm underwhelmed by Slack too. It's being used for things it doesn't seem to have been designed for.,0,0
2016-07-02 10:19:18,@danofer There's no easy way to do this without making assumptions about the content. If you can do it then make 2nd script for inputs.,0,0
2016-07-02 10:18:38,"@jurieongames @mark_riedl It's not text chat that's the revolution, it's the new platform &amp; interface‚Äîin some ways despite chat.",0,0
2016-07-02 10:17:00,"@jurieongames @mark_riedl That's why the buttons make it clearer, use text input field as a quick search, then button to confirm intent.",1,0
2016-07-02 10:15:36,@danofer The semantic map is optional. By default it will do something sensible.,0,0
2016-07-02 10:14:25,"@danofer Looks good! If you have CUDA already working, the rest is a single command install.",0,0
2016-07-02 10:12:54,"@jurieongames @mark_riedl I had hoped Twitter's polls could be used for this purpose (better interface), but they don't have foresight.",0,0
2016-07-02 10:12:05,@jurieongames @mark_riedl You should check out Telegram's bot interface. This and other clever ideas: https://t.co/KNeMx3JUTm,2,0
2016-07-02 09:05:33,"@ngutten @mark_riedl Only if you can qualify those 215,000 people is it a full explanation‚Äîbut by then it's easier to explain this 1 case.",0,0
2016-07-01 23:29:02,@ExUtumno @aireye I'd be curious to hear more as well! I'm working on a faster/hires version of #NeuralDoodle‚Äîkeen to make sure it works.,0,0
2016-07-01 20:45:42,"@tenpn Congrats! As long as you beat Portugal, I'm very happy for you ;-)",0,0
2016-07-01 20:38:04,"Neither of us noticed until we finished the drink, then we had a good laugh about it for 2 minutes. Should put recipe up online somewhere...",4,0
2016-07-01 20:32:33,@mark_riedl @mtyka No. Human decisions are irrational. See Trump and Brexit. Marketers also exploit this heavily.,1,0
2016-07-01 20:28:59,"Long day and kids are away, so made a nice drink for Petra. Later turns out the ice cubes in bottom of refrigerator were chicken stock ;-] üêî",20,0
2016-07-01 20:25:33,"@mark_riedl Yes, I agree. The difference with this ruling is that it'll force companies to do it too (before deploying), not just academia.",3,0
2016-07-01 20:21:45,@mtrc How did ICCC go? Sad I couldn't be there but was following Tweets all week.,0,0
2016-07-01 20:19:28,"@saltyhorse Yes, I think it would. If the ""pixels"" are regular (actual pixels) you could down-sample, transform, then up-sample again.",0,0
2016-07-01 20:14:57,"It'll push development of algorithms to inspect/understand deep networks, and also explain parameters human experts may not have considered.",2,4
2016-07-01 20:13:42,"Being able to ""align"" the deep network's understanding with intuitive parameters that human can grasp is useful to have anyway.",6,0
2016-07-01 20:12:32,"It means end-to-end deep learning that you can't understand is out, unless you can impose constraints on the latent space in the middle.",2,1
2016-07-01 20:11:28,"Overall I think this is the right direction to head towards, I don't think it'll affect the technology too much. https://t.co/KHF30E1odt",7,4
2016-07-01 20:09:04,"@mtyka The issue depends on what you consider ""significant"", eg. a loan decision or insurance rates? Hard to speculate how it affects Tesla.",1,0
2016-07-01 17:07:00,"My take on copyrighted material for deep learning:
1) If you do it well nobody will ever know.
2) Once you succeed, they'll sue you anyway.",10,4
2016-07-01 17:05:46,"Discussion about copyright and machine learning. Fascinating topic, sparked some interesting comments! https://t.co/pZw3eDAX4f",10,1
2016-07-01 14:48:38,@GET_TUDA_CHOPPA I wonder if they are cancelling future flights due to rising costs from GBP drop. https://t.co/0Bwfaa3bVK,0,0
2016-07-01 13:53:16,"@RecklessCoding Also an education problem. Many other appliances are ""life and death"" (or serious injury) but they are better understood...",1,0
2016-07-01 13:16:19,"@bmcnett @KreolDev Not sure how you'd generate lips, but the idea of generating voice that already fits is funny: https://t.co/V2JexJicav",1,0
2016-07-01 13:12:54,@bmcnett @KreolDev Voice synthesis can be done surprisingly well if the data is there and some compute time is dedicated. Getting there!,0,0
2016-07-01 13:01:22,"@dribnet Maybe save up for a paper on arXiv, no matter how small, or you'll get no academic respect for it. Your faces are the best so far!",5,0
2016-07-01 12:54:13,"@dribnet There must be a reason for it emerging... Helps the network control whether it should overfit or not? If so, it's pretty clever!",0,0
2016-07-01 12:45:57,"@dribnet Is this feature in latent space consistent, so if you retrained would it still be there? Trying to understand why it emerged...",0,0
2016-07-01 12:33:49,"20th century: Good artists copy, great artists steal.
21st century: Good artists copyright, great artists generate.",19,8
2016-07-01 12:08:38,"The regenerated faces look better with every iteration, @dribnet. But face selection/placement are this bot's charm! https://t.co/NxIdwDDBPH",5,0
2016-07-01 11:00:35,"Anyway, more testing soon but great news for the live stream! Details &amp; notifications here: https://t.co/Je8R1Usr4M https://t.co/FJwJoTHy9r",1,0
2016-07-01 10:57:26,My latest work-around was going via analog to bypass HDCP flag (DRM) that was erroneously set. There were driver bugs/glitches there too...,0,1
2016-07-01 10:55:29,"Turns out Windows HDMI capture now finally works out-of-the box! It took years to get to this stage, but I'll take a stroke of blind luck.",1,0
2016-07-01 10:51:15,"Our capture card drivers updated today. Naively thought: ""Update today? It's just for me. Everything will work now!"" https://t.co/UJ4EgcAUQs",1,1
2016-07-01 10:42:58,@ivanassen - social media,2,0
2016-07-01 10:32:03,Christo and Jeanne-Claude are famous for their Art of wrapping up everything small and big. https://t.co/DRJcCGKbTk https://t.co/9Qfg2QQPkU,4,3
2016-07-01 10:30:15,The official mugs look amazing! Very shiny so had to wrap it up for a photo ;-) Like a small scale Christo exhibit. https://t.co/RZgKffKMCf,14,0
2016-07-01 10:21:26,"Kids are now semi-guiltily offloaded to my parents for their summer vacation, so we can fully focus these last 2+ weeks before the storm!",1,0
2016-07-01 10:20:11,Didn't realize the extent of the boxes when I arrived late yesterday. Petra has been busy with @nuclai preparations! https://t.co/6RyMQhCJ9W,6,2
2016-07-01 08:41:12,"@dribnet @smilevector Wow, much better! Pretty soon it won't be noticeable that there was any modification ;-)",2,0
2016-06-30 14:22:35,"Someone needs to tell them to use the word ""Residual"" instead... It'd be more 2016 that way!",3,0
2016-06-30 14:21:55,Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections https://t.co/iBUdg1Sj2E #dlearn https://t.co/ca8jtQKwwm,33,8
2016-06-29 20:34:54,"The weather feels like March here in Brittany, but that doesn't seem to bother any of the plants ;-) https://t.co/kt6tvfilAW",2,0
2016-06-29 20:23:47,"Back to civilization tomorrow morning, enjoying the coastline for one more evening... https://t.co/ASowFu0RvL",7,0
2016-06-29 15:10:17,"@annajordanous @creativeEndvs Intuitively, I see #CreativeAI as application focused with less interest in understanding human creativity.",0,0
2016-06-29 15:09:25,"@annajordanous @creativeEndvs They are not necessarily distinct communities, just separate websites by admininstrative/technical necessity.",1,0
2016-06-29 15:02:02,@creativeEndvs @annajordanous Does CC have a clear definition? I don't think there's anything formal on the other side.,0,0
2016-06-29 14:03:36,@tech_mind Yes! It prompted some improvements in the main branch and the new forward branch in original repository.,0,0
2016-06-29 12:59:52,"@creativeEndvs The website seems to have no curation so far, whatever people feel is relevant is posted. Works for small communities!",0,0
2016-06-28 10:30:42,"@Smerity If done well, the line between mass-produced and artisan should be very fluid and traversed often. It's common problem in #procgen!",3,0
2016-06-28 10:29:52,@Smerity I get the sense that soon a different community (better artists) will take over exploration with AI once it's more accessible.,1,0
2016-06-27 20:25:19,"Away for a few days, taking the kids to my parents until the conference. Couple things seem to need my attention ;-) https://t.co/RaYDO3j8yB",6,0
2016-06-26 17:10:53,"@mtrc On the left sidebar, ""History"" &gt; ""Clear Watch History"".",0,0
2016-06-26 17:08:43,@mtrc Did you know you can clear your history? Plus I always do non-work YouTube in incognito ;-),0,0
2016-06-26 17:06:22,Which reminds me the kids are soon old enough to learn the scientific method. There's some great starting material there ;-),2,0
2016-06-26 16:56:48,"Yesterday made the mistake of watching some Brexit-related videos on YouTube, one auto-play later it's JFK theories then Flat Earth.",29,4
2016-06-25 13:46:21,"@nrose @baburovn Oh, I misread the ""feed forward"" in your tweet. Yes, likely a particularly good implementation of it...",0,0
2016-06-25 07:58:45,@nrose @baburovn Prepare the knife and fork! It returns results in second with a limited style selection.,0,0
2016-06-24 12:56:01,"Source (just published): https://t.co/DpglMgYN0u ""DeepWriter: A Multi-Stream Deep CNN for Text-independent Writer  Identification""",5,3
2016-06-24 12:55:04,"""Average the predictions of separately angry individuals, and you get a big fat middle finger as output."" #democracy https://t.co/pvisyR8e2Q",31,9
2016-06-24 12:44:07,"@ngutten I'm just using Gaussian multiplicative noise instead for now, together with small loss_decov we talked about.",0,0
2016-06-24 12:39:18,"@ngutten Using total variation on output usually fixes it, but in my latest residual architecture it doesn't work: dropout&gt;0 yields dither.",0,1
2016-06-24 12:38:23,"@ngutten Oh, that is absolutely the problem. Perceptual loss filters are not blurry but definitely have no bias towards smooth images...",0,0
2016-06-24 11:31:53,"@ferrouswheel BTW, do you have an intuitive explanation why grouping helps with that dithering / screen door effect?",0,0
2016-06-24 10:11:52,"Tree-structured convolution net predicts multiple colorizations, used to guide compression: https://t.co/vAeNmQmKsm https://t.co/NGML37iGcP",23,7
2016-06-24 08:43:44,@ngutten Have you seen any fixes for this? I saw a mention of applying total variation loss on the activations too...,0,0
2016-06-24 08:01:23,@lexiconjure brexit,0,0
2016-06-24 06:29:31,@zoombapup Echo chambers aren't necessarily a good thing...,0,0
2016-06-24 06:26:37,"@ngutten Ah, I see. Yes, that part I agree with. However, it's learned dithering in the sense that the results score high perceptually!",0,0
2016-06-24 06:14:46,"@ferrouswheel Theano will shine there, I wonder if there already is such a thing in Lasagne.",1,0
2016-06-24 06:13:58,"@ngutten It's only for certain colors and context-sensitive. I'm using float32 and nice smooth activation functions, no discretization.",0,0
2016-06-23 23:06:58,"@aireye Implication seems to be ""free market will work it out"" but even IMF recently changed its mind about infamous Trickle Down economics.",0,0
2016-06-23 23:05:51,"@aireye Agree. To question assumption of the graph, I'm still unsure if 1) economists have any clue, or 2) are working in our best interest.",2,0
2016-06-23 22:58:06,"@aireye @fchollet Oh, that's easily dismissed by the top right quadrant. Didn't you see the funny text? It has retweets, going viral!",0,0
2016-06-23 22:49:20,"@ferrouswheel Like splitting the channels into groups, applying convolution separately, then merging afterwards? Should be faster too!",1,0
2016-06-23 22:45:01,"@fchollet If you venture outside your company campus, malls or gated communities, do you see things getting better? https://t.co/Gv8RypHLZx",1,0
2016-06-23 22:28:29,"@ferrouswheel I don't know what ""group"" means in Caffe terminology. Is there another word to describe it?",0,0
2016-06-23 22:26:34,This is a good chart as long as you remember that poverty &amp; unemployment are widespread already regardless of AI. https://t.co/lRl0D4ldUM,4,2
2016-06-23 21:55:09,"Without zooming in, the reconstruction is arguably better than original‚Äîdespite dithering‚Äîbut it'll cause trouble. https://t.co/sxwBxL8lpI",1,0
2016-06-23 21:50:01,I find it equally amazing &amp; annoying that convolutional networks can learn image dithering patterns where necessary. https://t.co/US3GeQ5tcE,18,2
2016-06-23 20:36:01,"There's no bubble here, it's more like... a zeppelin! Gonna be smooth sailing here on through. https://t.co/x3XurtHO49",2,1
2016-06-23 20:26:11,Obviously we just *had* to watch the Person of Interest finale to prevent accidental spoilers. Predictably great! https://t.co/6FQNgZ4FIR,7,1
2016-06-23 15:49:44,"In case you wonder what this robot is useful for, the full video raises more questions ;-) https://t.co/1owpyhEEuW https://t.co/i1aoQTx1Dg",77,48
2016-06-23 10:01:27,"@samim Not just the middlemen, it will also have a huge impact on musicians! Who own copyright of randomly generated music?",2,0
2016-06-23 09:32:25,"Ah. It's generating random emoji by treating all characters as 8-bit from str, so now applying various prefix codes randomly! @speedingdeer",0,0
2016-06-23 09:08:25,"Training LSTM for #nuclai16 workshop. Now input data has overflowed into 16 bits it generates emoji, untrained: https://t.co/sTeM5gl8ls",28,8
2016-06-23 08:15:46,@GalaxyKate @inconvergent Whose theory was it that AI could in fact create more jobs for humans? ;-) P.S. T-shirts look great!,2,0
2016-06-23 07:40:54,"Not had much success with overnight experiments recently, but... Is It Art? https://t.co/cMj5mFJjF1",4,0
2016-06-22 19:40:15,"@totallytroy @mikepelletiernl Yes, that's what #NeuralDoodle does. https://t.co/7kVPE0p4m3",0,0
2016-06-22 19:19:18,"@mikepelletiernl It's impressive ;-) I hadn't tried Lucien Freud with the semantic maps, works rather well!",0,0
2016-06-22 19:14:22,"@TurfsterNTE @duskgame @ForgetAmnesia Next step is to have automated AI bots test experience in the level, auto-QA to see if it works! [3/3]",1,0
2016-06-22 19:13:08,@TurfsterNTE @duskgame @ForgetAmnesia If the levels are fun (or lack something) it's due to the designer's understanding of algorithms [2/3],1,0
2016-06-22 19:11:42,@TurfsterNTE @duskgame @ForgetAmnesia Most procedural approaches today rely on rules coded by a designer‚Äîmore or less indirectly. [1/3],1,0
2016-06-22 15:48:37,@richardmatthias https://t.co/Q9QG2KIBh4,1,0
2016-06-22 12:09:54,"@baburovn There are other apps on iOS that do this. It's not clear what technology they are using, existing work or something new?",0,0
2016-06-22 11:50:27,"@baburovn Yeas, I saw some of its output! Limited styles right? Looks great from what I saw.",0,0
2016-06-22 08:34:22,Patch-based style transfer using only residual signal (not colors). Like 70s wallpaper tones/texture! #NeuralDoodle https://t.co/zGJLfEZMp2,18,3
2016-06-22 06:21:28,@vakibs @ngutten @fchollet In my case it was open source with blog post (still no paper) but also wasn't credited.,1,0
2016-06-22 06:20:12,"@vakibs @ngutten @fchollet The problem here is that prior art was open source code announced with a Tweet, not a paper. Harder to find!",1,0
2016-06-21 17:32:58,"@astro_pyotr @fchollet @vakibs My feedback mostly focused on searching/browsing, not sure if I mentioned comments at the time.",0,0
2016-06-21 15:44:54,"@visageofscott Regular ponies don't cost as much, but don't be fooled!",0,0
2016-06-21 15:02:43,"@vakibs @fchollet A more open review process (e.g. comments on arXiv) would catch a lot of problems, even if it's after first submit.",0,1
2016-06-21 15:01:00,"@xululululuuum Yeah, it's a simple trick too!",0,0
2016-06-21 14:56:56,@xululululuuum Are you looking at the image with the Tweet or the paper?,0,0
2016-06-21 14:16:55,"@fchollet I know how you feel. There's always the chance they didn't know, but if you contact them and they don't credit then it's rude.",3,0
2016-06-21 13:46:41,@randal_olson @amuellerml The latest batch of adversarial / generative techniques use AE principles too. Full circle ;-),4,0
2016-06-21 13:45:38,"@isaackarth Hue won't work since it's a discontinuous dimension that wraps around, can't do interpolation. Best candidates are YUV or Lab.",0,0
2016-06-21 13:34:23,"@eisokant I don't know, but @quasimondo may be able to advise.",0,0
2016-06-21 13:26:22,"@isaackarth No. They did not retrain a network and since I'm doing that now it's also on my mind. YUV seems a bit easier, thoughts vs. Lab?",0,0
2016-06-21 10:17:11,@quasimondo @inconvergent Assuming you don't model science or mathematics that could work...,0,0
2016-06-21 10:12:19,"@quasimondo @inconvergent If I build a computer to monitor everything for me, then the simulation needs to make that consistent...",0,0
2016-06-21 09:43:01,@ferrouswheel @inconvergent ;-) You're just a Javascript chat bot in my simulation code. How many of us are there really?,1,0
2016-06-21 09:38:26,"@inconvergent Corollary: we could be in the experiment of an advanced Alien race, but one that's actually built with physical materials.",0,0
2016-06-21 09:36:51,@inconvergent I had the same thought. Simulating a whole planet down to the molecule without actually building it physically is intractable.,1,0
2016-06-21 06:12:19,Two simple but effective options: histogram matching (similar to original DeepTexture code) or luminance-only transfer (guessed by Reddit).,2,0
2016-06-21 06:11:14,Preserving Color in Neural Artistic Style Transfer https://t.co/HAhRYKctbF (New paper by Gatys et al.) #DeepStyle https://t.co/wsLj9alCe1,38,8
2016-06-20 22:50:31,"@graycrawford I'm not sure I got it right yet, first integration into new code and some data is missing at runtime. May be random noise ;-)",0,0
2016-06-20 22:49:50,"@graycrawford If I don't make the problem harder, it can learn to reproduce the original almost perfectly. But that's not the goal...",0,0
2016-06-20 22:44:59,"@graycrawford I feed in a lower resolution version of original image, residual is all the high-quality detail that was lost.",0,0
2016-06-20 22:39:49,I *think* this is the residual (normalized) of a residual auto-encoder. Forgot to inject the actual image data... https://t.co/m1Z5LrmlCn,11,1
2016-06-20 21:20:47,I suspect combining the two would get you even better results at similar performance level. Hopefully someone with more time is curious too!,2,0
2016-06-20 21:19:37,"Performance aside, I'd love to see a comparison with Justin perceptual loss: https://t.co/bTbPzYGUPc Instead, subpixel paper uses usual MSE.",6,1
2016-06-20 21:16:41,"It does upscaling of 1080p video in real-time by operating at lower resolution throughout, then just reshuffle into final image afterwards.",1,0
2016-06-20 21:15:22,Super-Resolution Efficient Sub-Pixel Convolutional Neural Network https://t.co/NGR5VPC9Z6 Very clever! (via @halhod) https://t.co/ty4G151P06,37,8
2016-06-20 19:42:50,"@sknthla However, procedural texture tools (increasingly popular) go in the opposite direction, use code to generate both‚Äînot data. [2/2]",2,0
2016-06-20 19:41:46,"@sknthla Not that I'm aware. Could also automate the process of removing lighting, to generate ideal textures too. [1/2] @samim",2,0
2016-06-20 17:12:36,"@halhod If they've figured out how to run the code on compute-challenged phones, the acquisition makes sense (e.g. shader or ARM-optimized).",1,0
2016-06-20 17:11:01,@halhod True. How is Periscope doing? There'd be a lot of value in deploying it at full scale within 6 months. Mobile will be challenging!,0,0
2016-06-20 16:55:33,@halhod Trying to rationalize the acquisition: likely patent portfolio (defensive) plus the team behind it for ~2-3 years (offensive).,0,0
2016-06-20 16:51:57,"@halhod If it's an open paper, it can't be a reason. It'll be open source soon if not already... 150M is expensive for 3 month advantage.",0,0
2016-06-20 16:17:07,@graphific Cool! How is inference speed? Previous CUDNN updates were not worth the time for performance so far...,0,0
2016-06-20 15:36:07,@mark_riedl Next round is Facebook vs. Google then we can declare a winner and they're done for this season until NIPS.,0,0
2016-06-20 13:59:46,@johnhenderson Very cool! Congrats @Rob_Bishop! Are those slides or recordings available somewhere?,0,0
2016-06-19 08:53:26,Anyone using reactive programming for procedural generation? @totallytroy Question came up here.. Watch it! #procgen https://t.co/oPOnsvzYKB,11,3
2016-06-19 08:27:01,"There's a reactive programming framework called RxCpp in modern C++, inspired by LINQ. https://t.co/r2GKlJRNf4 @totallytroy @nuclai",11,2
2016-06-19 08:02:01,"@mikepelletiernl Oh, that's incredibly cool! Was that with the same scale but no semantic map? Did you use the --variety parameter?",0,0
2016-06-19 05:18:51,"@SnstrMephisto If you know some statistics, should be OK. The files are not too big considering!",1,0
2016-06-19 04:40:47,"@DaveChurchill @mark_riedl If you find out who it's from, let us know!",0,0
2016-06-18 22:01:13,"This is a cool project, lots of ideas! https://t.co/uWS6i2PSDj https://t.co/xRZVXr1wcG",11,11
2016-06-18 21:43:35,"Wondering what it'd look like with semantic annotations, and with a portrait that matches size of photo. But obviously not the goal here ;-)",0,0
2016-06-18 21:42:23,"Animated portrait with #NeuralDoodle, mesmerizing to watch! https://t.co/q8LWeDdksG",1,0
2016-06-18 21:39:55,"@prostheticknowl Haha, that's both cool and hilarious! Wonder what it'd look like with semantic annotations...",1,0
2016-06-18 21:36:26,@tenpn Is 5 not too young?,0,0
2016-06-18 20:27:12,@nikete That part works already ;-) https://t.co/EtwQMiSerp,0,0
2016-06-18 20:17:21,"@nikete Many techniques from the 90s should be re-evaluated now we have the computation power and the ""brute force"" mindset! ;-)",0,0
2016-06-18 20:11:10,"@nikete Completely understand, good luck!",0,0
2016-06-18 20:07:30,"@nikete No code yet, I'm thinking out loud! If you're willing to modify code I could talk you through some experiments to try...",0,0
2016-06-18 20:06:51,"@mark_riedl I get that impression for #DeepArt too. The fact it worked at first was almost chance, but now we understand it better ;-)",1,0
2016-06-18 19:59:49,"Latest insight under investigation: #DeepStyle works despite deep representations, not because of them. #ShallowArt doesn't sound as good!",8,0
2016-06-18 19:50:21,https://t.co/aaaBDkmAM1,8,2
2016-06-18 18:56:29,@quasimondo I reverted the symlinks and it's fine ;-) I want to do some real work!,1,0
2016-06-18 18:55:33,"@Aelkus This is my DeepLearning box, Ubuntu 14.04. I use it mostly headless but it's a full installation with screen.",0,1
2016-06-18 18:54:50,@quasimondo I didn't realize until now it replaced the system-wide symlink. Mercurial broke and lots of other things‚Äîcrazy! :-|,0,0
2016-06-18 18:49:32,Conda is supposed to fix Python's packaging disaster but if it doesn't play well with regular setups (force upgrade Python) it only worsens!,1,1
2016-06-18 18:47:52,"Conda decided to replace my /usr/bin/python &amp; python3 symlinks on Ubuntu with a fresh 3.5 it installed, everything broke. Only wanted numba!",3,0
2016-06-18 18:41:27,"@totallytroy You have to sign-up, then the grey down-arrows are download buttons. I used the script linked just after in Twitter thread.",0,0
2016-06-18 17:57:33,"@bcbroom If you have understanding of statistics, then Hugo Larochelle's course on YouTube is pretty good too. Hinton's next.",1,0
2016-06-18 15:27:03,"Enjoying numba, feels like a light-weight version of PyPy that integrates directly with CPython and works today‚Äîrather than a huge rewrite.",16,6
2016-06-18 15:25:31,I'm using numba increasingly to migrate code away from Deep Learning frameworks. Tensors feel brute-force in places! https://t.co/SI0IdhVTS5,9,3
2016-06-18 15:17:23,Reintroduced style variety parameter using a different heuristic that's compatible with PatchMatch. Glad it works! https://t.co/VOuiKaM1zj,14,1
2016-06-18 15:00:21,"@tech_mind @samim Not a traditional convolutional network, for now...",0,0
2016-06-18 14:13:06,@D_M_Gregory @lousylinguist That neural network one is not part of the courses migrating. Not sure how they figured that out...,0,0
2016-06-18 13:59:31,. @lousylinguist You have until June 30th. 472 free courses will be removed. https://t.co/Uvis7B8xby,11,5
2016-06-18 13:52:16,"Using this script to do it all automatically, it works well. https://t.co/pEYqGb7tcJ Any other must-have courses? https://t.co/lTMBRMUw8N",28,3
2016-06-18 13:50:21,"Downloading Geoff Hinton's course on Neural Networks, apparently it will disappear soon... https://t.co/5rJ44sE9hn https://t.co/IaNV9qY7op",68,20
2016-06-18 11:44:34,"@paniq Came to the same conclusion, using a filter rather than unfollowing. IRL you'd just change topic/walk away. https://t.co/DwFiZhTtAX",0,0
2016-06-18 08:02:40,"@rodolfor Maybe not ""convenient"" but ""possible""?",0,0
2016-06-18 07:57:07,"@rodolfor I suspect the founders stashed offshore the money that would have been otherwise taxed, and consider it theirs now?",0,0
2016-06-18 07:55:14,"@rodolfor Amazon for much of its lifetime has been ""not profitable"" or IKEA that's actually a ""non-profit"". Translation: legal loophole.",0,0
2016-06-18 07:54:09,@rodolfor How is that different than what everyone else is doing? It's disgusting overall but not sure what's special in this instance.,0,0
2016-06-18 07:47:40,"@thecodinecowboy Hope to bring @DeepForger back to Twitter soon (spam/abuse issues), but the website is still up!",0,0
2016-06-18 07:29:28,@sneakin ... and cynics ;-),0,0
2016-06-18 07:26:38,@Beetlenaut How you edit and how you render the world doesn't have to be the same: multiple instances or unique tessellated mesh.,0,0
2016-06-17 19:01:36,"There are 14 different nationalities in Leon's class! If we can just get through this one generation cycle, the future looks more promising.",13,1
2016-06-17 19:00:14,"Leon, 6yo:
- I'm supporting Poland, someone in my class is born there.
*next day*
- I'm cheering for Croatia today; they're great too!",8,1
2016-06-17 18:51:08,"@quasimondo Bah, I hate this about conda! :-( Also, you run it from Python 3.4 and next thing you know it switched you to 3.5.",1,0
2016-06-17 14:14:32,@analyticsaurabh Likely not. Such interactive sessions don't come across well compared to other presentation types.,0,0
2016-06-17 12:33:04,"@samim @krides I estimate we have 2 years to fix this or we'll end up stuck in class hate wars, or middle class will soon-after vanish.",1,0
2016-06-17 12:31:24,@krides Where is your plane ticket to? Maybe we can elope...,1,0
2016-06-17 12:28:36,@krides It's everywhere in Europe. Rest of the world is scary in different ways...,1,0
2016-06-17 11:58:39,"@okayultra Yes, a large library would require much larger NN‚Äîwhich would be much slower and harder to control what you want.",0,0
2016-06-17 11:58:06,"All this to prepare a great #nuclai16 workshop; if you need a GPU *and* have to wait 5 minutes per image it'd never work, now ~30s on CPU!",3,1
2016-06-17 11:54:48,@okayultra Current patch-based approaches could basically steal patches from elsewhere... or get a neural network to learn those patches!,0,0
2016-06-17 11:54:07,"@okayultra Yes, constantly thinking about this! @DeepForger uses the image itself to try to add detail when missing, could be better.",0,0
2016-06-17 11:43:57,"Visualizing the correlation between activation values at key layers, looking great! Nice distribution and sparsity. https://t.co/NoCPKGL1ur",10,0
2016-06-17 11:10:49,@chuchaba Any paper in particular that comes to mind? Even just a year would be helpful! ;-),0,0
2016-06-17 10:41:40,"Fixed the bugs in the training of the network and let it run overnight. Finally happy with results, now to combine the layers together!",1,0
2016-06-17 10:41:06,"French village painted in the style of Picasso sketch at different layers, affecting scale &amp; quality. https://t.co/zXbLSXa7RF",20,6
2016-06-17 09:49:11,"The ResNet architecture shows benefit of depth even when receptive field is effectively a full image, but is it also true for early layers?",1,0
2016-06-17 09:47:35,Does depth help for convnets because the receptive field grows bigger too (in traditional architectures) or thanks to extra non-linearities?,0,1
2016-06-17 09:43:23,Are there any deep learning papers (for images) studying the impact of depth but decoupled from receptive field size?,2,0
2016-06-17 09:19:23,"@Donzanoid The animation itself is a visualization of the algorithm, if that's what you mean. I was comparing the before/after stills...",0,0
2016-06-17 09:15:37,"@Donzanoid Haha ;-) It's pixelated, but that aside I think it's quite promising!",0,0
2016-06-17 09:07:37,"In a few years (maybe 3-5), the film editing process will involve making adjustments to expressions so fewer takes are required!",10,2
2016-06-17 09:06:20,It's truly amazing how altering facial expressions (with a neural network) can affect the mood/tone of a scene: https://t.co/P0QXTw6VcQ,8,3
2016-06-17 08:58:54,"@mtrc @jurieongames There's one brown paper cup in all photos above, but everything else is UNFOUNDED SPECULATION! https://t.co/99EOYXHZFa",4,0
2016-06-17 08:11:18,"@andrew_clegg Just applying these ideas more evenly society-wide is going to cause huge changes, not human-level AI but big implications.",0,0
2016-06-17 08:10:33,"@andrew_clegg Yeah, it's a good counter-balance! I believe, however, it under-appreciates the implication of ""simple math, large scale"".",0,0
2016-06-16 17:28:22,"@netputing For each pixel of output, which patch of which layer matches best? If so promote that. Downside is higher-layers are low quality.",0,0
2016-06-16 17:21:11,@netputing Would be cool to compare on some images. With a patch-based approach you could do this context-sensitively &amp; locally...,0,0
2016-06-16 17:18:36,"@netputing Ah, I see. The original #NeuralPatches has code for disabling certain patches if the loss is too high. Same but with weights?",0,0
2016-06-16 17:14:32,@netputing Interesting! Didn't quite get what it does yet... Which problem is this solving?,0,0
2016-06-16 16:22:43,@notthatdsw Turns out I had a few ;-),0,0
2016-06-16 13:22:24,"To solve the rest of problem, it helps to have lower and similar values... But I left a loophole. (Right: correct!) https://t.co/4SHHXf6EAu",1,0
2016-06-16 13:17:57,"Outsmarted by gradient descent! Told it to target specific standard deviation, it used just one channel for that. https://t.co/9FQr33zzy7",6,1
2016-06-16 11:36:31,"@jurieongames @McOmghall Look at the examples and if any are close to what you want to do, then it'll be fine.",0,0
2016-06-16 11:19:43,"@McOmghall @jurieongames We use VisPy (contributed some code even), it's both great and still immature at the same time.",2,0
2016-06-16 10:34:28,"@mtrc Ah, I see ;-) Each email lets you unsubscribe (for only that type of notification) with just a click‚Äîno login required.",0,0
2016-06-16 10:25:29,@mtrc First thing I do is disable all emails for bots ;-),0,0
2016-06-16 08:05:42,"Likely they could use a variant of batch-normalization too? I opted for ELU activation functions, lower complexity: https://t.co/k1Vr64li8M",3,1
2016-06-16 08:01:14,Academic Trick #137: hide important but inconvenient facts in text because equations stand out too much! https://t.co/rn3aPjnUJq,6,1
2016-06-16 07:59:52,"I hope the paper is still in review (submitted to NIPS), so all this could be addressed. It's not a bad paper, just things that need fixing.",0,0
2016-06-16 07:58:48,"They're basically training an auto-encoder layerwise, which IMHO makes a lot of sense and interesting, but doesn't match with lofty intro!",3,1
2016-06-16 07:57:26,"Title claims they use ""Random Weights"" but later they clarify chosen to maximize certain criteria... (‚ïØ¬∞‚ñ°¬∞Ôºâ‚ïØÔ∏µ ‚îª‚îÅ‚îª https://t.co/TPVF7i4Mj7",2,2
2016-06-16 07:29:41,"@quantombone Not yet, not finished reading. I did this research a month ago: concluded random networks aren't good enough for ST.",2,0
2016-06-16 07:28:31,"Curious how they implemented their baseline, Gatys' approach (or open source) looks better than what they show: https://t.co/xJqHTH59Jt",5,1
2016-06-16 07:26:35,"They're overselling benefits image reconstruction; trained auto-encoder does better, but low quality style transfer. https://t.co/L7EMQ20O8g",6,3
2016-06-16 07:23:43,"This looks very familiar ;-) Texture are pretty good, comparable with my attempts month ago! https://t.co/k1Vr64li8M https://t.co/ahgiz2Nfqz",4,3
2016-06-16 07:22:34,A Powerful Generative Model Using Random Weights for the Deep Image  Representation https://t.co/r4Zi2GDNuT https://t.co/VVfXOCUyK3,42,15
2016-06-16 06:45:38,"@danofer The slower version is higher quality than the `forward` branch, but now you're on the cutting edge! Let me know how it goes ;-)",0,0
2016-06-16 06:10:03,@dribnet @smilevector Bots (and all practical applications) are amazing for this reason! It's easy to overfit looking at code &amp; papers.,1,0
2016-06-15 21:53:31,"@EnigmaDeus Yes, you just provide that painting as --style.",0,0
2016-06-15 21:23:21,"Since a few asked, I primarily use Firefox (to avoid alternative browsers) and Larry Filter. https://t.co/ckKSZMsnt4 https://t.co/gJDQSRaVQM",3,1
2016-06-15 21:15:01,I rarely discuss politics in person too: people either agree or disagree. Ungrounded conversation is unlikely to charge that. Bias action!,4,2
2016-06-15 21:11:59,@okayultra @sknthla Put spaces in the words ;-) A S S A U L T R I F L E G U N V I O L E N C E.,0,0
2016-06-15 21:10:27,"@marmalade_tim @sknthla I use Firefox for political reasons, and the plugin is called Larry Filter. Weird name, keen to know alternatives!",0,0
2016-06-15 21:08:46,"There are enough Tweets that sneak past so it's not an echo chamber, but it helps remove endless negative stream I quit TV &amp; newspapers for.",3,0
2016-06-15 21:06:06,. @sknthla Absolutely agree! Filters are necessary to say sane on Twitter. Keyword list grew quite a bit this week. https://t.co/U6EZ7Fwutq,12,1
2016-06-15 20:20:29,"@theshroffage The game looks awesome, congrats! Good luck too ;-)",1,0
2016-06-15 19:10:15,"@ferrouswheel One of the follow-up papers a few months ago, pre-NIPS / ICLR this year. Maybe even by the original authors?",0,0
2016-06-15 19:05:49,@ferrouswheel ResNet papers dig into it. The application I have in mind would benefit from sparsity of having pre-ReLU batch normalization.,0,0
2016-06-15 18:56:22,"@ferrouswheel If you have a specific application you can measure, why not ""quickly"" try both on a subset of the problem?",1,0
2016-06-15 14:59:26,"@ben_throop Webcast say they lost the vehicle but no data/footage yet. My guess it came in hot, caught fire, and exploded taking out camera.",0,0
2016-06-15 14:06:27,@Donzanoid AFAICT it's not a debate about facts.,4,0
2016-06-15 09:16:19,"@tenpn Trying to block it out... I forgot during registration to vote, turns out I can't anyway.",0,0
2016-06-15 09:05:39,I'm half English but can't referend...ate :-| Can I trust you to do the right thing?,3,2
2016-06-15 08:04:07,"The results aren't the most convincing, but the ideas are fascinating and it's a useful study! I wonder about combining it with better loss?",3,0
2016-06-15 08:03:02,Inverting Face Embeddings with Convolutional Neural Networks https://t.co/OP3HkCIm2j (e.g. blending face parameters) https://t.co/jLrjohgaCH,33,9
2016-06-15 07:29:15,"@apgamesdev Yes, after #nuclai16. Preparations got us completely and unexpectedly swamped. Just published cool workshops recordings though!",0,0
2016-06-15 05:33:02,"@shahidkamal Start with brushing up statistics, then dig into the deep learning stuff directly.",2,2
2016-06-15 05:24:00,"@paniq Knowing evolutionary algorithms, likely random then see how it works! I didn't read it fully...",1,0
2016-06-15 05:22:31,"@shahidkamal If you know some statistics, there's a Deep Learning book, or Hugo Larochelle's course on YouTube. Or just grab open source!",1,1
2016-06-15 05:21:24,"@soumithchintala The first paper set the bar so low by saying MNIST is ""big"" problem &amp; future work, at least this one taclkes convolution!",0,0
2016-06-15 05:09:57,Two other papers recently combined genetic algorithms; this one also does a great job of learning architecture combined w/ back propagation.,4,0
2016-06-15 05:08:22,EvoNet: Evolutionary Synthesis of Deep Neural Nets https://t.co/OLDqvS02sJ 19x parameter reduction for segmentation! https://t.co/L2smBvGFlN,46,15
2016-06-15 05:01:42,"@cdaylward Talking about ethics is fine, healthy, and... difficult. But welcome! For me, doomsday prophesies to promote a book are not.",2,0
2016-06-14 19:56:23,@Dom3D Interesting thought! Note the interview didn't go into much depth anywhere else either ;-),2,0
2016-06-14 18:25:02,"@fchollet Agree. Google is still unknown quantity, many projects will remain closed/secret‚Äîfor example those secretive TPUs ;-)",1,0
2016-06-14 18:23:56,"@fchollet In those cases it's ""fostered"" open source though. Also, I bet Ilya has much stronger influence on direction than Elon...",0,0
2016-06-14 18:21:59,"@fchollet I think it's happening increasingly? Community exploration once #DeepStyle came out, the OpenAI Gym, project Magenta...",1,0
2016-06-14 18:19:15,"@fchollet Also, I presume everyone there could get a pay raise by moving elsewhere now, so they must stay for other reasons...",0,0
2016-06-14 18:18:37,"@fchollet There are similarities, but also differences. He mentions a non-profit that's not legally obliged to cater to shareholders.",1,0
2016-06-14 17:45:10,"@ID_R_McGregor Very little was said in the conversation, a lot was hinted. I'm sure the company goals/mindset is an important factor.",0,0
2016-06-14 17:44:16,"@ID_R_McGregor They're ahead certainly given the talent they hired, but publish research and distribute tools. Risk is they sprint faster!",0,0
2016-06-14 17:39:30,"He doesn't say which it is (""There's only one."") but context hints that it's Google. Seems like it was a big motivation for starting OpenAI.",2,0
2016-06-14 17:38:15,"In this interview Elon Musk says he's worried abt development &amp; control of ""strong"" AI by one company in particular. https://t.co/qIYzvnuY9O",7,1
2016-06-14 17:32:21,"@sroecker Oh, I see! Very cool ;-)",0,0
2016-06-14 17:27:09,@sroecker Cool!! What do the originals look like? :-),0,0
2016-06-14 17:11:03,"@tenpn I try to avoid indentation. If it's a shortcut, I put it first in the function then just return. Or just lookup and try to avoid if?",0,0
2016-06-14 17:06:45,"@tenpn You used very different syntax and style in both regardless of indentation (brackets, explicit ==); was that intentional?",0,0
2016-06-14 16:26:43,"@rob_sherman @nuclai Hi, we're swamped with #nuclai16 preparations so things fell behind. Likely in the summer‚Äîhopefully!",0,0
2016-06-14 16:25:05,Source: this paper on Generative Adversarial Networks by the @OpenAI team. https://t.co/kNHxKpKtff Lots of little techniques to digest!,6,4
2016-06-14 16:21:24,"Can you distinguish thumbnails of real images from those generated? https://t.co/qRAYOPt9Z9 Got lucky, it's tough! https://t.co/GIuUIIL1tm",1,1
2016-06-14 10:19:26,"@okayultra Yeah, great idea. Can you think of an easy way to get a source of data? Need thousands of articles or more.",0,0
2016-06-14 10:08:38,Let's talk about AI again because the real problems in this world are just a little too inconvenient to solve‚Äîand less popular!,23,3
2016-06-14 10:06:09,"@okayultra Yeah, I agree with that. Makes more sense with second Tweet ;-)",1,0
2016-06-14 10:05:33,"@okayultra How about war, genocide? Inequality &amp; poverty? Pondering AI is equivalent to philosophical masturbation, ignoring real problems.",1,0
2016-06-14 10:02:05,"Oh, no! Who let the Philosophers out? They talked to the press again... /s https://t.co/ZN8aTkRwJD",35,11
2016-06-14 07:30:21,"@graphific @halhod @mjrobbins @jackclarkSF It's also a field of research AFAICT, data transformation compatible with ML but secure.",2,0
2016-06-14 07:28:40,"@graphific @halhod @mjrobbins @jackclarkSF For it to be secure, encoding has to be unique to each client. There's a startup that does this..",2,0
2016-06-13 23:38:46,@EnigmaDeus You can use the site directly.,0,0
2016-06-13 23:32:54,"@EnigmaDeus Ah, sorry. Much too busy for custom requests with @nuclai coming up!",0,0
2016-06-13 23:28:34,"@EnigmaDeus Sure, if you can fit them into 140ch each! ;-)",0,0
2016-06-13 19:37:47,"@halhod @mjrobbins @jackclarkSF Yes, lots of work being done on networks that operate with 1bit 2bit 8bit parameters to run on CPU.",5,0
2016-06-13 19:28:07,"@fchollet Yes, there's a full spectrum of options in between. At this stage, the intent is already a great contribution!",0,0
2016-06-13 19:24:32,"@halhod @mjrobbins @jackclarkSF It's likely just doing inference on the device, training is offline. But people could get the trained NN!",3,0
2016-06-13 19:19:55,"@fchollet Sure. Feel the same about Goog/Fcbk. If Apple follows through on that claim, it gives them the upper hand in that department.",0,0
2016-06-13 19:18:10,@fchollet I don't use Apple devices ;-) It's still a very important direction and precedent.,0,0
2016-06-13 19:15:04,"@kylotan Yeah, it's tricky... Will likely involve more human experts and employees to volunteer data.",0,0
2016-06-13 19:09:31,I'd take a 10x drop in performance/accuracy for such a privacy-friendly design‚Äîpossibly even more if it was externally verified/audited.,5,2
2016-06-13 19:07:30,"It's a *great* strategic move, consensus is Apple can't compete against research teams at Google or Facebook. Now can still come out on top!",7,2
2016-06-13 19:05:34,"If true, it's the most important AI-related announcement of this season of keynotes‚Äînot about technology but ethics: https://t.co/WWf1HtNWjY",27,9
2016-06-13 18:31:25,"@deliprao So you've increased the receptive field without discarding information via down-sampling, but you pay with performance.",0,0
2016-06-13 18:30:31,"@deliprao With dilated convolution assuming you don't downsample, you save parameters but you must do that computation 4x ... 8x more often.",2,0
2016-06-13 18:29:18,"@deliprao Doesn't matter. Imagine the simplest case, input RGB image + one 3x3 filter: inference performance is mostly factor of input size.",0,0
2016-06-13 18:05:48,"@deliprao @mtyka The parameters mostly affect the complexity of the optimization problem, but better performance can compensate for that.",0,0
2016-06-13 18:04:04,"@deliprao @mtyka Mostly depends how you use them, for example 3x3 convolution is few parameters but over 1080p image it's slow.",1,0
2016-06-13 17:59:25,"@deliprao @mtyka What concerns me most is runtime overhead not parameters, both memory &amp; computation increase without down-sampling.",0,0
2016-06-13 09:39:32,@danofer Forward branch is 10x faster or more even on CPU. Try it.,0,0
2016-06-13 09:35:35,"@danofer Nobody has CL support that really works AFAIK. It's fast enough to run on CPU, different implementation‚Äîless brute force.",0,0
2016-06-13 08:07:20,"@johnhenderson You could explain the drop in ""insured unemployment"" by insurance companies getting better at avoiding payouts!",0,0
2016-06-13 08:05:58,"@johnhenderson Not sure how graph is related, nor does the article: ""according to an obscure measure known as the insured unemployment rate""",0,0
2016-06-13 06:57:26,"Is it effective/ethical to threaten people with equivalent of an economic gun held to their livelihoods: ""Work, or else!"" [2/2] @paul1kirby",11,6
2016-06-13 06:54:20,Question is not whether we should encourage productive contributions from individuals to society; we should. [1/2] https://t.co/i5BVfooBFJ,4,2
2016-06-13 06:39:53,@graphific Does it call `make install -j 8` under the hood or just plain old make install?,0,0
2016-06-12 12:44:08,@jurieongames Looking forward to seeing you again in Vienna! ;-),0,0
2016-06-11 14:59:21,"@halhod @samim A fact that Gawker relied on to bully individuals who can't afford justice. But it's not about ""press"" but legal system.",0,0
2016-06-11 14:57:55,"@LoneWolfIT @DeepForger Yes, via the site. Twitter interface is suspended until further notice.",0,0
2016-06-11 07:05:13,"@Aelkus IMHO the answer can only come from the bottom up, the governments cannot be reinvented or evolved for what they wore not designed.",0,0
2016-06-11 07:03:50,"@Aelkus Europe does not have the answer to this question, trend is to cutting services and austerity‚Äîarguably the consequence of capitalism.",1,0
2016-06-11 07:02:08,@Aelkus Suspicious. Who pays for the services?,0,0
2016-06-11 07:00:32,"@Aelkus ""Oh, you want to tax us?"" ""We're out of here."" ""We'll take our best products elsewhere."" (It's also the gist of TTP/TTIP.)",0,0
2016-06-11 06:58:59,"@Aelkus @Miles_Brundage IMHO that will only make the current situation worse, everything needs to be resolved separately from that.",0,0
2016-06-11 06:58:23,"@Aelkus The difference back then, Capitalists were not yet global and required local support from US people. Now they've moved on and don't!",0,0
2016-06-11 06:55:09,@Aelkus I'm seriously starting to wonder if it's too late to save the U.S.‚Äîneither option is likely to fix things...,0,0
2016-06-11 06:51:50,"@Aelkus Not just heard but dealt with... However crazy, Bernie was the only one with ideas to address all of that!",1,0
2016-06-11 06:50:58,"@Aelkus I think the situation is increasingly zero sum, all extra productivity gains not redistributed evenly. https://t.co/IZAXI8fOQX",0,0
2016-06-11 06:49:56,"@Aelkus Oh, that sounds like a different article to me, doesn't detract from his main point and not purposefully misleading.",0,0
2016-06-11 06:46:20,"@Aelkus What in particular is not accurate? I see that bubble thing increasingly strong, even in Europe that's more social+integrated.",0,0
2016-06-11 06:40:40,"@Aelkus Did you read this? I head same ""shake it up"" arguments for voting extreme right when I was last in France. https://t.co/hWsXOM63wW",1,1
2016-06-11 06:38:01,"@fchollet Unfortunately, they're right about that‚Äîwhich makes the absolute gains highly questionable at the very least.",2,0
2016-06-11 06:36:31,@fchollet Humans are bad at judging in absolute terms. The feeling is that they're being screwed more than before. https://t.co/IZAXI8fOQX,2,0
2016-06-10 22:12:02,@dribnet At the same time it's exploring perception/morality/psychology and boundaries of the #NeuralPuppet concept.,0,0
2016-06-10 22:09:58,"@dribnet I like that it's raising questions (exploring new space) &amp; wouldn't like censoring it, but not sure it's projecting intended image.",2,0
2016-06-10 22:07:52,@dribnet Maybe you should remove the sources. Making this person smile is very spooky knowing context... https://t.co/RXQ2NIBATf,0,0
2016-06-10 21:50:22,"@LorenSchmidt Journalists aren't 100% sync'd up yet, but there's nuance in more specialized circles for now. High hopes for @nuclai in July!",1,0
2016-06-10 21:45:58,"@r3melly There are active research fields focused on applications, if you search papers you'll find reviews of techniques in those areas.",0,0
2016-06-10 21:37:55,2019: Writers Guild accidentally nominates a bot for an Award thinking it was a famous writer using a pseudonym.,9,5
2016-06-10 21:33:17,"Generative AI for articles or scripts:
2016: Haha, look how stupid/funny!
2017: There are some glitches...
2018: Wait! That was automated?",20,21
2016-06-10 21:30:17,"So many new (and failed) experiments are happening with AI these days, I think it's healthy to balance hype and opens up ideas/discussions.",3,1
2016-06-10 21:29:08,"Overall it does a reasonable job of covering the limitations of neural networks, and the topic of AI as a tool: https://t.co/KhOd6A1crj",2,0
2016-06-10 21:22:47,"This makes for a humorous article, but if you wanted a computer to write a coherent article you wouldn't use a RNN. https://t.co/JZg0OG77uE",7,2
2016-06-10 18:05:37,"@samim Ah, don't know about that yet... Your initial tweet seemed to be about the death of free speech‚Äîwhich I'm not sure I agree with.",0,0
2016-06-10 18:03:15,@samim Looks like the precedent was already set in 2012 when a billionaire sued MotherJones‚Äîbut they won. https://t.co/lLoDDfHk19,0,0
2016-06-10 17:36:20,@halhod @samim I'm more concerned by the fact that a victim requires billionaire backing to seek justice within the legal system.,3,0
2016-06-10 17:34:30,@soumithchintala Big question is whether ensemble of N ResNets with M neurons is equivalent to a single ResNet of N*M neurons wide. [2/2],0,0
2016-06-10 17:33:47,@soumithchintala The exponential ensemble theory seems to assume DropPath training; see /r/MachineLearning discussion on the topic. [1/2],1,0
2016-06-10 17:24:31,"@halhod @samim I know, I'm torn about possible implications where the defendant was not guilty. But it's not happened yet.",0,0
2016-06-10 17:20:40,@samim The company was found guilty by a jury and two judges. It's because they broke the law (again) they now owe 140MM in compensation.,4,0
2016-06-10 17:11:52,"@dougbinks Looking great! BTW, do you find PR benefits to posting Saturday screenshots with the hashtag early?",1,0
2016-06-10 12:50:56,"@nrose @samim My first thought seeing the title: Oh, cool! Seeing results: the magic has gone. Feels like just another Photoshop filter now.",2,0
2016-06-10 12:21:30,You should follow @dribnet by the way for generative ML and behind the scenes making-of tweets. Blog post incoming? https://t.co/Niz7bvBoBd,2,0
2016-06-10 12:19:22,It's a type of generative auto-encoder trained on celebrities. Fascinating to see it average out certain features: https://t.co/vPqThWeXe3,4,0
2016-06-10 12:16:27,The new @smilevector bot by @dribnet turns a photo into a #NeuralPuppet‚Äîadjusting facial expressions! https://t.co/OHKuY3XWAy,9,8
2016-06-10 06:42:29,@vikhik Make a nice explanatory Tweet with an action item and I'll share it.,1,0
2016-06-10 06:28:06,"@samim Hmm, the original blog post doesn't mention the way it's done (or any details) so I linked to GitHub instead.",1,0
2016-06-10 06:12:39,"@samim NOTE: The script doesn't do the style transfer, it just separates the color and recombines it in YUV space.",0,0
2016-06-10 06:10:15,"@nothings Yes, max() should work exactly the same for the last one too. Probably a question of legibility?",0,0
2016-06-09 23:19:07,"- Batchnorm brings ReLU up to ELU performance.
- Maxout is surprisingly strong (still)!
- max+avg pooling does better than strides.",10,3
2016-06-09 23:17:36,"Systematic comparison of architectural decisions for convolution networks, some surprises: https://t.co/ZhpLt9ERd5 https://t.co/uV3w0GyZnr",247,117
2016-06-09 22:57:39,@lsjroberts It's the team of 10 humans shown at the end that makes this work as amazing piece of art! Would love to see the full script ;-),0,1
2016-06-09 22:45:10,"Style transfer preserving original colors: run normally, split YUV components &amp; recombine. https://t.co/bXAIJswPid https://t.co/TbaetXyd10",25,7
2016-06-09 22:34:33,"@karoly_zsolnai Thanks! I'm using custom heuristic not just comparing pixel patches, so not 100% sure of applicability. Will dig deeper :-)",0,0
2016-06-09 20:35:02,"Unless I can get two specific operations to work much faster, I'm basically paying the price for using the same Deep Learning framework.",2,1
2016-06-09 20:33:07,@ankurhandos My code is online somewhere already but I'm really not happy with it yet!,0,0
2016-06-09 20:32:29,@DaveChurchill You mean calling pip2 rather than pip3 to install things? Virtual Environments help with that...,0,0
2016-06-09 20:31:49,"There are fast CPU implementations and GPU versions in OpenCL that do well with special tricks, but haven't yet found good tensor version...",5,0
2016-06-09 20:30:16,I wrote a tensor-based version of PatchMatch; disappointed to see it performs worse than brute force currently. https://t.co/xkQldbETgN,9,1
2016-06-09 20:26:07,"@DaveChurchill It's not fundamental, but consequence of some poor decisions from leadership over the years.",0,0
2016-06-09 18:21:42,"@API_Beast It's the kind of stuff you'd expect ML to come up with, but was in fact created as Art.",1,0
2016-06-09 18:05:03,An appropriate illustration of how Deep Learning can learn word embeddings from data? https://t.co/rWwXTynIDZ https://t.co/TE8iNdH8Rm,31,9
2016-06-09 17:41:08,@mtrc Brace yourself for reviews when @rogue_process comes out and doesn't include a disassembler!,2,0
2016-06-09 17:04:57,"Looking forward to the VizDOOM workshop at #nuclai16, hopefully I'll have time to drop by‚Äîit's always busy day #1 ;) https://t.co/LrexGXX5ut",2,1
2016-06-09 17:03:42,Deep Successor Reinforcement Learning https://t.co/ZTLZjFfZX2 (separates prediction of next state &amp; its value) #ml https://t.co/13Rsr4psIt,19,9
2016-06-09 11:51:57,I've been using DNN frameworks with Python 3.x (exclusively) for at least 18 months; only reason to hold back is legacy proprietary code!,1,2
2016-06-09 11:47:40,"Fun fact: #NeuralDoodle was Python 3.x only on purpose. It's somewhere in top #CreativeAI projects on GitHub, only one person mentioned it.",0,2
2016-06-09 09:57:11,@skittlesolives I'm `nuclai` since someone stole `alexjc`.,1,0
2016-06-09 08:57:49,"@SmejkalPavel Hard to say, but 40% of the people voted for it. Legacy code (in-house) that uses the language? Web platform support?",0,0
2016-06-09 07:40:39,"@martinpi I'll only deserve a fraction of the credit, but thanks for the kind words ;-)",1,0
2016-06-09 07:37:50,"@vectorpoem @hoskingc There's basically no way you can 100% sanitize image outputs or filter inputs, so needs watching. But it's not enough?",0,0
2016-06-09 07:36:49,@vectorpoem @hoskingc I took Twitter integration offline as it was being misused and suspended temporarily. Not sure if there's easy fix :-|,0,0
2016-06-09 07:33:30,@ChristerEricson ;-) How often to these kinds of things happen? Not used it yet...,0,0
2016-06-09 07:29:37,"I should add this is a poll for an application that you have full control over, not an open source library where you'd likely need both.",1,0
2016-06-09 07:28:46,Didn't expect that poll to be so controversial; results pretty much tied so far and my mentions are rather heated ;-),0,1
2016-06-09 07:23:08,"@soumithchintala @fchollet Oh, I didn't mean library but rather an application where you have full control and users sit next to you.",0,0
2016-06-09 07:21:34,@jorgearellano Is it a rational reason?,0,0
2016-06-08 21:19:44,If you started a *new* project in Python‚Äîspecifically ML and/or DNN‚Äîwhat version would you use? (cc. @fchollet),4,3
2016-06-08 20:57:14,@rasbt @randal_olson @fchollet TensorFlow not supporting 3 at launch is reflective of mindsets; new library is ideal opportunity to switch.,0,0
2016-06-08 20:52:52,"@fchollet By the way, would you consider making future Keras blog posts Python 3 compatible as a good example? (e.g. print with brackets)",1,0
2016-06-08 20:51:01,@randal_olson @fchollet @rasbt Agree. I've been exclusively on Python 3 for ML for over 18 months. Only reason for 2.7 is legacy codebase.,2,0
2016-06-08 14:11:19,"@HilariousCow I get the impression you're focusing on the performance aspect more than the sculpture! If so, big success ;-)",1,0
2016-06-08 09:55:29,@jongold Thanks for posting that! I want a bot/site that posts new ones every few hours. I'm sure there are many more...,1,1
2016-06-08 07:36:11,"I suspect this is mostly hard-coded in the traditional #GameAI sense, and human opponents in video sucked, but great video and solid PR!",2,0
2016-06-08 07:35:08,Students build foosball-playing robot that uses cameras and actuators: https://t.co/EhiHRnQlyd https://t.co/jtImRI7gbM,18,7
2016-06-07 19:40:47,"@spysamot @Miles_Brundage Feels like an orthogonal decision though, so Novelty+Thompson together?",1,0
2016-06-07 19:21:41,"@spysamot Hehe, @Miles_Brundage. I thought about including you in that tweet but didn't want to spam.",1,0
2016-06-07 19:13:34,@spysamot I'd say this is the second batchnorm-level RL breakthrough this year already: https://t.co/VZQBBj1sdn Moving fast!,1,0
2016-06-07 17:03:45,"@totallytroy @ErwanBancal Good point, also closely related to this I read earlier: https://t.co/l6uBOGLVwk",0,0
2016-06-07 16:59:35,"@totallytroy @ErwanBancal Yes, separate. Though it affects the minimum rate that BI would need to cover and how much landlords can charge.",0,0
2016-06-07 16:56:38,"@totallytroy @ErwanBancal Agree with that completely. Flats are different though, in Vienna/Berlin for example they don't have enough.",0,0
2016-06-07 16:52:22,"@totallytroy @ErwanBancal For most things, I think the market would regulate quickly. For certain things like flats would take a bit longer?",0,0
2016-06-07 16:51:41,"@Aelkus It didn't stop people from having swimming pools in their gardens, just requires people to acknowledge they need professional help.",1,0
2016-06-07 16:47:48,"@totallytroy @ErwanBancal It's a question of inflation though, if more people have money then base prices (even food) may go up?",0,0
2016-06-07 16:42:48,"When boxes of materials start to arrive pre-conference, that's when things start getting real. Only 40 days left?! https://t.co/6SjUhUJL7K",4,0
2016-06-07 16:15:51,"I endorse using these lanyards as keychains, they're very cool! Mine from 2015 just wore out though, need a new one. https://t.co/HweSPIhHKN",0,0
2016-06-07 13:05:51,@ID_R_McGregor I happen to have kids that watch @SpaceX YouTube channel for entertainment! See this concept anim: https://t.co/Au1n4HSGHO,2,0
2016-06-07 08:14:00,"@sbelak Hehe. Apparently I don't understand the constraints well enough‚Äîwhich are mutually exclusive, which can be broken ;-)",0,0
2016-06-07 08:12:04,"@recurseparadox @deliprao I was under that impression but it was a misunderstanding of a Tweet, sorry! https://t.co/BNto7tcaBi",0,0
2016-06-07 08:04:36,@deliprao Agreed! I think the Nervana acquisition made (almost) certain of this.,1,0
2016-06-07 07:56:44,"It's the day after the party, too! If we secure the most mind-blowing caffeinated beverage at T-30, then it might work out?",4,1
2016-06-07 07:53:45,"Finally happy w/ @nuclai's Tuesday schedule, but I broke only soft constraint: speaker preferred to avoid morning talk, now at 9:15. Hmm :-|",2,0
2016-06-06 20:53:26,@mtrc @aireye This is what makes the most frustrating discussions about AI destroying world; corporations doing that already on our behalf!,2,0
2016-06-06 20:42:56,"@aireye @mtrc My biggest concern is that protectionist, fearful or selfish mindsets take over, which would be hard to recover from...",1,0
2016-06-06 20:38:26,@aireye @mtrc @bjorn @mark_riedl That part seems to be progressing slowly. Did you see the #BasicIncome referendum in Switzerland on Sunday?,1,0
2016-06-06 20:30:14,@mtrc @aireye @bjorn @mark_riedl There are potentially many jobs created but will the skills transfer? Can those truckers be re-trained?,0,0
2016-06-06 20:21:10,@sedielem @seaandsailor @samim I'd like to see a comparison of copy/paste synthesis to see if NN blends better; that's main benefit? [2/2],1,0
2016-06-06 20:19:47,"@sedielem @seaandsailor @samim In #CreativeAI, I don't think there's anything wrong with overfitting: it's just another tool. [1/2]",3,0
2016-06-06 17:33:55,@gcpascutto It just becomes more spread out over time... I have experiments running overnight most days ;-),0,0
2016-06-06 17:33:27,"@gcpascutto It's not cheap, but the training is more reasonable if you know the parameters and architecture. 4Gb GTX is fine.",1,0
2016-06-06 17:24:05,@gcpascutto For AlphaGo? Reinforcement learning it's probably way more expensive than a regular neural network...,0,0
2016-06-06 17:18:08,@gcpascutto Academic research helps a lot here! If you write up a blog post (or paper) do let me know ;-),0,0
2016-06-06 17:12:24,"@gcpascutto Oh, that's extremely impressive. In your code/techniques published somewhere too?",0,0
2016-06-06 16:37:46,"@gcpascutto Cool ;-) 3-4d seems around the level of Facebook's bot? If so, impressive!",0,0
2016-06-06 16:14:57,@grahamboree @BobbyAnguelov @tenpn Depends on codebase? My last C++ project was compute-bound.,0,0
2016-06-06 16:12:30,". @nothings ;-) BetaGo is playing black, made pretty stupid moves mis-predicting a ladder, but I messed it up later so maybe it was right!",0,1
2016-06-06 15:59:51,@bchjam Agree. Problems we see now are people looking at this in the old frame and it obviously doesn't make sense.,1,0
2016-06-06 15:58:40,"Meanwhile, BetaGo is playable from its GitHub repository. How good? Beats me! https://t.co/4jjPjBROq0 #baduk #ai https://t.co/hHeGKW3VKD",5,2
2016-06-06 15:51:27,"@karoly_zsolnai Quake or Doom first, not convinced closed-source Starcraft will be very effective use of research time.",0,0
2016-06-06 15:42:49,. @CodeAnatomy Facebook's DarkForest played in online ladders during April and one match in May‚Äîno sign since. https://t.co/lOY5TGCxD8,3,0
2016-06-06 15:31:43,"@nathansttt I'd be happily surprised if they released the data, even more if they released the code!",1,0
2016-06-06 15:26:00,"@nathansttt When I say ""no benefit"" I mean no benefit to Google/DeepMind, who ultimately has the decision.",0,0
2016-06-06 15:25:02,@nathansttt @demishassabis That will continue as part of the academic community as it did before. There's an open source re-implementation.,0,0
2016-06-06 15:11:35,Looking forward to Tristan Cazenave's history of Computer Go at @nuclai. With all the PR it's easy to lose perspective of the achievement!,2,0
2016-06-06 15:08:11,"@carlesgelada They will likely move on to other games, benchmarks, problems and find better PR opportunities there. Go is done.",0,0
2016-06-06 15:07:32,It's the same reason IBM dismantled Deep Blue before a rematch was possible. Suspect both codes will remain dormant in version control!,3,0
2016-06-06 15:01:25,"@rodolfor It depends if the other alternatives to AlphaGo (Zen, Facebook's DarkForest) have made fast progress...",1,0
2016-06-06 14:59:51,That explains it... There's no obvious benefit to AlphaGo (ever) coming out of retirement to play another game. https://t.co/TjxhMIEHVa,3,0
2016-06-06 12:42:34,"@ErwanBancal Rents are increasing anyway because of other factors (AirBnB), would need similar controls in place. Here there are limits.",1,0
2016-06-06 10:22:55,"@j2bryson For Facebook I'd expect them to decide in their interest, for Twitter prefer to see customizable service. Could charge for it?",0,0
2016-06-06 10:20:23,". @j2bryson Mockup integrating AI abuse detector in Twitter, conveniently placed into a new tab for quick access ;-) https://t.co/YB1XXGOiyW",13,9
2016-06-06 10:19:09,"@j2bryson No, I don't use Facebook except for PR broadcasts for this reason.",1,0
2016-06-06 10:13:42,"@j2bryson Identifying is the hard part, integrating into the site feels easy in comparison! Responses could show up in 3rd Notification tab.",0,1
2016-06-06 09:58:22,"@ZipZapZeps That's how basic income would be funded, incl. multinational corporate taxes. Besides prices keep increasing today anyway.",0,0
2016-06-06 09:44:00,"@SommerPascal The current system is not sensible either, not designed to be egalitarian, so in that light no solution would look sensible!",0,0
2016-06-06 09:37:45,@phelixlau Not sure... In practice these licenses haven't stopped any startups from using them as if they were free-to-use!,1,1
2016-06-06 09:30:47,"@phelixlau Good question, if a trained model is a derived work... yes?",0,0
2016-06-06 09:20:50,@phelixlau Model licenses seem pretty much impossible to enforce anyway...,0,0
2016-06-06 08:29:16,"@rmanolescu5 I suspect the majority of my followers are not opposed, I was more interested in learning about the other side...",0,0
2016-06-06 07:40:25,"@logicalerror Also, in Switzerland only 3.5% are unemployed so maybe the pain isn't strong enough there...",1,0
2016-06-06 07:40:01,"@logicalerror Yeah, that was my conclusion as well. It may take a generation shift in voters (15-20 years)‚Äîat least for Switzerland.",0,0
2016-06-06 07:39:18,"@sopyer By the time basic income actually happens, all those things will already be even more commonplace so IMHO can't be much worse.",0,0
2016-06-06 07:37:15,"@logicalerror Yeah, there are lots already and increasingly more now. Apparently it was a bad proposal, which didn't help the cause.",0,0
2016-06-06 07:31:34,"@sopyer There's nothing really wrong with that, millionaires do it too! Besides, trials show 3/4 would prefer to work at their choice.",0,0
2016-06-06 07:24:53,"@sopyer The rent-seeking is happening already, BI would just distribute that around more evenly.",0,0
2016-06-06 07:06:49,"@martin_cerny_ai I think we've reached a minima/maxima though, it'll take a lot of energy to get out of this.",0,0
2016-06-06 07:05:12,"@martin_cerny_ai Agreed, but I see it as no riskier than not doing anything! There'll be (more) riots in the street if not...",0,0
2016-06-06 07:01:47,@nikete Then I'd speculate basic income would be accepted much quicker if proposed in Brazil. What do you think?,0,0
2016-06-06 07:00:07,"@nikete Maybe not a whole generation, but enough for younger people to dominate the workforce. Youth unemployment is near 50% in places!",0,0
2016-06-06 06:47:58,"@sd_marlow It's not going to be enough for most people, with Capitalism the natural tendency would be for them to have nothing (or less).",0,0
2016-06-06 06:38:58,"@sd_marlow I guess you could see it as an additional (strong) force within free market, but it's not going to disappear!",0,0
2016-06-06 06:25:36,. @boffbowsh The Swiss unemployment rate is only about 3.5% apparently‚Äînow if they had the same vote in Spain (21%).,2,0
2016-06-06 06:24:02,"@sd_marlow The free market would regulate things, if strawberries and potatoes end up worth more than Gold people will adjust cleverly.",0,0
2016-06-06 06:22:43,"@sd_marlow I asked people who disagreed, and according to Swiss survey that's 73% ;-)",0,0
2016-06-06 06:21:16,@boffbowsh I hope so... That fearful &amp; competitive mindset that's blocking us now may become further entrenched though.,1,0
2016-06-06 06:19:28,@spysamot It's fear. Makes everything look like zero-sum competition. Sadly this mindset makes things worse...,1,0
2016-06-06 06:18:38,"There were interesting answers that weren't based on fear, but no longer confident basic income will make it through a vote this generation.",2,1
2016-06-06 06:09:41,@sopyer Studies show over 3/4 would enjoy &amp; continue working productively. BI gives them choice to not take abusive jobs with slave wages.,0,0
2016-06-06 06:08:20,"@ZipZapZeps I assume prices would readjust but not by a constant amount, e.g. waiters would end up with relatively more than Lawyers.",0,0
2016-06-06 06:04:53,"The answers for Other are quite depressing, in summary:
- We need slaves.
- Fuck the poor.
- It won't save us.
Capitalism scores well here!",3,0
2016-06-05 19:06:34,"Looks like the specifics of the proposal were not good. Don't understand what went on, but in the end, great way to sabotage the cause!",0,0
2016-06-05 18:57:52,@SommerPascal I agree with what you said but I don't like that as a reason not to do it...,0,0
2016-06-05 18:57:21,@SommerPascal Slippery slope. You could have used the same argument before the end of slavery!,0,0
2016-06-05 18:50:38,"Curious to understand the mindsets against it. If you *oppose* #BasicIncome, what's your reason?",0,0
2016-06-05 18:45:21,"Regardless of all the positive spin, quite sad &amp; surprised only 23% voted for #BasicIncome in Switzerland today. https://t.co/CUQtuBJ3fd",15,7
2016-06-04 21:02:48,@lmenus There's one lab pending but finding time before #nuclai16 proved to be too hard. Downside of more people means more work...,0,0
2016-06-04 20:53:52,@lmenus ;-) I'll take credit for writing the code that dug up that view and noticing it! Where's that screenshot from?,0,0
2016-06-04 20:43:53,"@deliprao I've labelled thousands images, but hard to explain ;-) The curve of road+hill, also mountain+treeline, asymmetric but balanced.",1,0
2016-06-04 20:37:15,"Love the composition on this one, randomly popped up in Google Street View API crawl. https://t.co/Ga80CJAIRY",11,1
2016-06-04 18:40:30,"@ngutten Yeah, auto-encoders will give you blurred features by default if you rely on MSE as loss function.",0,0
2016-06-04 18:33:06,"@ngutten With patches, early layers are very expensive so I only try 3_1 in testing.",0,0
2016-06-04 18:29:49,"@ngutten To be fair that particular comparison has a bit more going on for right side, but left is a more traditional auto-encoder.",0,0
2016-06-04 18:28:55,@ngutten Yes! This absolutely helps: https://t.co/TSqlqxHZb2,0,0
2016-06-04 18:28:39,@ngutten I'd trying to convince myself that's not the case ‚Äî but nothing so far ;-),0,0
2016-06-04 18:27:15,"@ngutten My training was an auto-encoder problem + some extra loss functions, so you'd expect the reconstruction to do well...",0,0
2016-06-04 18:21:06,"@ngutten With patches, I've found reconstruction to be the easy part. Hard part is having features that blend/mix well...",0,0
2016-06-04 18:13:43,@ngutten Doing reconstruction on an image unseen during training? My focus has been mostly on patches + feed forward these days.,0,0
2016-06-04 18:06:43,@ngutten There's been nothing published but I'm working on it. Are you working on this too?,0,0
2016-06-04 17:50:29,"Here's my reply on Reddit: https://t.co/qyN7g154ob This topic is open research AFAIAC, also very important. https://t.co/6mZVlJgX4V",2,0
2016-06-04 17:49:15,"The quality isn't as good as the usual VGG, but that one takes 80Mb if you use all convolution layers. Useful experiment nonetheless!",1,0
2016-06-04 17:47:14,Lightweight SqueezeNet (&lt;500k compressed) for #DeepStyle using mxnet: https://t.co/gvSS6p2yqp #CreativeAI https://t.co/EDolj1OLWa,13,4
2016-06-04 06:24:29,"@cupe_cupe @nuclai Sure, if you're there at the right place and time. Most people aren't so we'll have calendar entries+email notification.",0,0
2016-06-03 20:27:43,"I should mention we're planning to live stream the Amphitheatre for 3 days again, follow @nuclai for details soon... https://t.co/cFCOtabkrZ",1,0
2016-06-03 20:19:50,"It's been a long day, posted this under the wrong account ;-) Curious to learn more either way! @nuclai https://t.co/Fi5jfU6KK1",1,0
2016-06-03 19:38:28,How do Game AI techniques help manage complexity of game logic? Join @Crytek's @viladoman on July 19th to find out! https://t.co/Th71l7TXR9,13,7
2016-06-03 18:39:29,I wonder if anyone crawled recent news stories about AI to check how many of them mention Google... Guessing around 40%? Feels like that!,2,0
2016-06-03 17:44:59,"@richardmatthias For cmpletly blue-sky, now that's outside of DL. Within the field, it's so fast everything is closer than anyone thinks ;-)",0,0
2016-06-03 17:31:57,"@richardmatthias Because of the risk of being scooped, it would encourage bolder research and/or faster research. Less risk of local minima?",0,0
2016-06-03 17:31:19,"@richardmatthias But so many people working in the field on similar problems, makes the big ideas more attractive and competitive...",0,0
2016-06-03 17:29:42,"@richardmatthias This doesn't feel like a small development, maybe one of the most important contributions in generative ML this year?",0,0
2016-06-03 17:26:11,Published 3 days apart from two big teams. Relevant to our discussions earlier about fast pace of research and risk of being scooped!,2,0
2016-06-03 17:24:14,"An idea whose time has come:
‚ÜíAdversarially Learned Inference https://t.co/l2MddMtq4h
‚ÜíAdversarial Feature Learning https://t.co/EJcORzB6Pe",37,8
2016-06-03 17:03:42,"Looks like @samim posted this hours ago, yet again ;-) https://t.co/jf6rLuCWC6",2,1
2016-06-03 16:57:27,Storytelling of Photo Stream with &lt;[Insert Clever-Sounding Neural Network Wizardry]&gt; https://t.co/VeHvUp89qs #dlearn https://t.co/HJwACh4h05,15,7
2016-06-03 16:17:00,@nikete @fhuszar I'm coming to the same conclusion they missed it. Other  assumptions don't lead to very constructive places... Thanks!,0,0
2016-06-03 15:37:22,"@mtrc The best articles would strike a conversation that doesn't get filtered, so you'd see them anyway ;-)",0,0
2016-06-03 15:34:12,@mtrc :-) There are some pretty good Twitter filter plugins that keep you sane/safe.,0,0
2016-06-03 13:45:31,"@ngutten Oh, it was published a month before. That part is not under question...",0,0
2016-06-03 13:34:54,"@TrAIthlon Thanks, I had wondered if DCMA bot just looked at video length ;-)",0,0
2016-06-03 13:07:08,"@ngutten Papers have a certain value that academics expect, could also help your career more...",0,0
2016-06-03 12:48:49,"@ChristerEricson However, they mention a bias in the domain operators: mutation alone wouldn't generate trees that are as complex. [2/2]",0,0
2016-06-03 12:47:40,"@ChristerEricson This paper explicitly investigated the benefits of crossover, and it was an order of magnitude better than without. [1/2]",0,0
2016-06-03 12:31:30,"@thouis @fhuszar It felt like the most appropriate format at the time, but seeing another paper now why not! After @nuclai maybe ;-)",0,0
2016-06-03 11:41:19,"There's significantly more insight, but you have to scan through GitHub issues on 5 projects, follow dozen blogs, and hit right sub-reddit.",1,0
2016-06-03 11:39:49,"For example, many insights in this exploration paper were discovered by the community months after original release. https://t.co/eXwlzIIDjn",1,0
2016-06-03 11:35:49,"IMHO, there's a significant role for academia to play in studying open-source and practitioners post-factum‚Äîespecially with fast progress.",1,0
2016-06-03 11:34:02,"These days, if you wait too long, guaranteed you will get scooped! More thoughtful understanding emerges from community digesting the idea.",1,0
2016-06-03 11:32:49,"The discussion with @fhuszar is fragmented by Twitter, but if you can follow it's worth read. What's the value of research speed over depth?",0,0
2016-06-03 11:31:39,"The fast pace of progress in ML, a growing community, increasingly corporate R&amp;D is changing the nature of research. https://t.co/EZ75DKcotC",3,2
2016-06-03 11:13:07,"@fhuszar I'd argue this is the expected standard if I'd uploaded as 2 page PDF on arXiv, but I didn't and consequence is interesting.",0,0
2016-06-03 11:09:57,"@fhuszar I agree too, the study is well done. It's not about appropriation but citing related work, possibly adding 1 column in comparison.",0,0
2016-06-03 11:08:27,@fhuszar I'm more interested in knowing how to bridge the gaps: it's either communication problem or issue of credibility of open research.,0,0
2016-06-03 11:04:25,@fhuszar The practice of acknowledging Personal Communication in a citation goes back decades and decades. I don't see this any different!,2,0
2016-06-03 11:03:39,@fhuszar I don't want to speculate without knowing their intent or decisions. You're assuming they knew about it?,0,0
2016-06-03 11:01:31,"@fhuszar As you mentioned, there's value in deep study of topics‚Äîregardless of whether it was done before. This should play bigger role!",0,0
2016-06-03 10:51:46,"@fhuszar Overall it's hard to speculate. Depends if they were aware and didn't cite by choice, or not aware because it's a different medium.",1,0
2016-06-03 10:50:05,"@loftexperience @MannyKayy ML academia has picked up pace, but in other places they can't keep up. There's a role for post-factum study!",0,0
2016-06-03 10:49:03,"@fhuszar Granted. It's peer reviewed in different ways, people tried the code and new insights came out of that‚Äîplus reproducible &amp; open.",3,0
2016-06-03 10:46:52,"@fhuszar There's value in both of course, just having acknowledgements all around would be both beneficial and universally appreciated!",1,0
2016-06-03 10:39:37,@loftexperience @MannyKayy How do you get a DOI? I saw them but never really stop to think what they are ;-),0,0
2016-06-03 10:35:02,"@loftexperience @MannyKayy If I was to save my post as a PDF, do you think it would get cited? I'm not sure. https://t.co/ppC8WmWgKn",0,0
2016-06-03 10:34:24,@loftexperience @MannyKayy arXiv does a good job of this. Problem is that writing papers has a high bar that not everyone may want to hit.,0,0
2016-06-03 10:10:02,"To be fair, their paper is a better study of the phenomenon with more comparisons, but still not sure their results are as good. @MannyKayy",1,0
2016-06-03 10:09:01,"It's likely a communication problem, and just don't monitor relevant open source or social media. https://t.co/s7IzjweBSP",4,2
2016-06-03 09:51:34,Notice #NeuralDoodle removes label from image as it's a more sensible patch-based algorithm ;-) Mr. label's website: https://t.co/QcIYl7VB8V,2,1
2016-06-03 09:48:01,Using similar command lines than this Gist: https://t.co/dNTwPPjZQ4 Only using --phases=3 and --seed-range=144:256 for the leaves.,5,2
2016-06-03 09:46:53,"For comparison, here are the textures generated by the `random` branch of #NeuralDoodle‚Äîopen source FTW :-) https://t.co/ZCJg3hNPso",7,0
2016-06-03 09:44:20,@AsserFahrenholz Supreme Commander 2 uses a neural network as did Planetary Annihilation. Home-brew RL by @merobbins!,1,0
2016-06-03 09:43:32,"@skittlesolives Oh, and cat photos shared by your second cousin you can't unfriend for social reasons.",0,0
2016-06-03 09:41:47,"@skittlesolives We interrupt this stream of random violence, sadness and moral decay with a reminder you should get out the house on Sunday.",2,0
2016-06-03 09:38:30,"@DaveChurchill You either need annotations or abstract style that hides flaws, or a bit of luck...",0,0
2016-06-03 09:36:47,"@DaveChurchill Things were it requires ""understanding"" of scenes is mediocre without annotations, and that part isn't automated yet.",0,0
2016-06-03 09:35:50,@AsserFahrenholz Sophisticated technically as opposed to fun to play?,0,0
2016-06-03 09:17:33,"As @saltyhorse points out, the ""standard"" benchmark for image synthesis seems 256x256 with huge yellow credit label. https://t.co/QNuetUxifs",2,0
2016-06-03 09:03:42,"@FloRicx Not even an acknowledgement, comparison or even an email?",0,0
2016-06-03 09:01:13,"@saltyhorse Oh, man. That's sloppy!",0,0
2016-06-03 08:56:56,"What's I'm not sure about is whether they don't cite blog posts by principle, or whether nobody reads Twitter or reddit Machine Learning!",7,0
2016-06-03 08:55:26,"TL;DR: I beat the state of the art by a month ;-) Honestly, I think my results still look better thanks to patches: https://t.co/k1Vr64CTxm",12,1
2016-06-03 08:54:27,Texture Synthesis Using Shallow Convolutional Networks with Random Filters https://t.co/2XsbEIjEL3 https://t.co/CXj6nUjalS,21,6
2016-06-03 08:43:20,@hardmaru Safe rocket flight and best of luck with the next bit!,1,0
2016-06-03 07:58:35,"@halhod @samim ""Be employed or else..."" ?",1,1
2016-06-03 07:47:32,@samim Fun to play with! Is the face recognition designed to work with beards / mustaches?,0,0
2016-06-03 07:46:03,@halhod @samim Be happy or else... ;-),0,0
2016-06-03 07:25:08,"@spysamot With all the work done to break down large / deep networks and understand them better, getting easier to use parts in evolution!",0,0
2016-06-03 07:22:30,@MC_Spacebat By then the kids will be old enough to help at the conference!,1,0
2016-06-03 07:18:59,"@MC_Spacebat No :-) But our kids are, and I need to outsource them to my parents before the conference so we can actually run it.",1,0
2016-06-03 07:09:26,Wrestling with a sad realization today: I may have to withdraw from ICCC due to end-of-term + pre-conf logistics :-| Doesn't seem to fit...,1,0
2016-06-03 07:06:29,@NeoshamanTamago Simple answer: yes. Detail answer: there are some tricky problems there and they propose interesting solutions.,1,0
2016-06-03 06:58:04,"Instead, his research solves a very relevant problem (learning architecture) while applying it to a reasonable scale problem (MNIST). +1!",0,0
2016-06-03 06:56:00,"The other paper had evolution compete head-to-head with gradient descent, which may never work and toy problems didn't reveal much new.",0,0
2016-06-03 06:53:20,"In particular, this research uses what evolution is good at (structure) and combines it with gradient descent-based (parameter adjustment).",1,0
2016-06-03 06:51:45,"I had a long rant a few weeks ago about another paper at the border between machine learning and evolution, but this one is much better!",2,0
2016-06-03 06:51:05,Fascinating paper combining evolution and convolutional neural networks. https://t.co/es9PXAu4FW via @Miles_Brundage https://t.co/StONeUA7Mm,56,30
2016-06-02 21:05:01,"@nuclai For scheduling reasons and because the track focuses on text &amp; stories too, Monday seems the best fit! (In case you're wondering :-)",1,0
